-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch1/10: 0.28969 in 0 mins 0.26 secs
Train Loss for batch 040/1082 @epoch1/10: 0.25026 in 0 mins 0.26 secs
Train Loss for batch 060/1082 @epoch1/10: 0.25457 in 0 mins 0.26 secs
Train Loss for batch 080/1082 @epoch1/10: 0.21967 in 0 mins 0.26 secs
Train Loss for batch 100/1082 @epoch1/10: 0.20921 in 0 mins 0.26 secs
Train Loss for batch 120/1082 @epoch1/10: 0.23283 in 0 mins 0.26 secs
Train Loss for batch 140/1082 @epoch1/10: 0.23036 in 0 mins 0.26 secs
Train Loss for batch 160/1082 @epoch1/10: 0.20975 in 0 mins 0.26 secs
Train Loss for batch 180/1082 @epoch1/10: 0.18452 in 0 mins 0.26 secs
Train Loss for batch 200/1082 @epoch1/10: 0.21116 in 0 mins 0.26 secs
Train Loss for batch 220/1082 @epoch1/10: 0.22276 in 0 mins 0.26 secs
Train Loss for batch 240/1082 @epoch1/10: 0.22737 in 0 mins 0.26 secs
Train Loss for batch 260/1082 @epoch1/10: 0.21618 in 0 mins 0.26 secs
Train Loss for batch 280/1082 @epoch1/10: 0.19085 in 0 mins 0.26 secs
Train Loss for batch 300/1082 @epoch1/10: 0.21174 in 0 mins 0.26 secs
Train Loss for batch 320/1082 @epoch1/10: 0.21203 in 0 mins 0.26 secs
Train Loss for batch 340/1082 @epoch1/10: 0.20103 in 0 mins 0.26 secs
Train Loss for batch 360/1082 @epoch1/10: 0.18012 in 0 mins 0.26 secs
Train Loss for batch 380/1082 @epoch1/10: 0.20089 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch1/10: 0.19545 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch1/10: 0.18869 in 0 mins 0.26 secs
Train Loss for batch 440/1082 @epoch1/10: 0.21001 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch1/10: 0.22122 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch1/10: 0.19381 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch1/10: 0.1956 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch1/10: 0.20938 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch1/10: 0.19995 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch1/10: 0.17848 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch1/10: 0.18928 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch1/10: 0.16609 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch1/10: 0.17483 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch1/10: 0.16037 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch1/10: 0.18225 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch1/10: 0.1654 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch1/10: 0.1697 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch1/10: 0.15565 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch1/10: 0.17397 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch1/10: 0.19714 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch1/10: 0.15928 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch1/10: 0.16594 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch1/10: 0.17572 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch1/10: 0.17157 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch1/10: 0.14984 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch1/10: 0.20462 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch1/10: 0.16674 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch1/10: 0.15861 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch1/10: 0.1465 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch1/10: 0.15169 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch1/10: 0.11824 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch1/10: 0.16048 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch1/10: 0.14174 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch1/10: 0.12903 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch1/10: 0.15494 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch1/10: 0.1516 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch1/10: 0.22196 in 0.09 secs
Val Loss for batch 040/271 @epoch1/10: 0.23583 in 0.09 secs
Val Loss for batch 060/271 @epoch1/10: 0.23425 in 0.09 secs
Val Loss for batch 080/271 @epoch1/10: 0.21931 in 0.09 secs
Val Loss for batch 100/271 @epoch1/10: 0.16972 in 0.09 secs
Val Loss for batch 120/271 @epoch1/10: 0.19802 in 0.09 secs
Val Loss for batch 140/271 @epoch1/10: 0.21931 in 0.09 secs
Val Loss for batch 160/271 @epoch1/10: 0.20488 in 0.09 secs
Val Loss for batch 180/271 @epoch1/10: 0.25353 in 0.09 secs
Val Loss for batch 200/271 @epoch1/10: 0.23767 in 0.09 secs
Val Loss for batch 220/271 @epoch1/10: 0.18974 in 0.09 secs
Val Loss for batch 240/271 @epoch1/10: 0.20441 in 0.09 secs
Val Loss for batch 260/271 @epoch1/10: 0.25107 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.749939378554663, 'Cardiomegaly': 0.8688964783281734, 'Consolidation': 0.7714449223354525, 'Edema': 0.8507472155185382, 'Effusion': 0.8755396516445322, 'Emphysema': 0.8504846936845609, 'Fibrosis': 0.7240508206970361, 'Hernia': 0.7652358919276212, 'Infiltration': 0.6404341267042972, 'Mass': 0.7502932099962452, 'Nodule': 0.6171071978488214, 'Pleural_Thickening': 0.7067785845650553, 'Pneumonia': 0.6384275182802275, 'Pneumothorax': 0.7641778241998506, 'none': 0.7281370038145409}
AVG Loss in validation set: 0.21270353195846936
0.7552541081632196
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch2/10: 0.18315 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch2/10: 0.17766 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch2/10: 0.14631 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch2/10: 0.16313 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch2/10: 0.14409 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch2/10: 0.13467 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch2/10: 0.14069 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch2/10: 0.1388 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch2/10: 0.18192 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch2/10: 0.12972 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch2/10: 0.13418 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch2/10: 0.13617 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch2/10: 0.10954 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch2/10: 0.14005 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch2/10: 0.14392 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch2/10: 0.13568 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch2/10: 0.12986 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch2/10: 0.15214 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch2/10: 0.13281 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch2/10: 0.12079 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch2/10: 0.11373 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch2/10: 0.14467 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch2/10: 0.14248 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch2/10: 0.10768 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch2/10: 0.12161 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch2/10: 0.13392 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch2/10: 0.13974 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch2/10: 0.11366 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch2/10: 0.15628 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch2/10: 0.12061 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch2/10: 0.10435 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch2/10: 0.12101 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch2/10: 0.14342 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch2/10: 0.11447 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch2/10: 0.16208 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch2/10: 0.13439 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch2/10: 0.12713 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch2/10: 0.09306 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch2/10: 0.12805 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch2/10: 0.11065 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch2/10: 0.10067 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch2/10: 0.1288 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch2/10: 0.13823 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch2/10: 0.14574 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch2/10: 0.09923 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch2/10: 0.11051 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch2/10: 0.1409 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch2/10: 0.10079 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch2/10: 0.15287 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch2/10: 0.13251 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch2/10: 0.11195 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch2/10: 0.14841 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch2/10: 0.10708 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch2/10: 0.11759 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch2/10: 0.21985 in 0.09 secs
Val Loss for batch 040/271 @epoch2/10: 0.23849 in 0.09 secs
Val Loss for batch 060/271 @epoch2/10: 0.24496 in 0.09 secs
Val Loss for batch 080/271 @epoch2/10: 0.19868 in 0.09 secs
Val Loss for batch 100/271 @epoch2/10: 0.16986 in 0.09 secs
Val Loss for batch 120/271 @epoch2/10: 0.18681 in 0.09 secs
Val Loss for batch 140/271 @epoch2/10: 0.21987 in 0.09 secs
Val Loss for batch 160/271 @epoch2/10: 0.19682 in 0.09 secs
Val Loss for batch 180/271 @epoch2/10: 0.26586 in 0.09 secs
Val Loss for batch 200/271 @epoch2/10: 0.22244 in 0.09 secs
Val Loss for batch 220/271 @epoch2/10: 0.18214 in 0.09 secs
Val Loss for batch 240/271 @epoch2/10: 0.20615 in 0.09 secs
Val Loss for batch 260/271 @epoch2/10: 0.26232 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7502585112489863, 'Cardiomegaly': 0.8642633513931888, 'Consolidation': 0.7052546416423083, 'Edema': 0.884167813533874, 'Effusion': 0.8689704958168154, 'Emphysema': 0.8594088070416995, 'Fibrosis': 0.7207895787194512, 'Hernia': 0.8613401635958028, 'Infiltration': 0.6414198300230662, 'Mass': 0.7599519746086248, 'Nodule': 0.6695554515729812, 'Pleural_Thickening': 0.6804427816080751, 'Pneumonia': 0.6113957116587311, 'Pneumothorax': 0.7580123763086798, 'none': 0.7322778164706457}
AVG Loss in validation set: 0.20658147842780453
0.7596593920551632
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch3/10: 0.12641 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch3/10: 0.09618 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch3/10: 0.10643 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch3/10: 0.14863 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch3/10: 0.11249 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch3/10: 0.10266 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch3/10: 0.0902 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch3/10: 0.12609 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch3/10: 0.0993 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch3/10: 0.08453 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch3/10: 0.08493 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch3/10: 0.09528 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch3/10: 0.08266 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch3/10: 0.08728 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch3/10: 0.07887 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch3/10: 0.09467 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch3/10: 0.09028 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch3/10: 0.11967 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch3/10: 0.11225 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch3/10: 0.09237 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch3/10: 0.11688 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch3/10: 0.08911 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch3/10: 0.07487 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch3/10: 0.06513 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch3/10: 0.10486 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch3/10: 0.10084 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch3/10: 0.08327 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch3/10: 0.10629 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch3/10: 0.08162 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch3/10: 0.10069 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch3/10: 0.09387 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch3/10: 0.07595 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch3/10: 0.08285 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch3/10: 0.09142 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch3/10: 0.09485 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch3/10: 0.06574 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch3/10: 0.09591 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch3/10: 0.08056 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch3/10: 0.08774 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch3/10: 0.06181 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch3/10: 0.08155 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch3/10: 0.07793 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch3/10: 0.10295 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch3/10: 0.08563 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch3/10: 0.09607 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch3/10: 0.06119 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch3/10: 0.09077 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch3/10: 0.04844 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch3/10: 0.06188 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch3/10: 0.06416 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch3/10: 0.06082 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch3/10: 0.0707 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch3/10: 0.09906 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch3/10: 0.06564 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch3/10: 0.22675 in 0.09 secs
Val Loss for batch 040/271 @epoch3/10: 0.24974 in 0.09 secs
Val Loss for batch 060/271 @epoch3/10: 0.23625 in 0.09 secs
Val Loss for batch 080/271 @epoch3/10: 0.18958 in 0.09 secs
Val Loss for batch 100/271 @epoch3/10: 0.15276 in 0.09 secs
Val Loss for batch 120/271 @epoch3/10: 0.19964 in 0.09 secs
Val Loss for batch 140/271 @epoch3/10: 0.24506 in 0.09 secs
Val Loss for batch 160/271 @epoch3/10: 0.18538 in 0.09 secs
Val Loss for batch 180/271 @epoch3/10: 0.23302 in 0.09 secs
Val Loss for batch 200/271 @epoch3/10: 0.21657 in 0.09 secs
Val Loss for batch 220/271 @epoch3/10: 0.16309 in 0.09 secs
Val Loss for batch 240/271 @epoch3/10: 0.19536 in 0.09 secs
Val Loss for batch 260/271 @epoch3/10: 0.2914 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7454902899238801, 'Cardiomegaly': 0.8571780185758514, 'Consolidation': 0.7366125473473443, 'Edema': 0.8811460636994805, 'Effusion': 0.8548967197221734, 'Emphysema': 0.8640869450916905, 'Fibrosis': 0.7452755613482956, 'Hernia': 0.8950053705692804, 'Infiltration': 0.6366731551448847, 'Mass': 0.784881036822148, 'Nodule': 0.6408011003447619, 'Pleural_Thickening': 0.682959371715879, 'Pneumonia': 0.6555296282808118, 'Pneumothorax': 0.7975091849349654, 'none': 0.7357872847164696}
AVG Loss in validation set: 0.20345439134622909
0.7698603566801033
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch4/10: 0.06539 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch4/10: 0.06864 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch4/10: 0.0964 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch4/10: 0.05749 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch4/10: 0.05433 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch4/10: 0.09574 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch4/10: 0.08728 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch4/10: 0.06326 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch4/10: 0.05378 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch4/10: 0.08783 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch4/10: 0.09308 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch4/10: 0.08003 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch4/10: 0.08848 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch4/10: 0.0826 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch4/10: 0.07737 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch4/10: 0.06563 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch4/10: 0.08026 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch4/10: 0.07322 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch4/10: 0.06929 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch4/10: 0.05594 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch4/10: 0.06204 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch4/10: 0.06059 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch4/10: 0.09842 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch4/10: 0.08263 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch4/10: 0.04667 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch4/10: 0.07233 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch4/10: 0.08567 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch4/10: 0.06199 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch4/10: 0.0622 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch4/10: 0.07157 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch4/10: 0.06911 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch4/10: 0.07709 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch4/10: 0.08717 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch4/10: 0.08458 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch4/10: 0.07989 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch4/10: 0.09191 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch4/10: 0.07845 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch4/10: 0.06888 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch4/10: 0.04334 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch4/10: 0.06129 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch4/10: 0.06874 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch4/10: 0.08205 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch4/10: 0.05319 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch4/10: 0.09025 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch4/10: 0.07291 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch4/10: 0.07616 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch4/10: 0.07702 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch4/10: 0.06757 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch4/10: 0.06108 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch4/10: 0.07218 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch4/10: 0.05946 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch4/10: 0.06756 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch4/10: 0.06554 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch4/10: 0.04583 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch4/10: 0.22435 in 0.09 secs
Val Loss for batch 040/271 @epoch4/10: 0.24265 in 0.09 secs
Val Loss for batch 060/271 @epoch4/10: 0.24092 in 0.09 secs
Val Loss for batch 080/271 @epoch4/10: 0.19303 in 0.09 secs
Val Loss for batch 100/271 @epoch4/10: 0.14447 in 0.09 secs
Val Loss for batch 120/271 @epoch4/10: 0.17616 in 0.09 secs
Val Loss for batch 140/271 @epoch4/10: 0.24933 in 0.09 secs
Val Loss for batch 160/271 @epoch4/10: 0.19135 in 0.09 secs
Val Loss for batch 180/271 @epoch4/10: 0.25628 in 0.09 secs
Val Loss for batch 200/271 @epoch4/10: 0.21782 in 0.09 secs
Val Loss for batch 220/271 @epoch4/10: 0.16513 in 0.09 secs
Val Loss for batch 240/271 @epoch4/10: 0.19413 in 0.09 secs
Val Loss for batch 260/271 @epoch4/10: 0.25717 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7672662343804043, 'Cardiomegaly': 0.8583054373065014, 'Consolidation': 0.6771934931877394, 'Edema': 0.8888756216674281, 'Effusion': 0.8618137730864426, 'Emphysema': 0.8575880732539489, 'Fibrosis': 0.753959019896649, 'Hernia': 0.8439684375774602, 'Infiltration': 0.6509639778122385, 'Mass': 0.7689845662014665, 'Nodule': 0.6450665471850432, 'Pleural_Thickening': 0.703736733740423, 'Pneumonia': 0.6511720477001908, 'Pneumothorax': 0.7839892594968251, 'none': 0.7337093576648774}
AVG Loss in validation set: 0.19795905750105353
0.7652059444637687
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch5/10: 0.07001 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch5/10: 0.0651 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch5/10: 0.06313 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch5/10: 0.09062 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch5/10: 0.05893 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch5/10: 0.07687 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch5/10: 0.04715 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch5/10: 0.05262 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch5/10: 0.0691 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch5/10: 0.03908 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch5/10: 0.06044 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch5/10: 0.0667 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch5/10: 0.06105 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch5/10: 0.07418 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch5/10: 0.04348 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch5/10: 0.04166 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch5/10: 0.06984 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch5/10: 0.06265 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch5/10: 0.08327 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch5/10: 0.05787 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch5/10: 0.04345 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch5/10: 0.06103 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch5/10: 0.06154 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch5/10: 0.0522 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch5/10: 0.05182 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch5/10: 0.06293 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch5/10: 0.07682 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch5/10: 0.07537 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch5/10: 0.0578 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch5/10: 0.07545 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch5/10: 0.06982 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch5/10: 0.08138 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch5/10: 0.05135 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch5/10: 0.05469 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch5/10: 0.06342 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch5/10: 0.05423 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch5/10: 0.08635 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch5/10: 0.05667 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch5/10: 0.04946 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch5/10: 0.04842 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch5/10: 0.05807 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch5/10: 0.0709 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch5/10: 0.06198 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch5/10: 0.05093 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch5/10: 0.05557 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch5/10: 0.03993 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch5/10: 0.06984 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch5/10: 0.0881 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch5/10: 0.07696 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch5/10: 0.03301 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch5/10: 0.04486 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch5/10: 0.06305 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch5/10: 0.04726 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch5/10: 0.0551 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch5/10: 0.24803 in 0.09 secs
Val Loss for batch 040/271 @epoch5/10: 0.26183 in 0.09 secs
Val Loss for batch 060/271 @epoch5/10: 0.26556 in 0.09 secs
Val Loss for batch 080/271 @epoch5/10: 0.20297 in 0.09 secs
Val Loss for batch 100/271 @epoch5/10: 0.15939 in 0.09 secs
Val Loss for batch 120/271 @epoch5/10: 0.20055 in 0.09 secs
Val Loss for batch 140/271 @epoch5/10: 0.25349 in 0.09 secs
Val Loss for batch 160/271 @epoch5/10: 0.20576 in 0.09 secs
Val Loss for batch 180/271 @epoch5/10: 0.25379 in 0.09 secs
Val Loss for batch 200/271 @epoch5/10: 0.23912 in 0.09 secs
Val Loss for batch 220/271 @epoch5/10: 0.16462 in 0.09 secs
Val Loss for batch 240/271 @epoch5/10: 0.20372 in 0.09 secs
Val Loss for batch 260/271 @epoch5/10: 0.2592 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7446744743753257, 'Cardiomegaly': 0.8490665634674923, 'Consolidation': 0.717835959442868, 'Edema': 0.8868341513229382, 'Effusion': 0.859768979207682, 'Emphysema': 0.8566047138836772, 'Fibrosis': 0.7429061894014052, 'Hernia': 0.8632776997438653, 'Infiltration': 0.6430313994000688, 'Mass': 0.7795534129859025, 'Nodule': 0.672184446296718, 'Pleural_Thickening': 0.7052369016543494, 'Pneumonia': 0.6408504445853209, 'Pneumothorax': 0.7857254204457805, 'none': 0.7305719482574768}
AVG Loss in validation set: 0.21273020314938815
0.7676821968723853
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch6/10: 0.04561 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch6/10: 0.03611 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch6/10: 0.04389 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch6/10: 0.05683 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch6/10: 0.03748 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch6/10: 0.05101 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch6/10: 0.02832 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch6/10: 0.06203 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch6/10: 0.05808 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch6/10: 0.06079 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch6/10: 0.04614 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch6/10: 0.04835 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch6/10: 0.04465 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch6/10: 0.06108 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch6/10: 0.03222 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch6/10: 0.03538 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch6/10: 0.06034 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch6/10: 0.05761 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch6/10: 0.03845 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch6/10: 0.0695 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch6/10: 0.04383 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch6/10: 0.04891 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch6/10: 0.05677 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch6/10: 0.04401 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch6/10: 0.03611 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch6/10: 0.03885 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch6/10: 0.03322 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch6/10: 0.05952 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch6/10: 0.05673 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch6/10: 0.04629 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch6/10: 0.0392 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch6/10: 0.0398 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch6/10: 0.04453 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch6/10: 0.05434 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch6/10: 0.02467 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch6/10: 0.0405 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch6/10: 0.05156 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch6/10: 0.04551 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch6/10: 0.05678 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch6/10: 0.04088 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch6/10: 0.03571 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch6/10: 0.05359 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch6/10: 0.05151 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch6/10: 0.04284 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch6/10: 0.04239 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch6/10: 0.02257 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch6/10: 0.04003 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch6/10: 0.05964 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch6/10: 0.02227 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch6/10: 0.0485 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch6/10: 0.02358 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch6/10: 0.0433 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch6/10: 0.03897 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch6/10: 0.03785 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch6/10: 0.23103 in 0.09 secs
Val Loss for batch 040/271 @epoch6/10: 0.29552 in 0.09 secs
Val Loss for batch 060/271 @epoch6/10: 0.27111 in 0.09 secs
Val Loss for batch 080/271 @epoch6/10: 0.20282 in 0.09 secs
Val Loss for batch 100/271 @epoch6/10: 0.15382 in 0.09 secs
Val Loss for batch 120/271 @epoch6/10: 0.20317 in 0.09 secs
Val Loss for batch 140/271 @epoch6/10: 0.25542 in 0.09 secs
Val Loss for batch 160/271 @epoch6/10: 0.18448 in 0.09 secs
Val Loss for batch 180/271 @epoch6/10: 0.25183 in 0.09 secs
Val Loss for batch 200/271 @epoch6/10: 0.23438 in 0.09 secs
Val Loss for batch 220/271 @epoch6/10: 0.18327 in 0.08 secs
Val Loss for batch 240/271 @epoch6/10: 0.19015 in 0.09 secs
Val Loss for batch 260/271 @epoch6/10: 0.26422 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7490084084358682, 'Cardiomegaly': 0.8455276702786377, 'Consolidation': 0.7453026759492027, 'Edema': 0.884662437973404, 'Effusion': 0.8535513136301225, 'Emphysema': 0.8535592431761786, 'Fibrosis': 0.7286242595712665, 'Hernia': 0.8027679087829463, 'Infiltration': 0.6531230490060506, 'Mass': 0.7872151894915835, 'Nodule': 0.6652515153330752, 'Pleural_Thickening': 0.723476287057597, 'Pneumonia': 0.6514458577057209, 'Pneumothorax': 0.7934920847437605, 'none': 0.7300321919770303}
AVG Loss in validation set: 0.21712937212574554
0.7669291357953868
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch7/10: 0.04689 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch7/10: 0.05777 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch7/10: 0.04162 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch7/10: 0.03649 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch7/10: 0.07326 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch7/10: 0.06032 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch7/10: 0.05582 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch7/10: 0.0411 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch7/10: 0.06204 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch7/10: 0.04504 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch7/10: 0.05433 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch7/10: 0.03379 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch7/10: 0.05237 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch7/10: 0.04889 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch7/10: 0.05472 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch7/10: 0.04235 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch7/10: 0.03154 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch7/10: 0.04141 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch7/10: 0.04383 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch7/10: 0.03639 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch7/10: 0.0705 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch7/10: 0.02606 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch7/10: 0.04702 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch7/10: 0.0222 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch7/10: 0.03609 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch7/10: 0.02694 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch7/10: 0.04714 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch7/10: 0.02167 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch7/10: 0.03238 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch7/10: 0.03407 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch7/10: 0.03461 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch7/10: 0.02301 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch7/10: 0.05601 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch7/10: 0.01853 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch7/10: 0.03085 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch7/10: 0.02823 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch7/10: 0.03766 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch7/10: 0.03711 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch7/10: 0.03679 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch7/10: 0.04611 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch7/10: 0.03273 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch7/10: 0.02572 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch7/10: 0.02772 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch7/10: 0.04664 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch7/10: 0.03651 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch7/10: 0.03018 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch7/10: 0.04017 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch7/10: 0.03519 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch7/10: 0.04041 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch7/10: 0.03928 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch7/10: 0.021 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch7/10: 0.06316 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch7/10: 0.02162 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch7/10: 0.04867 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch7/10: 0.2527 in 0.09 secs
Val Loss for batch 040/271 @epoch7/10: 0.27118 in 0.09 secs
Val Loss for batch 060/271 @epoch7/10: 0.26699 in 0.09 secs
Val Loss for batch 080/271 @epoch7/10: 0.21366 in 0.09 secs
Val Loss for batch 100/271 @epoch7/10: 0.16281 in 0.09 secs
Val Loss for batch 120/271 @epoch7/10: 0.20874 in 0.09 secs
Val Loss for batch 140/271 @epoch7/10: 0.27606 in 0.09 secs
Val Loss for batch 160/271 @epoch7/10: 0.19456 in 0.09 secs
Val Loss for batch 180/271 @epoch7/10: 0.25704 in 0.09 secs
Val Loss for batch 200/271 @epoch7/10: 0.2329 in 0.09 secs
Val Loss for batch 220/271 @epoch7/10: 0.17312 in 0.09 secs
Val Loss for batch 240/271 @epoch7/10: 0.19975 in 0.09 secs
Val Loss for batch 260/271 @epoch7/10: 0.25023 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7479869084823451, 'Cardiomegaly': 0.8435178018575852, 'Consolidation': 0.716336380194734, 'Edema': 0.8654410370108764, 'Effusion': 0.8489832062046349, 'Emphysema': 0.8391413673364402, 'Fibrosis': 0.7169077364868445, 'Hernia': 0.8476080310666777, 'Infiltration': 0.6580054353656952, 'Mass': 0.7759195482045136, 'Nodule': 0.6676951942625898, 'Pleural_Thickening': 0.709568101015323, 'Pneumonia': 0.6552454773391123, 'Pneumothorax': 0.7818845599443185, 'none': 0.724278425017115}
AVG Loss in validation set: 0.2174636101590446
0.762445770340835
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch8/10: 0.04499 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch8/10: 0.06789 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch8/10: 0.02805 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch8/10: 0.02695 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch8/10: 0.0386 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch8/10: 0.04871 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch8/10: 0.02485 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch8/10: 0.02572 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch8/10: 0.04557 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch8/10: 0.02307 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch8/10: 0.05975 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch8/10: 0.02335 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch8/10: 0.03022 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch8/10: 0.06275 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch8/10: 0.02326 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch8/10: 0.04466 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch8/10: 0.03704 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch8/10: 0.04105 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch8/10: 0.03213 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch8/10: 0.0418 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch8/10: 0.0358 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch8/10: 0.03995 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch8/10: 0.02516 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch8/10: 0.0301 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch8/10: 0.04318 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch8/10: 0.05933 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch8/10: 0.02833 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch8/10: 0.03672 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch8/10: 0.02827 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch8/10: 0.05172 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch8/10: 0.0424 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch8/10: 0.04326 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch8/10: 0.02694 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch8/10: 0.04222 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch8/10: 0.03071 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch8/10: 0.03094 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch8/10: 0.03377 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch8/10: 0.03633 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch8/10: 0.0206 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch8/10: 0.03644 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch8/10: 0.02334 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch8/10: 0.04053 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch8/10: 0.04138 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch8/10: 0.02701 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch8/10: 0.02803 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch8/10: 0.02468 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch8/10: 0.03556 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch8/10: 0.03977 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch8/10: 0.04653 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch8/10: 0.03778 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch8/10: 0.04026 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch8/10: 0.02445 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch8/10: 0.04196 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch8/10: 0.01957 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch8/10: 0.22861 in 0.09 secs
Val Loss for batch 040/271 @epoch8/10: 0.29312 in 0.08 secs
Val Loss for batch 060/271 @epoch8/10: 0.26843 in 0.09 secs
Val Loss for batch 080/271 @epoch8/10: 0.22398 in 0.09 secs
Val Loss for batch 100/271 @epoch8/10: 0.15721 in 0.09 secs
Val Loss for batch 120/271 @epoch8/10: 0.20674 in 0.09 secs
Val Loss for batch 140/271 @epoch8/10: 0.27892 in 0.09 secs
Val Loss for batch 160/271 @epoch8/10: 0.21697 in 0.09 secs
Val Loss for batch 180/271 @epoch8/10: 0.28236 in 0.09 secs
Val Loss for batch 200/271 @epoch8/10: 0.22955 in 0.09 secs
Val Loss for batch 220/271 @epoch8/10: 0.18412 in 0.09 secs
Val Loss for batch 240/271 @epoch8/10: 0.20795 in 0.09 secs
Val Loss for batch 260/271 @epoch8/10: 0.2791 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7487331543056892, 'Cardiomegaly': 0.8438490712074304, 'Consolidation': 0.737359836141544, 'Edema': 0.8687862454417282, 'Effusion': 0.846904011627734, 'Emphysema': 0.832432206242813, 'Fibrosis': 0.7227531056503941, 'Hernia': 0.8121664050235479, 'Infiltration': 0.6587663222617199, 'Mass': 0.7738722852668601, 'Nodule': 0.6606668197753123, 'Pleural_Thickening': 0.7101647383932808, 'Pneumonia': 0.6321237435387882, 'Pneumothorax': 0.7723458514494715, 'none': 0.7245670554203041}
AVG Loss in validation set: 0.22263709604877926
0.7586374140233081
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch9/10: 0.03231 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch9/10: 0.04485 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch9/10: 0.04733 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch9/10: 0.05396 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch9/10: 0.02012 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch9/10: 0.01702 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch9/10: 0.03987 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch9/10: 0.02842 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch9/10: 0.01393 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch9/10: 0.03581 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch9/10: 0.01737 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch9/10: 0.0194 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch9/10: 0.02729 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch9/10: 0.01563 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch9/10: 0.03262 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch9/10: 0.01601 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch9/10: 0.02639 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch9/10: 0.01451 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch9/10: 0.01252 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch9/10: 0.01765 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch9/10: 0.02256 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch9/10: 0.01606 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch9/10: 0.02343 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch9/10: 0.02709 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch9/10: 0.01513 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch9/10: 0.04248 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch9/10: 0.01524 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch9/10: 0.01176 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch9/10: 0.04641 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch9/10: 0.03229 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch9/10: 0.03882 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch9/10: 0.02093 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch9/10: 0.05242 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch9/10: 0.03438 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch9/10: 0.02603 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch9/10: 0.04242 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch9/10: 0.02321 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch9/10: 0.03386 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch9/10: 0.03833 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch9/10: 0.01516 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch9/10: 0.01923 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch9/10: 0.01442 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch9/10: 0.02716 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch9/10: 0.0276 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch9/10: 0.03983 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch9/10: 0.02478 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch9/10: 0.02183 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch9/10: 0.01116 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch9/10: 0.01584 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch9/10: 0.04237 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch9/10: 0.02281 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch9/10: 0.01787 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch9/10: 0.01329 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch9/10: 0.03919 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch9/10: 0.28148 in 0.09 secs
Val Loss for batch 040/271 @epoch9/10: 0.29462 in 0.09 secs
Val Loss for batch 060/271 @epoch9/10: 0.31034 in 0.09 secs
Val Loss for batch 080/271 @epoch9/10: 0.19965 in 0.09 secs
Val Loss for batch 100/271 @epoch9/10: 0.15193 in 0.09 secs
Val Loss for batch 120/271 @epoch9/10: 0.17752 in 0.09 secs
Val Loss for batch 140/271 @epoch9/10: 0.28381 in 0.09 secs
Val Loss for batch 160/271 @epoch9/10: 0.23422 in 0.09 secs
Val Loss for batch 180/271 @epoch9/10: 0.28198 in 0.09 secs
Val Loss for batch 200/271 @epoch9/10: 0.22954 in 0.09 secs
Val Loss for batch 220/271 @epoch9/10: 0.1731 in 0.09 secs
Val Loss for batch 240/271 @epoch9/10: 0.21077 in 0.09 secs
Val Loss for batch 260/271 @epoch9/10: 0.28997 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7485804033872934, 'Cardiomegaly': 0.8282043343653251, 'Consolidation': 0.7475592921242845, 'Edema': 0.8762515801541053, 'Effusion': 0.85206504710364, 'Emphysema': 0.8429593171261273, 'Fibrosis': 0.7386632428276578, 'Hernia': 0.8056287697265141, 'Infiltration': 0.6652222092428842, 'Mass': 0.7809044413360234, 'Nodule': 0.66760621339249, 'Pleural_Thickening': 0.7152722748152416, 'Pneumonia': 0.6309937339921559, 'Pneumothorax': 0.7891855655694001, 'none': 0.7175714430808067}
AVG Loss in validation set: 0.22717071003898448
0.7635068875116531
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch10/10: 0.01858 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch10/10: 0.02782 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch10/10: 0.01326 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch10/10: 0.04772 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch10/10: 0.02092 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch10/10: 0.0175 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch10/10: 0.02631 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch10/10: 0.02535 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch10/10: 0.01977 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch10/10: 0.01532 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch10/10: 0.02972 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch10/10: 0.01845 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch10/10: 0.03185 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch10/10: 0.01051 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch10/10: 0.01948 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch10/10: 0.0249 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch10/10: 0.01656 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch10/10: 0.02017 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch10/10: 0.04211 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch10/10: 0.02053 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch10/10: 0.02721 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch10/10: 0.01693 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch10/10: 0.0161 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch10/10: 0.01747 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch10/10: 0.02134 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch10/10: 0.03472 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch10/10: 0.03306 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch10/10: 0.06051 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch10/10: 0.03555 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch10/10: 0.03294 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch10/10: 0.02635 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch10/10: 0.03088 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch10/10: 0.0262 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch10/10: 0.02407 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch10/10: 0.01575 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch10/10: 0.01802 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch10/10: 0.03146 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch10/10: 0.02067 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch10/10: 0.02649 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch10/10: 0.02128 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch10/10: 0.02149 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch10/10: 0.02371 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch10/10: 0.03111 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch10/10: 0.02294 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch10/10: 0.02203 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch10/10: 0.02914 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch10/10: 0.02243 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch10/10: 0.02111 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch10/10: 0.0262 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch10/10: 0.01621 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch10/10: 0.05116 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch10/10: 0.02539 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch10/10: 0.01981 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch10/10: 0.03201 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch10/10: 0.25281 in 0.09 secs
Val Loss for batch 040/271 @epoch10/10: 0.30492 in 0.09 secs
Val Loss for batch 060/271 @epoch10/10: 0.30779 in 0.09 secs
Val Loss for batch 080/271 @epoch10/10: 0.21932 in 0.09 secs
Val Loss for batch 100/271 @epoch10/10: 0.18498 in 0.09 secs
Val Loss for batch 120/271 @epoch10/10: 0.21455 in 0.09 secs
Val Loss for batch 140/271 @epoch10/10: 0.28765 in 0.09 secs
Val Loss for batch 160/271 @epoch10/10: 0.23348 in 0.09 secs
Val Loss for batch 180/271 @epoch10/10: 0.26895 in 0.09 secs
Val Loss for batch 200/271 @epoch10/10: 0.24716 in 0.09 secs
Val Loss for batch 220/271 @epoch10/10: 0.19811 in 0.09 secs
Val Loss for batch 240/271 @epoch10/10: 0.20779 in 0.09 secs
Val Loss for batch 260/271 @epoch10/10: 0.28891 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7450842920208217, 'Cardiomegaly': 0.8215234133126934, 'Consolidation': 0.734794137809812, 'Edema': 0.8637727306277546, 'Effusion': 0.853275028369407, 'Emphysema': 0.833052080811596, 'Fibrosis': 0.7332860024089322, 'Hernia': 0.7854498884574074, 'Infiltration': 0.6567903549944195, 'Mass': 0.7773266689017422, 'Nodule': 0.6619555301945041, 'Pleural_Thickening': 0.7080137053783309, 'Pneumonia': 0.6530609920404765, 'Pneumothorax': 0.7797527420683904, 'none': 0.7164878780082741}
AVG Loss in validation set: 0.23343776889107484
0.7576526833854491
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_steplr_0/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch1/10: 0.29557 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch1/10: 0.26189 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch1/10: 0.2685 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch1/10: 0.26198 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch1/10: 0.24804 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch1/10: 0.26762 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch1/10: 0.26017 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch1/10: 0.25365 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch1/10: 0.24589 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch1/10: 0.25174 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch1/10: 0.25712 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch1/10: 0.25817 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch1/10: 0.26225 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch1/10: 0.24301 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch1/10: 0.25738 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch1/10: 0.25247 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch1/10: 0.25382 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch1/10: 0.22956 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch1/10: 0.24078 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch1/10: 0.24984 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch1/10: 0.23529 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch1/10: 0.25488 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch1/10: 0.2532 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch1/10: 0.23571 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch1/10: 0.2506 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch1/10: 0.28035 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch1/10: 0.24304 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch1/10: 0.23441 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch1/10: 0.2505 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch1/10: 0.22502 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch1/10: 0.22973 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch1/10: 0.23962 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch1/10: 0.24139 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch1/10: 0.25451 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch1/10: 0.24365 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch1/10: 0.2278 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch1/10: 0.22709 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch1/10: 0.24458 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch1/10: 0.24586 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch1/10: 0.23696 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch1/10: 0.24068 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch1/10: 0.23863 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch1/10: 0.21301 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch1/10: 0.26496 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch1/10: 0.24648 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch1/10: 0.22876 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch1/10: 0.21085 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch1/10: 0.23126 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch1/10: 0.2042 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch1/10: 0.22869 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch1/10: 0.24016 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch1/10: 0.22535 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch1/10: 0.23228 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch1/10: 0.23453 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch1/10: 0.235 in 0.09 secs
Val Loss for batch 040/271 @epoch1/10: 0.23988 in 0.09 secs
Val Loss for batch 060/271 @epoch1/10: 0.24291 in 0.09 secs
Val Loss for batch 080/271 @epoch1/10: 0.24172 in 0.09 secs
Val Loss for batch 100/271 @epoch1/10: 0.20739 in 0.09 secs
Val Loss for batch 120/271 @epoch1/10: 0.217 in 0.09 secs
Val Loss for batch 140/271 @epoch1/10: 0.22385 in 0.09 secs
Val Loss for batch 160/271 @epoch1/10: 0.22307 in 0.09 secs
Val Loss for batch 180/271 @epoch1/10: 0.25589 in 0.09 secs
Val Loss for batch 200/271 @epoch1/10: 0.26539 in 0.09 secs
Val Loss for batch 220/271 @epoch1/10: 0.20786 in 0.09 secs
Val Loss for batch 240/271 @epoch1/10: 0.23559 in 0.09 secs
Val Loss for batch 260/271 @epoch1/10: 0.26811 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7296006849011475, 'Cardiomegaly': 0.8163407507739938, 'Consolidation': 0.7617872787990463, 'Edema': 0.8534878310615552, 'Effusion': 0.8520304788696317, 'Emphysema': 0.7494553047267446, 'Fibrosis': 0.6839058373629376, 'Hernia': 0.7497232091217054, 'Infiltration': 0.6044063661628422, 'Mass': 0.688468778037196, 'Nodule': 0.5778201858022441, 'Pleural_Thickening': 0.6873479769814902, 'Pneumonia': 0.5667591356176311, 'Pneumothorax': 0.7087096760530969, 'none': 0.7129704482513877}
AVG Loss in validation set: 0.2340830372016958
0.7164173924479473
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch2/10: 0.23103 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch2/10: 0.22136 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch2/10: 0.2069 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch2/10: 0.24296 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch2/10: 0.1961 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch2/10: 0.21056 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch2/10: 0.21639 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch2/10: 0.21125 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch2/10: 0.22475 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch2/10: 0.21577 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch2/10: 0.20382 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch2/10: 0.20891 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch2/10: 0.2057 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch2/10: 0.19453 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch2/10: 0.2203 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch2/10: 0.20097 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch2/10: 0.20673 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch2/10: 0.21241 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch2/10: 0.22751 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch2/10: 0.20474 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch2/10: 0.18471 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch2/10: 0.21655 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch2/10: 0.21093 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch2/10: 0.18959 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch2/10: 0.21913 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch2/10: 0.21213 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch2/10: 0.21817 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch2/10: 0.21335 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch2/10: 0.22566 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch2/10: 0.18985 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch2/10: 0.2013 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch2/10: 0.21024 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch2/10: 0.23015 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch2/10: 0.19607 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch2/10: 0.22784 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch2/10: 0.20336 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch2/10: 0.18728 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch2/10: 0.18173 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch2/10: 0.21172 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch2/10: 0.20414 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch2/10: 0.18684 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch2/10: 0.20514 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch2/10: 0.21006 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch2/10: 0.21081 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch2/10: 0.21033 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch2/10: 0.21185 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch2/10: 0.19095 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch2/10: 0.19192 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch2/10: 0.22886 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch2/10: 0.22092 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch2/10: 0.19258 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch2/10: 0.20711 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch2/10: 0.19944 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch2/10: 0.2032 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch2/10: 0.24612 in 0.09 secs
Val Loss for batch 040/271 @epoch2/10: 0.22834 in 0.09 secs
Val Loss for batch 060/271 @epoch2/10: 0.23547 in 0.09 secs
Val Loss for batch 080/271 @epoch2/10: 0.23883 in 0.09 secs
Val Loss for batch 100/271 @epoch2/10: 0.18647 in 0.09 secs
Val Loss for batch 120/271 @epoch2/10: 0.19502 in 0.09 secs
Val Loss for batch 140/271 @epoch2/10: 0.21994 in 0.09 secs
Val Loss for batch 160/271 @epoch2/10: 0.19846 in 0.09 secs
Val Loss for batch 180/271 @epoch2/10: 0.24014 in 0.09 secs
Val Loss for batch 200/271 @epoch2/10: 0.24838 in 0.09 secs
Val Loss for batch 220/271 @epoch2/10: 0.19373 in 0.09 secs
Val Loss for batch 240/271 @epoch2/10: 0.21823 in 0.09 secs
Val Loss for batch 260/271 @epoch2/10: 0.24762 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7382646557215727, 'Cardiomegaly': 0.8747916021671827, 'Consolidation': 0.7545843273706745, 'Edema': 0.8704865052737205, 'Effusion': 0.8666135640016797, 'Emphysema': 0.7970742960570115, 'Fibrosis': 0.7209594755451003, 'Hernia': 0.7470420556886722, 'Infiltration': 0.6128883158927945, 'Mass': 0.7071053346766768, 'Nodule': 0.5913638064532684, 'Pleural_Thickening': 0.7043719065699368, 'Pneumonia': 0.563592411251538, 'Pneumothorax': 0.76732525564167, 'none': 0.7275452346064594}
AVG Loss in validation set: 0.21702995046911228
0.7368902508793927
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch3/10: 0.20331 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch3/10: 0.18593 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch3/10: 0.19618 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch3/10: 0.22277 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch3/10: 0.225 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch3/10: 0.20779 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch3/10: 0.16694 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch3/10: 0.20428 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch3/10: 0.1872 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch3/10: 0.19758 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch3/10: 0.18441 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch3/10: 0.18156 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch3/10: 0.17274 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch3/10: 0.18527 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch3/10: 0.18715 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch3/10: 0.18885 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch3/10: 0.19281 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch3/10: 0.21242 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch3/10: 0.19995 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch3/10: 0.21058 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch3/10: 0.20489 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch3/10: 0.17782 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch3/10: 0.18447 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch3/10: 0.17261 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch3/10: 0.19571 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch3/10: 0.19381 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch3/10: 0.2137 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch3/10: 0.19887 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch3/10: 0.19386 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch3/10: 0.19506 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch3/10: 0.20131 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch3/10: 0.19534 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch3/10: 0.17435 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch3/10: 0.19087 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch3/10: 0.17488 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch3/10: 0.17986 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch3/10: 0.19678 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch3/10: 0.196 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch3/10: 0.199 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch3/10: 0.19377 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch3/10: 0.19766 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch3/10: 0.17518 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch3/10: 0.21041 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch3/10: 0.1953 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch3/10: 0.20747 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch3/10: 0.17607 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch3/10: 0.1932 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch3/10: 0.14671 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch3/10: 0.17712 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch3/10: 0.17019 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch3/10: 0.18514 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch3/10: 0.1799 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch3/10: 0.19034 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch3/10: 0.19423 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch3/10: 0.25196 in 0.09 secs
Val Loss for batch 040/271 @epoch3/10: 0.22933 in 0.09 secs
Val Loss for batch 060/271 @epoch3/10: 0.23322 in 0.09 secs
Val Loss for batch 080/271 @epoch3/10: 0.24008 in 0.09 secs
Val Loss for batch 100/271 @epoch3/10: 0.18696 in 0.09 secs
Val Loss for batch 120/271 @epoch3/10: 0.20032 in 0.09 secs
Val Loss for batch 140/271 @epoch3/10: 0.22149 in 0.09 secs
Val Loss for batch 160/271 @epoch3/10: 0.19738 in 0.09 secs
Val Loss for batch 180/271 @epoch3/10: 0.2441 in 0.09 secs
Val Loss for batch 200/271 @epoch3/10: 0.25751 in 0.09 secs
Val Loss for batch 220/271 @epoch3/10: 0.19724 in 0.09 secs
Val Loss for batch 240/271 @epoch3/10: 0.20814 in 0.09 secs
Val Loss for batch 260/271 @epoch3/10: 0.25062 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7420843593801377, 'Cardiomegaly': 0.868140479876161, 'Consolidation': 0.754035114509427, 'Edema': 0.8757791923251927, 'Effusion': 0.8689675732466813, 'Emphysema': 0.7929467636022515, 'Fibrosis': 0.71047579352885, 'Hernia': 0.7432661323638766, 'Infiltration': 0.5897363920274477, 'Mass': 0.7177516406113764, 'Nodule': 0.5890348635007984, 'Pleural_Thickening': 0.6941282300918705, 'Pneumonia': 0.5834491068578391, 'Pneumothorax': 0.7706833393962297, 'none': 0.7275015727230457}
AVG Loss in validation set: 0.21865205755401307
0.7357484986655815
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch4/10: 0.16903 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch4/10: 0.16625 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch4/10: 0.1774 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch4/10: 0.1713 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch4/10: 0.20668 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch4/10: 0.19659 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch4/10: 0.19224 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch4/10: 0.19789 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch4/10: 0.16786 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch4/10: 0.18508 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch4/10: 0.21446 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch4/10: 0.17833 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch4/10: 0.20782 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch4/10: 0.21359 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch4/10: 0.18917 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch4/10: 0.17685 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch4/10: 0.18452 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch4/10: 0.19322 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch4/10: 0.16406 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch4/10: 0.18644 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch4/10: 0.18943 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch4/10: 0.17297 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch4/10: 0.22628 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch4/10: 0.19131 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch4/10: 0.18081 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch4/10: 0.1915 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch4/10: 0.17576 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch4/10: 0.19223 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch4/10: 0.19677 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch4/10: 0.19091 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch4/10: 0.20717 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch4/10: 0.18433 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch4/10: 0.20212 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch4/10: 0.20788 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch4/10: 0.2097 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch4/10: 0.18701 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch4/10: 0.20007 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch4/10: 0.18038 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch4/10: 0.17943 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch4/10: 0.17643 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch4/10: 0.19851 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch4/10: 0.19163 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch4/10: 0.16966 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch4/10: 0.18727 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch4/10: 0.17332 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch4/10: 0.19848 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch4/10: 0.20267 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch4/10: 0.19499 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch4/10: 0.21429 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch4/10: 0.17801 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch4/10: 0.18213 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch4/10: 0.1906 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch4/10: 0.18635 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch4/10: 0.18322 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch4/10: 0.25122 in 0.09 secs
Val Loss for batch 040/271 @epoch4/10: 0.23018 in 0.09 secs
Val Loss for batch 060/271 @epoch4/10: 0.23896 in 0.09 secs
Val Loss for batch 080/271 @epoch4/10: 0.23258 in 0.09 secs
Val Loss for batch 100/271 @epoch4/10: 0.1865 in 0.09 secs
Val Loss for batch 120/271 @epoch4/10: 0.20541 in 0.09 secs
Val Loss for batch 140/271 @epoch4/10: 0.2163 in 0.09 secs
Val Loss for batch 160/271 @epoch4/10: 0.19784 in 0.09 secs
Val Loss for batch 180/271 @epoch4/10: 0.24028 in 0.09 secs
Val Loss for batch 200/271 @epoch4/10: 0.25371 in 0.09 secs
Val Loss for batch 220/271 @epoch4/10: 0.19669 in 0.09 secs
Val Loss for batch 240/271 @epoch4/10: 0.21622 in 0.09 secs
Val Loss for batch 260/271 @epoch4/10: 0.25323 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7399494917590318, 'Cardiomegaly': 0.8771031346749227, 'Consolidation': 0.7557243485287158, 'Edema': 0.871264786645327, 'Effusion': 0.868152027258458, 'Emphysema': 0.8050763991859833, 'Fibrosis': 0.7128837837424162, 'Hernia': 0.7160166900768404, 'Infiltration': 0.5928105779937349, 'Mass': 0.7180393562868101, 'Nodule': 0.5863066686370861, 'Pleural_Thickening': 0.7072688190724795, 'Pneumonia': 0.5827579126895277, 'Pneumothorax': 0.7675920858261406, 'none': 0.727781667566306}
AVG Loss in validation set: 0.22038481524020392
0.7357818630269625
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch5/10: 0.19084 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch5/10: 0.19367 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch5/10: 0.18345 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch5/10: 0.21564 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch5/10: 0.17043 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch5/10: 0.18412 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch5/10: 0.16394 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch5/10: 0.18133 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch5/10: 0.19177 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch5/10: 0.16349 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch5/10: 0.18988 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch5/10: 0.1765 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch5/10: 0.1843 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch5/10: 0.18729 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch5/10: 0.19814 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch5/10: 0.17119 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch5/10: 0.17687 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch5/10: 0.18884 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch5/10: 0.21283 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch5/10: 0.18867 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch5/10: 0.15892 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch5/10: 0.21195 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch5/10: 0.19835 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch5/10: 0.18782 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch5/10: 0.18155 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch5/10: 0.20544 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch5/10: 0.20689 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch5/10: 0.23353 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch5/10: 0.16767 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch5/10: 0.20848 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch5/10: 0.19001 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch5/10: 0.23309 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch5/10: 0.19492 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch5/10: 0.17771 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch5/10: 0.21657 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch5/10: 0.17543 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch5/10: 0.18941 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch5/10: 0.18958 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch5/10: 0.19312 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch5/10: 0.20651 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch5/10: 0.19543 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch5/10: 0.20383 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch5/10: 0.20586 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch5/10: 0.18915 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch5/10: 0.1966 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch5/10: 0.17069 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch5/10: 0.20624 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch5/10: 0.23708 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch5/10: 0.21912 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch5/10: 0.14978 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch5/10: 0.20195 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch5/10: 0.18891 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch5/10: 0.18353 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch5/10: 0.17955 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch5/10: 0.24691 in 0.09 secs
Val Loss for batch 040/271 @epoch5/10: 0.23223 in 0.09 secs
Val Loss for batch 060/271 @epoch5/10: 0.23947 in 0.09 secs
Val Loss for batch 080/271 @epoch5/10: 0.24439 in 0.09 secs
Val Loss for batch 100/271 @epoch5/10: 0.18749 in 0.09 secs
Val Loss for batch 120/271 @epoch5/10: 0.20226 in 0.09 secs
Val Loss for batch 140/271 @epoch5/10: 0.22255 in 0.09 secs
Val Loss for batch 160/271 @epoch5/10: 0.20541 in 0.08 secs
Val Loss for batch 180/271 @epoch5/10: 0.24873 in 0.09 secs
Val Loss for batch 200/271 @epoch5/10: 0.25549 in 0.08 secs
Val Loss for batch 220/271 @epoch5/10: 0.20338 in 0.09 secs
Val Loss for batch 240/271 @epoch5/10: 0.21869 in 0.09 secs
Val Loss for batch 260/271 @epoch5/10: 0.25314 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7344568378605425, 'Cardiomegaly': 0.8742647058823529, 'Consolidation': 0.7528577850527542, 'Edema': 0.8748448809547166, 'Effusion': 0.8673422147199247, 'Emphysema': 0.7981866186527871, 'Fibrosis': 0.7145358920289779, 'Hernia': 0.699681897050318, 'Infiltration': 0.5945698855782051, 'Mass': 0.7247337014025528, 'Nodule': 0.5849533953540079, 'Pleural_Thickening': 0.7015234613363618, 'Pneumonia': 0.5845560366338903, 'Pneumothorax': 0.7690283569425497, 'none': 0.725652670667359}
AVG Loss in validation set: 0.22258443084652646
0.7339668335321387
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch6/10: 0.20491 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch6/10: 0.19262 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch6/10: 0.16501 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch6/10: 0.21018 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch6/10: 0.1771 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch6/10: 0.20205 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch6/10: 0.1683 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch6/10: 0.2026 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch6/10: 0.19592 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch6/10: 0.21568 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch6/10: 0.19347 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch6/10: 0.21532 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch6/10: 0.21501 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch6/10: 0.19475 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch6/10: 0.19899 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch6/10: 0.20511 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch6/10: 0.21293 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch6/10: 0.19057 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch6/10: 0.17118 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch6/10: 0.21776 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch6/10: 0.21649 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch6/10: 0.19702 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch6/10: 0.17813 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch6/10: 0.19665 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch6/10: 0.16376 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch6/10: 0.19808 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch6/10: 0.16104 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch6/10: 0.20791 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch6/10: 0.1874 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch6/10: 0.19196 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch6/10: 0.17008 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch6/10: 0.18754 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch6/10: 0.19579 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch6/10: 0.22055 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch6/10: 0.18045 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch6/10: 0.2093 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch6/10: 0.19886 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch6/10: 0.19621 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch6/10: 0.20073 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch6/10: 0.19109 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch6/10: 0.17316 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch6/10: 0.18993 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch6/10: 0.18942 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch6/10: 0.20868 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch6/10: 0.19194 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch6/10: 0.17413 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch6/10: 0.17886 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch6/10: 0.19776 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch6/10: 0.14766 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch6/10: 0.18409 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch6/10: 0.15689 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch6/10: 0.20222 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch6/10: 0.22184 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch6/10: 0.18028 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch6/10: 0.24836 in 0.09 secs
Val Loss for batch 040/271 @epoch6/10: 0.23452 in 0.09 secs
Val Loss for batch 060/271 @epoch6/10: 0.23715 in 0.09 secs
Val Loss for batch 080/271 @epoch6/10: 0.24208 in 0.09 secs
Val Loss for batch 100/271 @epoch6/10: 0.18968 in 0.09 secs
Val Loss for batch 120/271 @epoch6/10: 0.20187 in 0.09 secs
Val Loss for batch 140/271 @epoch6/10: 0.22033 in 0.09 secs
Val Loss for batch 160/271 @epoch6/10: 0.19821 in 0.09 secs
Val Loss for batch 180/271 @epoch6/10: 0.24975 in 0.09 secs
Val Loss for batch 200/271 @epoch6/10: 0.24776 in 0.09 secs
Val Loss for batch 220/271 @epoch6/10: 0.19658 in 0.08 secs
Val Loss for batch 240/271 @epoch6/10: 0.21637 in 0.09 secs
Val Loss for batch 260/271 @epoch6/10: 0.25246 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7360487785374993, 'Cardiomegaly': 0.8798072755417957, 'Consolidation': 0.7512281626515248, 'Edema': 0.8696514177707891, 'Effusion': 0.8657393432296151, 'Emphysema': 0.8053979207014464, 'Fibrosis': 0.7106910197223958, 'Hernia': 0.7347558456581013, 'Infiltration': 0.5962218218870456, 'Mass': 0.71551397970678, 'Nodule': 0.5901114524396771, 'Pleural_Thickening': 0.7027848683597193, 'Pneumonia': 0.5802161405528055, 'Pneumothorax': 0.7687468205089352, 'none': 0.7279688143306324}
AVG Loss in validation set: 0.22021917756293805
0.736208203376295
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch7/10: 0.16789 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch7/10: 0.20312 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch7/10: 0.19979 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch7/10: 0.19266 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch7/10: 0.20888 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch7/10: 0.19285 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch7/10: 0.19651 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch7/10: 0.16534 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch7/10: 0.218 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch7/10: 0.18414 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch7/10: 0.18392 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch7/10: 0.16431 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch7/10: 0.22272 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch7/10: 0.19309 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch7/10: 0.21616 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch7/10: 0.19458 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch7/10: 0.1711 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch7/10: 0.20116 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch7/10: 0.1891 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch7/10: 0.19895 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch7/10: 0.20455 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch7/10: 0.19077 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch7/10: 0.21781 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch7/10: 0.19766 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch7/10: 0.20313 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch7/10: 0.18726 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch7/10: 0.19856 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch7/10: 0.18424 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch7/10: 0.1845 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch7/10: 0.23753 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch7/10: 0.20755 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch7/10: 0.21009 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch7/10: 0.21618 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch7/10: 0.1727 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch7/10: 0.20439 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch7/10: 0.19301 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch7/10: 0.19228 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch7/10: 0.2121 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch7/10: 0.20292 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch7/10: 0.19734 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch7/10: 0.20032 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch7/10: 0.19287 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch7/10: 0.18799 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch7/10: 0.22004 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch7/10: 0.1678 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch7/10: 0.18206 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch7/10: 0.19708 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch7/10: 0.20803 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch7/10: 0.18846 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch7/10: 0.18834 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch7/10: 0.18855 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch7/10: 0.21202 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch7/10: 0.15523 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch7/10: 0.20149 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch7/10: 0.25503 in 0.09 secs
Val Loss for batch 040/271 @epoch7/10: 0.23351 in 0.09 secs
Val Loss for batch 060/271 @epoch7/10: 0.23774 in 0.09 secs
Val Loss for batch 080/271 @epoch7/10: 0.24082 in 0.09 secs
Val Loss for batch 100/271 @epoch7/10: 0.19065 in 0.09 secs
Val Loss for batch 120/271 @epoch7/10: 0.19712 in 0.09 secs
Val Loss for batch 140/271 @epoch7/10: 0.21715 in 0.09 secs
Val Loss for batch 160/271 @epoch7/10: 0.19321 in 0.09 secs
Val Loss for batch 180/271 @epoch7/10: 0.25052 in 0.09 secs
Val Loss for batch 200/271 @epoch7/10: 0.25024 in 0.09 secs
Val Loss for batch 220/271 @epoch7/10: 0.19658 in 0.09 secs
Val Loss for batch 240/271 @epoch7/10: 0.2171 in 0.09 secs
Val Loss for batch 260/271 @epoch7/10: 0.25358 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7376863234490422, 'Cardiomegaly': 0.8750568885448915, 'Consolidation': 0.7558149908520664, 'Edema': 0.8696248833278676, 'Effusion': 0.8670025450559793, 'Emphysema': 0.8003833671246141, 'Fibrosis': 0.7116428187096083, 'Hernia': 0.7368916797488225, 'Infiltration': 0.5993851127946146, 'Mass': 0.7120405634573226, 'Nodule': 0.5871507293916326, 'Pleural_Thickening': 0.7043586641467219, 'Pneumonia': 0.5887223848296967, 'Pneumothorax': 0.7690680638152387, 'none': 0.726550729115183}
AVG Loss in validation set: 0.22077277512171176
0.7367735010891514
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch8/10: 0.20405 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch8/10: 0.1997 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch8/10: 0.19275 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch8/10: 0.19034 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch8/10: 0.19564 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch8/10: 0.18539 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch8/10: 0.20992 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch8/10: 0.17357 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch8/10: 0.19917 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch8/10: 0.18264 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch8/10: 0.16181 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch8/10: 0.17317 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch8/10: 0.19206 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch8/10: 0.21055 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch8/10: 0.18649 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch8/10: 0.22257 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch8/10: 0.19311 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch8/10: 0.18636 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch8/10: 0.18838 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch8/10: 0.23028 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch8/10: 0.1833 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch8/10: 0.22207 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch8/10: 0.18727 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch8/10: 0.19088 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch8/10: 0.21922 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch8/10: 0.17937 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch8/10: 0.17528 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch8/10: 0.20691 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch8/10: 0.19224 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch8/10: 0.2064 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch8/10: 0.2092 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch8/10: 0.19563 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch8/10: 0.19428 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch8/10: 0.17944 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch8/10: 0.19643 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch8/10: 0.17974 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch8/10: 0.1994 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch8/10: 0.21854 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch8/10: 0.19335 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch8/10: 0.19195 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch8/10: 0.18209 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch8/10: 0.2242 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch8/10: 0.18665 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch8/10: 0.17934 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch8/10: 0.21942 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch8/10: 0.20254 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch8/10: 0.20838 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch8/10: 0.19376 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch8/10: 0.19618 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch8/10: 0.1798 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch8/10: 0.21902 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch8/10: 0.17603 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch8/10: 0.21669 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch8/10: 0.19533 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch8/10: 0.25154 in 0.09 secs
Val Loss for batch 040/271 @epoch8/10: 0.23548 in 0.08 secs
Val Loss for batch 060/271 @epoch8/10: 0.23684 in 0.09 secs
Val Loss for batch 080/271 @epoch8/10: 0.23672 in 0.09 secs
Val Loss for batch 100/271 @epoch8/10: 0.18514 in 0.09 secs
Val Loss for batch 120/271 @epoch8/10: 0.20337 in 0.09 secs
Val Loss for batch 140/271 @epoch8/10: 0.22917 in 0.09 secs
Val Loss for batch 160/271 @epoch8/10: 0.20101 in 0.09 secs
Val Loss for batch 180/271 @epoch8/10: 0.24438 in 0.09 secs
Val Loss for batch 200/271 @epoch8/10: 0.24972 in 0.09 secs
Val Loss for batch 220/271 @epoch8/10: 0.19443 in 0.09 secs
Val Loss for batch 240/271 @epoch8/10: 0.2217 in 0.09 secs
Val Loss for batch 260/271 @epoch8/10: 0.25711 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7361349845013466, 'Cardiomegaly': 0.8754953560371517, 'Consolidation': 0.751588282152404, 'Edema': 0.8687817607471501, 'Effusion': 0.8679279759582308, 'Emphysema': 0.794639243403135, 'Fibrosis': 0.7183007020753787, 'Hernia': 0.6811823514831034, 'Infiltration': 0.5905219039426586, 'Mass': 0.7221656630373984, 'Nodule': 0.594567276955521, 'Pleural_Thickening': 0.699492603312089, 'Pneumonia': 0.5869764151721016, 'Pneumothorax': 0.7701557968269326, 'none': 0.7288715403424526}
AVG Loss in validation set: 0.2210306142746603
0.7327093082574715
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch9/10: 0.18161 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch9/10: 0.19471 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch9/10: 0.20796 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch9/10: 0.1826 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch9/10: 0.16095 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch9/10: 0.18567 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch9/10: 0.18983 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch9/10: 0.20272 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch9/10: 0.17357 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch9/10: 0.21095 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch9/10: 0.17406 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch9/10: 0.18483 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch9/10: 0.21182 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch9/10: 0.18315 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch9/10: 0.19345 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch9/10: 0.17235 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch9/10: 0.18526 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch9/10: 0.18613 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch9/10: 0.17475 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch9/10: 0.1816 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch9/10: 0.21157 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch9/10: 0.17934 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch9/10: 0.18826 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch9/10: 0.17223 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch9/10: 0.21194 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch9/10: 0.18927 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch9/10: 0.19315 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch9/10: 0.16654 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch9/10: 0.2086 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch9/10: 0.18448 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch9/10: 0.25777 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch9/10: 0.19864 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch9/10: 0.20647 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch9/10: 0.19875 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch9/10: 0.18874 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch9/10: 0.19124 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch9/10: 0.17404 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch9/10: 0.18352 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch9/10: 0.19374 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch9/10: 0.17026 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch9/10: 0.18711 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch9/10: 0.17868 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch9/10: 0.18023 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch9/10: 0.19756 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch9/10: 0.18587 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch9/10: 0.17676 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch9/10: 0.21394 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch9/10: 0.18159 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch9/10: 0.16743 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch9/10: 0.20376 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch9/10: 0.19791 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch9/10: 0.18227 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch9/10: 0.17876 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch9/10: 0.20729 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch9/10: 0.2466 in 0.09 secs
Val Loss for batch 040/271 @epoch9/10: 0.23549 in 0.09 secs
Val Loss for batch 060/271 @epoch9/10: 0.23156 in 0.09 secs
Val Loss for batch 080/271 @epoch9/10: 0.23305 in 0.09 secs
Val Loss for batch 100/271 @epoch9/10: 0.18214 in 0.09 secs
Val Loss for batch 120/271 @epoch9/10: 0.20172 in 0.09 secs
Val Loss for batch 140/271 @epoch9/10: 0.22202 in 0.09 secs
Val Loss for batch 160/271 @epoch9/10: 0.19726 in 0.09 secs
Val Loss for batch 180/271 @epoch9/10: 0.24116 in 0.09 secs
Val Loss for batch 200/271 @epoch9/10: 0.24946 in 0.09 secs
Val Loss for batch 220/271 @epoch9/10: 0.19306 in 0.09 secs
Val Loss for batch 240/271 @epoch9/10: 0.2141 in 0.09 secs
Val Loss for batch 260/271 @epoch9/10: 0.25771 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7448397121674772, 'Cardiomegaly': 0.87406201625387, 'Consolidation': 0.7577895236255949, 'Edema': 0.8743740814551338, 'Effusion': 0.8677022865295207, 'Emphysema': 0.7947985856835926, 'Fibrosis': 0.7163321123838655, 'Hernia': 0.7245806824754193, 'Infiltration': 0.5931161520954545, 'Mass': 0.7201198006128932, 'Nodule': 0.5938709339960598, 'Pleural_Thickening': 0.6993767321089566, 'Pneumonia': 0.5866712826207829, 'Pneumothorax': 0.7643320045158774, 'none': 0.7285730007624053}
AVG Loss in validation set: 0.2184265997334867
0.7365689933231785
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch10/10: 0.18632 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch10/10: 0.1857 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch10/10: 0.19045 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch10/10: 0.20197 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch10/10: 0.18853 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch10/10: 0.20463 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch10/10: 0.18532 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch10/10: 0.16169 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch10/10: 0.17412 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch10/10: 0.17761 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch10/10: 0.19497 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch10/10: 0.2065 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch10/10: 0.19836 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch10/10: 0.16695 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch10/10: 0.17056 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch10/10: 0.21686 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch10/10: 0.17732 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch10/10: 0.17446 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch10/10: 0.21111 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch10/10: 0.19315 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch10/10: 0.18046 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch10/10: 0.1773 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch10/10: 0.18591 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch10/10: 0.17636 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch10/10: 0.21046 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch10/10: 0.18987 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch10/10: 0.19899 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch10/10: 0.1976 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch10/10: 0.2247 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch10/10: 0.19355 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch10/10: 0.17966 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch10/10: 0.17532 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch10/10: 0.18678 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch10/10: 0.18281 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch10/10: 0.19479 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch10/10: 0.18225 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch10/10: 0.18751 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch10/10: 0.1758 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch10/10: 0.21493 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch10/10: 0.18634 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch10/10: 0.19827 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch10/10: 0.16877 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch10/10: 0.19485 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch10/10: 0.19858 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch10/10: 0.1877 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch10/10: 0.18754 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch10/10: 0.19044 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch10/10: 0.19586 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch10/10: 0.19539 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch10/10: 0.18106 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch10/10: 0.20304 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch10/10: 0.17748 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch10/10: 0.20623 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch10/10: 0.20693 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch10/10: 0.25289 in 0.09 secs
Val Loss for batch 040/271 @epoch10/10: 0.23622 in 0.09 secs
Val Loss for batch 060/271 @epoch10/10: 0.2353 in 0.09 secs
Val Loss for batch 080/271 @epoch10/10: 0.24623 in 0.09 secs
Val Loss for batch 100/271 @epoch10/10: 0.18852 in 0.09 secs
Val Loss for batch 120/271 @epoch10/10: 0.20759 in 0.09 secs
Val Loss for batch 140/271 @epoch10/10: 0.22437 in 0.09 secs
Val Loss for batch 160/271 @epoch10/10: 0.20351 in 0.09 secs
Val Loss for batch 180/271 @epoch10/10: 0.24435 in 0.09 secs
Val Loss for batch 200/271 @epoch10/10: 0.25495 in 0.09 secs
Val Loss for batch 220/271 @epoch10/10: 0.19803 in 0.09 secs
Val Loss for batch 240/271 @epoch10/10: 0.21637 in 0.09 secs
Val Loss for batch 260/271 @epoch10/10: 0.26088 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.733953291103657, 'Cardiomegaly': 0.8727111068111455, 'Consolidation': 0.7534261879554317, 'Edema': 0.8720565221006683, 'Effusion': 0.8661620734536811, 'Emphysema': 0.7917996883132603, 'Fibrosis': 0.7042610783209059, 'Hernia': 0.7573576799140709, 'Infiltration': 0.5992733356886664, 'Mass': 0.7128890589614598, 'Nodule': 0.5906612873618576, 'Pleural_Thickening': 0.6996163537570345, 'Pneumonia': 0.5842185324563021, 'Pneumothorax': 0.7632276240301523, 'none': 0.7261119370960532}
AVG Loss in validation set: 0.22211761263526814
0.7358295585877352
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/0/ft_resnet_50_adam_exponential/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch1/10: 0.28548 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch1/10: 0.26573 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch1/10: 0.25157 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch1/10: 0.26341 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch1/10: 0.26334 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch1/10: 0.26847 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch1/10: 0.25503 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch1/10: 0.25771 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch1/10: 0.26303 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch1/10: 0.26589 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch1/10: 0.25564 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch1/10: 0.24065 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch1/10: 0.23087 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch1/10: 0.21977 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch1/10: 0.23734 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch1/10: 0.29294 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch1/10: 0.23619 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch1/10: 0.20953 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch1/10: 0.22305 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch1/10: 0.21536 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch1/10: 0.27425 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch1/10: 0.18741 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch1/10: 0.30291 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch1/10: 0.25489 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch1/10: 0.22532 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch1/10: 0.25846 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch1/10: 0.22801 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch1/10: 0.2264 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch1/10: 0.233 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch1/10: 0.25095 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch1/10: 0.22257 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch1/10: 0.22579 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch1/10: 0.2356 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch1/10: 0.16978 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch1/10: 0.16979 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch1/10: 0.20357 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch1/10: 0.20425 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch1/10: 0.20531 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch1/10: 0.21919 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch1/10: 0.20957 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch1/10: 0.22883 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch1/10: 0.21045 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch1/10: 0.19824 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch1/10: 0.20474 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch1/10: 0.2353 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch1/10: 0.2482 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch1/10: 0.20972 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch1/10: 0.18458 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch1/10: 0.17195 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch1/10: 0.23077 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch1/10: 0.21796 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch1/10: 0.30266 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch1/10: 0.22142 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch1/10: 0.218 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch1/10: 0.2629 in 0.05 secs
Val Loss for batch 160/1082 @epoch1/10: 0.26431 in 0.05 secs
Val Loss for batch 240/1082 @epoch1/10: 0.25003 in 0.05 secs
Val Loss for batch 320/1082 @epoch1/10: 0.25213 in 0.05 secs
Val Loss for batch 400/1082 @epoch1/10: 0.24928 in 0.05 secs
Val Loss for batch 480/1082 @epoch1/10: 0.22854 in 0.05 secs
Val Loss for batch 560/1082 @epoch1/10: 0.20576 in 0.05 secs
Val Loss for batch 640/1082 @epoch1/10: 0.208 in 0.05 secs
Val Loss for batch 720/1082 @epoch1/10: 0.2167 in 0.05 secs
Val Loss for batch 800/1082 @epoch1/10: 0.18096 in 0.05 secs
Val Loss for batch 880/1082 @epoch1/10: 0.2251 in 0.05 secs
Val Loss for batch 960/1082 @epoch1/10: 0.24641 in 0.05 secs
Val Loss for batch 1040/1082 @epoch1/10: 0.26169 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7422450212371862, 'Cardiomegaly': 0.87143653250774, 'Consolidation': 0.7633160514080795, 'Edema': 0.8408366945184885, 'Effusion': 0.8686368015988134, 'Emphysema': 0.860505762800339, 'Fibrosis': 0.7147475860639863, 'Hernia': 0.7189952904238618, 'Infiltration': 0.6551103404480347, 'Mass': 0.7185740650246046, 'Nodule': 0.6300309131321947, 'Pleural_Thickening': 0.6891174295714964, 'Pneumonia': 0.5990342464829577, 'Pneumothorax': 0.7842991495787894, 'none': 0.731125727731657}
AVG Loss in validation set: 0.23945789063246892
0.7469204203426123
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch2/10: 0.18158 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch2/10: 0.23562 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch2/10: 0.18845 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch2/10: 0.16627 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch2/10: 0.21953 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch2/10: 0.24115 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch2/10: 0.2173 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch2/10: 0.20836 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch2/10: 0.18704 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch2/10: 0.21992 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch2/10: 0.22388 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch2/10: 0.20449 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch2/10: 0.2446 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch2/10: 0.23135 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch2/10: 0.19649 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch2/10: 0.17057 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch2/10: 0.21629 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch2/10: 0.17999 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch2/10: 0.16235 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch2/10: 0.18652 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch2/10: 0.19758 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch2/10: 0.22198 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch2/10: 0.21702 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch2/10: 0.24624 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch2/10: 0.16904 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch2/10: 0.17873 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch2/10: 0.19315 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch2/10: 0.2135 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch2/10: 0.17193 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch2/10: 0.20417 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch2/10: 0.18042 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch2/10: 0.19902 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch2/10: 0.18108 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch2/10: 0.16333 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch2/10: 0.15048 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch2/10: 0.21576 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch2/10: 0.22093 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch2/10: 0.17016 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch2/10: 0.22997 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch2/10: 0.14147 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch2/10: 0.21795 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch2/10: 0.28603 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch2/10: 0.16805 in 0 mins 0.19 secs
Train Loss for batch 3520/4327 @epoch2/10: 0.22969 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch2/10: 0.21862 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch2/10: 0.28687 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch2/10: 0.19524 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch2/10: 0.19452 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch2/10: 0.21495 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch2/10: 0.17651 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch2/10: 0.1531 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch2/10: 0.18335 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch2/10: 0.18957 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch2/10: 0.19491 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch2/10: 0.20985 in 0.05 secs
Val Loss for batch 160/1082 @epoch2/10: 0.24311 in 0.05 secs
Val Loss for batch 240/1082 @epoch2/10: 0.2245 in 0.05 secs
Val Loss for batch 320/1082 @epoch2/10: 0.24575 in 0.05 secs
Val Loss for batch 400/1082 @epoch2/10: 0.20962 in 0.05 secs
Val Loss for batch 480/1082 @epoch2/10: 0.18384 in 0.05 secs
Val Loss for batch 560/1082 @epoch2/10: 0.16491 in 0.05 secs
Val Loss for batch 640/1082 @epoch2/10: 0.19245 in 0.05 secs
Val Loss for batch 720/1082 @epoch2/10: 0.19497 in 0.05 secs
Val Loss for batch 800/1082 @epoch2/10: 0.14979 in 0.05 secs
Val Loss for batch 880/1082 @epoch2/10: 0.18109 in 0.05 secs
Val Loss for batch 960/1082 @epoch2/10: 0.22782 in 0.05 secs
Val Loss for batch 1040/1082 @epoch2/10: 0.20274 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7526857151986853, 'Cardiomegaly': 0.8672401315789473, 'Consolidation': 0.7300721627217521, 'Edema': 0.8601251790374163, 'Effusion': 0.848838380754671, 'Emphysema': 0.8360758015342249, 'Fibrosis': 0.7061922271319225, 'Hernia': 0.7565190448649096, 'Infiltration': 0.5454774449470663, 'Mass': 0.758655997198399, 'Nodule': 0.6450903921480861, 'Pleural_Thickening': 0.7001645238660249, 'Pneumonia': 0.5741732871138447, 'Pneumothorax': 0.7702236808729819, 'none': 0.7372041124915453}
AVG Loss in validation set: 0.21733537073136477
0.7393952834977808
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch3/10: 0.16067 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch3/10: 0.14127 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch3/10: 0.15954 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch3/10: 0.18185 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch3/10: 0.10222 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch3/10: 0.16027 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch3/10: 0.16366 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch3/10: 0.16247 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch3/10: 0.1447 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch3/10: 0.16014 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch3/10: 0.17328 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch3/10: 0.17522 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch3/10: 0.18573 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch3/10: 0.14242 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch3/10: 0.15621 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch3/10: 0.14769 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch3/10: 0.16142 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch3/10: 0.11812 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch3/10: 0.17106 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch3/10: 0.15975 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch3/10: 0.14586 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch3/10: 0.12484 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch3/10: 0.14989 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch3/10: 0.14994 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch3/10: 0.08901 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch3/10: 0.15428 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch3/10: 0.11109 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch3/10: 0.11677 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch3/10: 0.1366 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch3/10: 0.13465 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch3/10: 0.1126 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch3/10: 0.12228 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch3/10: 0.11403 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch3/10: 0.13392 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch3/10: 0.17301 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch3/10: 0.12513 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch3/10: 0.12722 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch3/10: 0.10987 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch3/10: 0.15097 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch3/10: 0.15669 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch3/10: 0.12221 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch3/10: 0.08829 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch3/10: 0.17429 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch3/10: 0.12055 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch3/10: 0.19174 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch3/10: 0.15371 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch3/10: 0.09812 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch3/10: 0.15943 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch3/10: 0.07846 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch3/10: 0.10206 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch3/10: 0.17523 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch3/10: 0.08097 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch3/10: 0.12791 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch3/10: 0.15957 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch3/10: 0.23715 in 0.05 secs
Val Loss for batch 160/1082 @epoch3/10: 0.23865 in 0.05 secs
Val Loss for batch 240/1082 @epoch3/10: 0.25241 in 0.05 secs
Val Loss for batch 320/1082 @epoch3/10: 0.21621 in 0.05 secs
Val Loss for batch 400/1082 @epoch3/10: 0.205 in 0.05 secs
Val Loss for batch 480/1082 @epoch3/10: 0.19609 in 0.05 secs
Val Loss for batch 560/1082 @epoch3/10: 0.14257 in 0.05 secs
Val Loss for batch 640/1082 @epoch3/10: 0.191 in 0.05 secs
Val Loss for batch 720/1082 @epoch3/10: 0.1937 in 0.05 secs
Val Loss for batch 800/1082 @epoch3/10: 0.16294 in 0.05 secs
Val Loss for batch 880/1082 @epoch3/10: 0.2205 in 0.05 secs
Val Loss for batch 960/1082 @epoch3/10: 0.2701 in 0.05 secs
Val Loss for batch 1040/1082 @epoch3/10: 0.22223 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7503554396370369, 'Cardiomegaly': 0.866313660990712, 'Consolidation': 0.7018282495374996, 'Edema': 0.8592375832354642, 'Effusion': 0.8599622411384695, 'Emphysema': 0.8353597069236821, 'Fibrosis': 0.7112747677900108, 'Hernia': 0.7564736015863835, 'Infiltration': 0.6103718365989467, 'Mass': 0.7739196513397381, 'Nodule': 0.6484983435550439, 'Pleural_Thickening': 0.6713408006475016, 'Pneumonia': 0.6259142361719952, 'Pneumothorax': 0.7426806409759867, 'none': 0.7323766212147986}
AVG Loss in validation set: 0.22069061842716461
0.7438236257234622
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch4/10: 0.18585 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch4/10: 0.09878 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch4/10: 0.13662 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch4/10: 0.1284 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch4/10: 0.09266 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch4/10: 0.07843 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch4/10: 0.15224 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch4/10: 0.1697 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch4/10: 0.10714 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch4/10: 0.13609 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch4/10: 0.16686 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch4/10: 0.12614 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch4/10: 0.103 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch4/10: 0.10471 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch4/10: 0.09968 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch4/10: 0.17054 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch4/10: 0.10534 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch4/10: 0.09245 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch4/10: 0.15639 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch4/10: 0.13277 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch4/10: 0.12901 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch4/10: 0.12791 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch4/10: 0.0901 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch4/10: 0.18253 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch4/10: 0.20844 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch4/10: 0.10402 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch4/10: 0.10519 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch4/10: 0.12245 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch4/10: 0.08879 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch4/10: 0.08473 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch4/10: 0.10938 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch4/10: 0.12874 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch4/10: 0.09648 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch4/10: 0.08251 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch4/10: 0.19613 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch4/10: 0.09108 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch4/10: 0.206 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch4/10: 0.07847 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch4/10: 0.11916 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch4/10: 0.12093 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch4/10: 0.0555 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch4/10: 0.09516 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch4/10: 0.08042 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch4/10: 0.1268 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch4/10: 0.10066 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch4/10: 0.1164 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch4/10: 0.06608 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch4/10: 0.0971 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch4/10: 0.13137 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch4/10: 0.0532 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch4/10: 0.19411 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch4/10: 0.14752 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch4/10: 0.10469 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch4/10: 0.08879 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch4/10: 0.21705 in 0.05 secs
Val Loss for batch 160/1082 @epoch4/10: 0.24741 in 0.05 secs
Val Loss for batch 240/1082 @epoch4/10: 0.23963 in 0.05 secs
Val Loss for batch 320/1082 @epoch4/10: 0.1952 in 0.05 secs
Val Loss for batch 400/1082 @epoch4/10: 0.19594 in 0.05 secs
Val Loss for batch 480/1082 @epoch4/10: 0.1705 in 0.05 secs
Val Loss for batch 560/1082 @epoch4/10: 0.15106 in 0.05 secs
Val Loss for batch 640/1082 @epoch4/10: 0.19623 in 0.05 secs
Val Loss for batch 720/1082 @epoch4/10: 0.18627 in 0.05 secs
Val Loss for batch 800/1082 @epoch4/10: 0.14588 in 0.05 secs
Val Loss for batch 880/1082 @epoch4/10: 0.17069 in 0.05 secs
Val Loss for batch 960/1082 @epoch4/10: 0.24669 in 0.05 secs
Val Loss for batch 1040/1082 @epoch4/10: 0.22075 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.746827510009955, 'Cardiomegaly': 0.8573355263157895, 'Consolidation': 0.7100829785557412, 'Edema': 0.8737190357532931, 'Effusion': 0.8497600141772574, 'Emphysema': 0.8331309245067482, 'Fibrosis': 0.7156425172987465, 'Hernia': 0.7775179707510534, 'Infiltration': 0.617573761637197, 'Mass': 0.7519246641713114, 'Nodule': 0.6324094879903841, 'Pleural_Thickening': 0.686107824047393, 'Pneumonia': 0.5639550933606694, 'Pneumothorax': 0.7516438057043305, 'none': 0.7342292682559464}
AVG Loss in validation set: 0.2143636092550491
0.7405450795914192
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch5/10: 0.09163 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch5/10: 0.09383 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch5/10: 0.12191 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch5/10: 0.10449 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch5/10: 0.11771 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch5/10: 0.07758 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch5/10: 0.09576 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch5/10: 0.09893 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch5/10: 0.15132 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch5/10: 0.0681 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch5/10: 0.1151 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch5/10: 0.08304 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch5/10: 0.13034 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch5/10: 0.07112 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch5/10: 0.0947 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch5/10: 0.08551 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch5/10: 0.09607 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch5/10: 0.10402 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch5/10: 0.0733 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch5/10: 0.10003 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch5/10: 0.12678 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch5/10: 0.07122 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch5/10: 0.06648 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch5/10: 0.09466 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch5/10: 0.06377 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch5/10: 0.09996 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch5/10: 0.10292 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch5/10: 0.10015 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch5/10: 0.05528 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch5/10: 0.05713 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch5/10: 0.09644 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch5/10: 0.09651 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch5/10: 0.11023 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch5/10: 0.11403 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch5/10: 0.05613 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch5/10: 0.08677 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch5/10: 0.08156 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch5/10: 0.07957 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch5/10: 0.12475 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch5/10: 0.07398 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch5/10: 0.08747 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch5/10: 0.03497 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch5/10: 0.04887 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch5/10: 0.12434 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch5/10: 0.10568 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch5/10: 0.10094 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch5/10: 0.06827 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch5/10: 0.10937 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch5/10: 0.10707 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch5/10: 0.09135 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch5/10: 0.07431 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch5/10: 0.06023 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch5/10: 0.11428 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch5/10: 0.06873 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch5/10: 0.2497 in 0.05 secs
Val Loss for batch 160/1082 @epoch5/10: 0.27421 in 0.05 secs
Val Loss for batch 240/1082 @epoch5/10: 0.2669 in 0.05 secs
Val Loss for batch 320/1082 @epoch5/10: 0.22962 in 0.05 secs
Val Loss for batch 400/1082 @epoch5/10: 0.18466 in 0.05 secs
Val Loss for batch 480/1082 @epoch5/10: 0.20067 in 0.05 secs
Val Loss for batch 560/1082 @epoch5/10: 0.156 in 0.05 secs
Val Loss for batch 640/1082 @epoch5/10: 0.19708 in 0.05 secs
Val Loss for batch 720/1082 @epoch5/10: 0.21172 in 0.05 secs
Val Loss for batch 800/1082 @epoch5/10: 0.14916 in 0.05 secs
Val Loss for batch 880/1082 @epoch5/10: 0.27665 in 0.05 secs
Val Loss for batch 960/1082 @epoch5/10: 0.28468 in 0.05 secs
Val Loss for batch 1040/1082 @epoch5/10: 0.24579 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7259341393416447, 'Cardiomegaly': 0.8691282894736841, 'Consolidation': 0.7125571669292707, 'Edema': 0.8609007509060485, 'Effusion': 0.859590162591698, 'Emphysema': 0.8268930524874417, 'Fibrosis': 0.7266728597179688, 'Hernia': 0.6647277534495578, 'Infiltration': 0.6150881707861775, 'Mass': 0.7776120503885956, 'Nodule': 0.6550572365069505, 'Pleural_Thickening': 0.6793013509390466, 'Pneumonia': 0.6071097682880954, 'Pneumothorax': 0.7593250561072817, 'none': 0.7294627013320927}
AVG Loss in validation set: 0.22406665384907223
0.7385641291366758
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch6/10: 0.05215 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch6/10: 0.06567 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch6/10: 0.08875 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch6/10: 0.07998 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch6/10: 0.06321 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch6/10: 0.09619 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch6/10: 0.03918 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch6/10: 0.05511 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch6/10: 0.07442 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch6/10: 0.07922 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch6/10: 0.06111 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch6/10: 0.04823 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch6/10: 0.12693 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch6/10: 0.04935 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch6/10: 0.07929 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch6/10: 0.12618 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch6/10: 0.10465 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch6/10: 0.04367 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch6/10: 0.09285 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch6/10: 0.07425 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch6/10: 0.0355 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch6/10: 0.09767 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch6/10: 0.06158 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch6/10: 0.06635 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch6/10: 0.07591 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch6/10: 0.10163 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch6/10: 0.12854 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch6/10: 0.03028 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch6/10: 0.07306 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch6/10: 0.06102 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch6/10: 0.10484 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch6/10: 0.07088 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch6/10: 0.04646 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch6/10: 0.06934 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch6/10: 0.0558 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch6/10: 0.12421 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch6/10: 0.14643 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch6/10: 0.07084 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch6/10: 0.04778 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch6/10: 0.06048 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch6/10: 0.08734 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch6/10: 0.05865 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch6/10: 0.07962 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch6/10: 0.06618 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch6/10: 0.10762 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch6/10: 0.18571 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch6/10: 0.15446 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch6/10: 0.10775 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch6/10: 0.10358 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch6/10: 0.07536 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch6/10: 0.06717 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch6/10: 0.08728 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch6/10: 0.07341 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch6/10: 0.04275 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch6/10: 0.22949 in 0.05 secs
Val Loss for batch 160/1082 @epoch6/10: 0.26138 in 0.05 secs
Val Loss for batch 240/1082 @epoch6/10: 0.22149 in 0.05 secs
Val Loss for batch 320/1082 @epoch6/10: 0.21655 in 0.05 secs
Val Loss for batch 400/1082 @epoch6/10: 0.19392 in 0.05 secs
Val Loss for batch 480/1082 @epoch6/10: 0.22209 in 0.05 secs
Val Loss for batch 560/1082 @epoch6/10: 0.19592 in 0.05 secs
Val Loss for batch 640/1082 @epoch6/10: 0.19135 in 0.05 secs
Val Loss for batch 720/1082 @epoch6/10: 0.1867 in 0.05 secs
Val Loss for batch 800/1082 @epoch6/10: 0.15075 in 0.05 secs
Val Loss for batch 880/1082 @epoch6/10: 0.18054 in 0.05 secs
Val Loss for batch 960/1082 @epoch6/10: 0.29118 in 0.05 secs
Val Loss for batch 1040/1082 @epoch6/10: 0.25176 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.737714632200103, 'Cardiomegaly': 0.8626691176470589, 'Consolidation': 0.7121792353952556, 'Edema': 0.8682204264757681, 'Effusion': 0.8563159160563397, 'Emphysema': 0.8284051492616352, 'Fibrosis': 0.7201022206680725, 'Hernia': 0.7338056680161943, 'Infiltration': 0.6155193944055243, 'Mass': 0.7852203919310907, 'Nodule': 0.6683322909253583, 'Pleural_Thickening': 0.6936807686114312, 'Pneumonia': 0.6078162490577009, 'Pneumothorax': 0.7632133883809809, 'none': 0.730938792818698}
AVG Loss in validation set: 0.2254852926219937
0.7466567749308939
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch7/10: 0.09508 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch7/10: 0.02879 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch7/10: 0.06731 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch7/10: 0.08089 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch7/10: 0.07334 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch7/10: 0.06318 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch7/10: 0.057 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch7/10: 0.07984 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch7/10: 0.08856 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch7/10: 0.07295 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch7/10: 0.06344 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch7/10: 0.02397 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch7/10: 0.06014 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch7/10: 0.08709 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch7/10: 0.02192 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch7/10: 0.08534 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch7/10: 0.10668 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch7/10: 0.04583 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch7/10: 0.05815 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch7/10: 0.04991 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch7/10: 0.05486 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch7/10: 0.06192 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch7/10: 0.04231 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch7/10: 0.06966 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch7/10: 0.05079 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch7/10: 0.03354 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch7/10: 0.06318 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch7/10: 0.06391 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch7/10: 0.05249 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch7/10: 0.10972 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch7/10: 0.03473 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch7/10: 0.10701 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch7/10: 0.01618 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch7/10: 0.09621 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch7/10: 0.08607 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch7/10: 0.07692 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch7/10: 0.11735 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch7/10: 0.05967 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch7/10: 0.04118 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch7/10: 0.07718 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch7/10: 0.08354 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch7/10: 0.07992 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch7/10: 0.06057 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch7/10: 0.05909 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch7/10: 0.04312 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch7/10: 0.04631 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch7/10: 0.02768 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch7/10: 0.04529 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch7/10: 0.08046 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch7/10: 0.06913 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch7/10: 0.04846 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch7/10: 0.06363 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch7/10: 0.02723 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch7/10: 0.06445 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch7/10: 0.23974 in 0.05 secs
Val Loss for batch 160/1082 @epoch7/10: 0.2988 in 0.05 secs
Val Loss for batch 240/1082 @epoch7/10: 0.23583 in 0.05 secs
Val Loss for batch 320/1082 @epoch7/10: 0.20684 in 0.05 secs
Val Loss for batch 400/1082 @epoch7/10: 0.21417 in 0.05 secs
Val Loss for batch 480/1082 @epoch7/10: 0.20815 in 0.05 secs
Val Loss for batch 560/1082 @epoch7/10: 0.1485 in 0.05 secs
Val Loss for batch 640/1082 @epoch7/10: 0.20491 in 0.05 secs
Val Loss for batch 720/1082 @epoch7/10: 0.2216 in 0.05 secs
Val Loss for batch 800/1082 @epoch7/10: 0.20706 in 0.05 secs
Val Loss for batch 880/1082 @epoch7/10: 0.19525 in 0.05 secs
Val Loss for batch 960/1082 @epoch7/10: 0.2716 in 0.05 secs
Val Loss for batch 1040/1082 @epoch7/10: 0.23661 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7327480363324593, 'Cardiomegaly': 0.8492206849845202, 'Consolidation': 0.7122181768889024, 'Edema': 0.8656574235242787, 'Effusion': 0.8552911922299099, 'Emphysema': 0.8091531028717546, 'Fibrosis': 0.7015021092873399, 'Hernia': 0.7312195323473518, 'Infiltration': 0.6327501561985924, 'Mass': 0.7848372258980305, 'Nodule': 0.6585961919498513, 'Pleural_Thickening': 0.6895847546867585, 'Pneumonia': 0.5987596871342269, 'Pneumothorax': 0.7608112108207875, 'none': 0.726653531699655}
AVG Loss in validation set: 0.227409048773214
0.7415963917967688
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch8/10: 0.0371 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch8/10: 0.05762 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch8/10: 0.11588 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch8/10: 0.03299 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch8/10: 0.04935 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch8/10: 0.01918 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch8/10: 0.0401 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch8/10: 0.03122 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch8/10: 0.04514 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch8/10: 0.04078 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch8/10: 0.10551 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch8/10: 0.05216 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch8/10: 0.07072 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch8/10: 0.03026 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch8/10: 0.0928 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch8/10: 0.08421 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch8/10: 0.04938 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch8/10: 0.05074 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch8/10: 0.0385 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch8/10: 0.07498 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch8/10: 0.06747 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch8/10: 0.03727 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch8/10: 0.0912 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch8/10: 0.07057 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch8/10: 0.12988 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch8/10: 0.04328 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch8/10: 0.07116 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch8/10: 0.0449 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch8/10: 0.13913 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch8/10: 0.04392 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch8/10: 0.05643 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch8/10: 0.06605 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch8/10: 0.0302 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch8/10: 0.01378 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch8/10: 0.04843 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch8/10: 0.02136 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch8/10: 0.05156 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch8/10: 0.03988 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch8/10: 0.04292 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch8/10: 0.04215 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch8/10: 0.11975 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch8/10: 0.04517 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch8/10: 0.08989 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch8/10: 0.04196 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch8/10: 0.15636 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch8/10: 0.06649 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch8/10: 0.07235 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch8/10: 0.03235 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch8/10: 0.06764 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch8/10: 0.04124 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch8/10: 0.01913 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch8/10: 0.0649 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch8/10: 0.03085 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch8/10: 0.08217 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch8/10: 0.20828 in 0.05 secs
Val Loss for batch 160/1082 @epoch8/10: 0.3062 in 0.05 secs
Val Loss for batch 240/1082 @epoch8/10: 0.30485 in 0.05 secs
Val Loss for batch 320/1082 @epoch8/10: 0.18797 in 0.05 secs
Val Loss for batch 400/1082 @epoch8/10: 0.20627 in 0.05 secs
Val Loss for batch 480/1082 @epoch8/10: 0.1947 in 0.05 secs
Val Loss for batch 560/1082 @epoch8/10: 0.16606 in 0.05 secs
Val Loss for batch 640/1082 @epoch8/10: 0.24517 in 0.05 secs
Val Loss for batch 720/1082 @epoch8/10: 0.2002 in 0.05 secs
Val Loss for batch 800/1082 @epoch8/10: 0.13802 in 0.05 secs
Val Loss for batch 880/1082 @epoch8/10: 0.19597 in 0.05 secs
Val Loss for batch 960/1082 @epoch8/10: 0.30148 in 0.05 secs
Val Loss for batch 1040/1082 @epoch8/10: 0.28146 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7326154893309164, 'Cardiomegaly': 0.8372256191950463, 'Consolidation': 0.6970063433294396, 'Edema': 0.8499589370152676, 'Effusion': 0.8507355196888152, 'Emphysema': 0.8017295020577377, 'Fibrosis': 0.7037319609720029, 'Hernia': 0.7342477071800382, 'Infiltration': 0.6262516517398325, 'Mass': 0.7795586918431529, 'Nodule': 0.6629836651497365, 'Pleural_Thickening': 0.6963524937072005, 'Pneumonia': 0.6274629786991701, 'Pneumothorax': 0.7482833689499079, 'none': 0.7221322408217548}
AVG Loss in validation set: 0.2403541942037921
0.7391531377755903
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch9/10: 0.06665 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch9/10: 0.01767 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch9/10: 0.04008 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch9/10: 0.0444 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch9/10: 0.04201 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch9/10: 0.06713 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch9/10: 0.10599 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch9/10: 0.02866 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch9/10: 0.13498 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch9/10: 0.09088 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch9/10: 0.0355 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch9/10: 0.02144 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch9/10: 0.12484 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch9/10: 0.04328 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch9/10: 0.03348 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch9/10: 0.03723 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch9/10: 0.02637 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch9/10: 0.07891 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch9/10: 0.0788 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch9/10: 0.05184 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch9/10: 0.03551 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch9/10: 0.06307 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch9/10: 0.04524 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch9/10: 0.04071 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch9/10: 0.08086 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch9/10: 0.03201 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch9/10: 0.0457 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch9/10: 0.01542 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch9/10: 0.02328 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch9/10: 0.07661 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch9/10: 0.03911 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch9/10: 0.03611 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch9/10: 0.02738 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch9/10: 0.04172 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch9/10: 0.01916 in 0 mins 0.19 secs
Train Loss for batch 2880/4327 @epoch9/10: 0.06608 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch9/10: 0.0247 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch9/10: 0.04638 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch9/10: 0.03216 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch9/10: 0.09812 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch9/10: 0.02803 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch9/10: 0.00807 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch9/10: 0.03696 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch9/10: 0.05485 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch9/10: 0.04588 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch9/10: 0.04862 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch9/10: 0.0665 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch9/10: 0.01589 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch9/10: 0.03912 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch9/10: 0.0475 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch9/10: 0.0372 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch9/10: 0.05659 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch9/10: 0.04496 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch9/10: 0.03089 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch9/10: 0.24915 in 0.05 secs
Val Loss for batch 160/1082 @epoch9/10: 0.25964 in 0.05 secs
Val Loss for batch 240/1082 @epoch9/10: 0.28998 in 0.05 secs
Val Loss for batch 320/1082 @epoch9/10: 0.22131 in 0.05 secs
Val Loss for batch 400/1082 @epoch9/10: 0.23017 in 0.05 secs
Val Loss for batch 480/1082 @epoch9/10: 0.24585 in 0.05 secs
Val Loss for batch 560/1082 @epoch9/10: 0.13792 in 0.05 secs
Val Loss for batch 640/1082 @epoch9/10: 0.21803 in 0.05 secs
Val Loss for batch 720/1082 @epoch9/10: 0.18172 in 0.05 secs
Val Loss for batch 800/1082 @epoch9/10: 0.17128 in 0.05 secs
Val Loss for batch 880/1082 @epoch9/10: 0.20423 in 0.05 secs
Val Loss for batch 960/1082 @epoch9/10: 0.30803 in 0.05 secs
Val Loss for batch 1040/1082 @epoch9/10: 0.26386 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7294109581003726, 'Cardiomegaly': 0.8355711106811147, 'Consolidation': 0.7221980191794257, 'Edema': 0.8621498317772377, 'Effusion': 0.8492129164941667, 'Emphysema': 0.8091661055801004, 'Fibrosis': 0.7083926441621073, 'Hernia': 0.7353713955217716, 'Infiltration': 0.6338722616424959, 'Mass': 0.7834952470174815, 'Nodule': 0.6694193538199663, 'Pleural_Thickening': 0.6980167352447624, 'Pneumonia': 0.6203824347959014, 'Pneumothorax': 0.751316032823407, 'none': 0.7266570853354939}
AVG Loss in validation set: 0.23368978556168063
0.7434267890600222
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch10/10: 0.05079 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch10/10: 0.02566 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch10/10: 0.05952 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch10/10: 0.03058 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch10/10: 0.03696 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch10/10: 0.02292 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch10/10: 0.06638 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch10/10: 0.02033 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch10/10: 0.04891 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch10/10: 0.04097 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch10/10: 0.03648 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch10/10: 0.08952 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch10/10: 0.04337 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch10/10: 0.05923 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch10/10: 0.03861 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch10/10: 0.05151 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch10/10: 0.0159 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch10/10: 0.06879 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch10/10: 0.03822 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch10/10: 0.06679 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch10/10: 0.0772 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch10/10: 0.02792 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch10/10: 0.0402 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch10/10: 0.02433 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch10/10: 0.1036 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch10/10: 0.01727 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch10/10: 0.05373 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch10/10: 0.03811 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch10/10: 0.04353 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch10/10: 0.07531 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch10/10: 0.03775 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch10/10: 0.02471 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch10/10: 0.02637 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch10/10: 0.06168 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch10/10: 0.02837 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch10/10: 0.02647 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch10/10: 0.03267 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch10/10: 0.03199 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch10/10: 0.02272 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch10/10: 0.04721 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch10/10: 0.02733 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch10/10: 0.09932 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch10/10: 0.0441 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch10/10: 0.03953 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch10/10: 0.05186 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch10/10: 0.03503 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch10/10: 0.04498 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch10/10: 0.01213 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch10/10: 0.02679 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch10/10: 0.13048 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch10/10: 0.03871 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch10/10: 0.01394 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch10/10: 0.03564 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch10/10: 0.08083 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch10/10: 0.24768 in 0.05 secs
Val Loss for batch 160/1082 @epoch10/10: 0.33045 in 0.05 secs
Val Loss for batch 240/1082 @epoch10/10: 0.31315 in 0.05 secs
Val Loss for batch 320/1082 @epoch10/10: 0.19503 in 0.05 secs
Val Loss for batch 400/1082 @epoch10/10: 0.20877 in 0.05 secs
Val Loss for batch 480/1082 @epoch10/10: 0.21868 in 0.05 secs
Val Loss for batch 560/1082 @epoch10/10: 0.1564 in 0.05 secs
Val Loss for batch 640/1082 @epoch10/10: 0.24415 in 0.05 secs
Val Loss for batch 720/1082 @epoch10/10: 0.17146 in 0.05 secs
Val Loss for batch 800/1082 @epoch10/10: 0.14442 in 0.05 secs
Val Loss for batch 880/1082 @epoch10/10: 0.22309 in 0.05 secs
Val Loss for batch 960/1082 @epoch10/10: 0.33892 in 0.05 secs
Val Loss for batch 1040/1082 @epoch10/10: 0.25709 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7291855157383276, 'Cardiomegaly': 0.8311151315789476, 'Consolidation': 0.7082941196405175, 'Edema': 0.858540400090815, 'Effusion': 0.8414562292069374, 'Emphysema': 0.8062563358651575, 'Fibrosis': 0.7143319687427517, 'Hernia': 0.7518466495910104, 'Infiltration': 0.6411968592859958, 'Mass': 0.7930355425817763, 'Nodule': 0.6734699094712765, 'Pleural_Thickening': 0.7045555127678148, 'Pneumonia': 0.6201210638875025, 'Pneumothorax': 0.750016529824038, 'none': 0.7211483825701652}
AVG Loss in validation set: 0.24240265999865984
0.7445301263052049
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/0/ft_dense161_adam_steplr_0/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/10: 0.29634 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch1/10: 0.25636 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch1/10: 0.25799 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch1/10: 0.25691 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch1/10: 0.23414 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch1/10: 0.24361 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch1/10: 0.22921 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch1/10: 0.22972 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch1/10: 0.22385 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch1/10: 0.20553 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch1/10: 0.22917 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch1/10: 0.20995 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch1/10: 0.21136 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch1/10: 0.22027 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch1/10: 0.21469 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch1/10: 0.22506 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch1/10: 0.21265 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch1/10: 0.20113 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch1/10: 0.2192 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch1/10: 0.19761 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch1/10: 0.215 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch1/10: 0.20555 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch1/10: 0.21065 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch1/10: 0.19733 in 0 mins 0.24 secs
Train Loss for batch 250/541 @epoch1/10: 0.20557 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch1/10: 0.21269 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch1/10: 0.20259 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch1/10: 0.19635 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch1/10: 0.20452 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch1/10: 0.19739 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch1/10: 0.20325 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch1/10: 0.19376 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch1/10: 0.19971 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch1/10: 0.20928 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch1/10: 0.1882 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch1/10: 0.18237 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch1/10: 0.18704 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch1/10: 0.22239 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch1/10: 0.18847 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch1/10: 0.17589 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch1/10: 0.1735 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch1/10: 0.1741 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch1/10: 0.18276 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch1/10: 0.17339 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch1/10: 0.19263 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch1/10: 0.20984 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch1/10: 0.17748 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch1/10: 0.19326 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch1/10: 0.17716 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch1/10: 0.16996 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch1/10: 0.18116 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch1/10: 0.18946 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch1/10: 0.19652 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch1/10: 0.17042 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/10: 0.24898 in 0.08 secs
Val Loss for batch 020/136 @epoch1/10: 0.21769 in 0.09 secs
Val Loss for batch 030/136 @epoch1/10: 0.22285 in 0.09 secs
Val Loss for batch 040/136 @epoch1/10: 0.22187 in 0.09 secs
Val Loss for batch 050/136 @epoch1/10: 0.21284 in 0.09 secs
Val Loss for batch 060/136 @epoch1/10: 0.2322 in 0.08 secs
Val Loss for batch 070/136 @epoch1/10: 0.21118 in 0.08 secs
Val Loss for batch 080/136 @epoch1/10: 0.19266 in 0.09 secs
Val Loss for batch 090/136 @epoch1/10: 0.23312 in 0.09 secs
Val Loss for batch 100/136 @epoch1/10: 0.237 in 0.09 secs
Val Loss for batch 110/136 @epoch1/10: 0.20564 in 0.09 secs
Val Loss for batch 120/136 @epoch1/10: 0.23101 in 0.09 secs
Val Loss for batch 130/136 @epoch1/10: 0.23177 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7515956149977282, 'Cardiomegaly': 0.8382426470588236, 'Consolidation': 0.7471771755280425, 'Edema': 0.8673204977637258, 'Effusion': 0.8591391374211093, 'Emphysema': 0.833970663053017, 'Fibrosis': 0.7025762386985644, 'Hernia': 0.8266586796661984, 'Infiltration': 0.6111922379272212, 'Mass': 0.7322339520584958, 'Nodule': 0.6451708728778222, 'Pleural_Thickening': 0.6938216679944402, 'Pneumonia': 0.5886636363227631, 'Pneumothorax': 0.7213491089424818, 'none': 0.7137337282261044}
AVG Loss in validation set: 0.22407964264635571
0.7442222950221739
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/10: 0.16574 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch2/10: 0.17655 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch2/10: 0.17753 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch2/10: 0.15993 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch2/10: 0.1746 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch2/10: 0.17441 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch2/10: 0.16584 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch2/10: 0.16818 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch2/10: 0.19109 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch2/10: 0.16436 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch2/10: 0.15482 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch2/10: 0.15997 in 0 mins 0.24 secs
Train Loss for batch 130/541 @epoch2/10: 0.15142 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch2/10: 0.17157 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch2/10: 0.15758 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch2/10: 0.15835 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch2/10: 0.16214 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch2/10: 0.17641 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch2/10: 0.15908 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch2/10: 0.17436 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch2/10: 0.14481 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch2/10: 0.15502 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch2/10: 0.17792 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch2/10: 0.1593 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch2/10: 0.16408 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch2/10: 0.16077 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch2/10: 0.13553 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch2/10: 0.16092 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch2/10: 0.14987 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch2/10: 0.14032 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch2/10: 0.17332 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch2/10: 0.14868 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch2/10: 0.16682 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch2/10: 0.16123 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch2/10: 0.15077 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch2/10: 0.13916 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch2/10: 0.15926 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch2/10: 0.14814 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch2/10: 0.14057 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch2/10: 0.14142 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch2/10: 0.14401 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch2/10: 0.15409 in 0 mins 0.24 secs
Train Loss for batch 430/541 @epoch2/10: 0.15058 in 0 mins 0.24 secs
Train Loss for batch 440/541 @epoch2/10: 0.13412 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch2/10: 0.14293 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch2/10: 0.14926 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch2/10: 0.12928 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch2/10: 0.13564 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch2/10: 0.14334 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch2/10: 0.15477 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch2/10: 0.14969 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch2/10: 0.15464 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch2/10: 0.13293 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch2/10: 0.13763 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/10: 0.2404 in 0.09 secs
Val Loss for batch 020/136 @epoch2/10: 0.20993 in 0.09 secs
Val Loss for batch 030/136 @epoch2/10: 0.21903 in 0.09 secs
Val Loss for batch 040/136 @epoch2/10: 0.21141 in 0.09 secs
Val Loss for batch 050/136 @epoch2/10: 0.22247 in 0.09 secs
Val Loss for batch 060/136 @epoch2/10: 0.22755 in 0.09 secs
Val Loss for batch 070/136 @epoch2/10: 0.22818 in 0.08 secs
Val Loss for batch 080/136 @epoch2/10: 0.18421 in 0.09 secs
Val Loss for batch 090/136 @epoch2/10: 0.27291 in 0.09 secs
Val Loss for batch 100/136 @epoch2/10: 0.23604 in 0.09 secs
Val Loss for batch 110/136 @epoch2/10: 0.20841 in 0.09 secs
Val Loss for batch 120/136 @epoch2/10: 0.24679 in 0.09 secs
Val Loss for batch 130/136 @epoch2/10: 0.23484 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7626667021883324, 'Cardiomegaly': 0.8842830882352942, 'Consolidation': 0.7475942527050813, 'Edema': 0.8790930078939967, 'Effusion': 0.8652299783469198, 'Emphysema': 0.844496591871936, 'Fibrosis': 0.7165485159635905, 'Hernia': 0.7337932743947781, 'Infiltration': 0.6317260268948554, 'Mass': 0.7765995152931726, 'Nodule': 0.6134338956181491, 'Pleural_Thickening': 0.645947858223439, 'Pneumonia': 0.6505430490175361, 'Pneumothorax': 0.7822711578218187, 'none': 0.7155027144789052}
AVG Loss in validation set: 0.22371324442130683
0.7524447796049214
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/10: 0.14107 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch3/10: 0.15719 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch3/10: 0.13203 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch3/10: 0.12546 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch3/10: 0.12592 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch3/10: 0.11391 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch3/10: 0.13402 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch3/10: 0.13544 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch3/10: 0.12969 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch3/10: 0.11514 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch3/10: 0.12201 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch3/10: 0.12676 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch3/10: 0.14324 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch3/10: 0.12439 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch3/10: 0.13589 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch3/10: 0.13856 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch3/10: 0.13742 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch3/10: 0.11942 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch3/10: 0.1134 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch3/10: 0.11991 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch3/10: 0.13323 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch3/10: 0.10022 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch3/10: 0.13243 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch3/10: 0.12257 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch3/10: 0.13393 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch3/10: 0.10843 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch3/10: 0.10506 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch3/10: 0.12077 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch3/10: 0.10513 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch3/10: 0.1108 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch3/10: 0.09793 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch3/10: 0.09311 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch3/10: 0.10797 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch3/10: 0.11443 in 0 mins 0.24 secs
Train Loss for batch 350/541 @epoch3/10: 0.08555 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch3/10: 0.12689 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch3/10: 0.10934 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch3/10: 0.10428 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch3/10: 0.12191 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch3/10: 0.10891 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch3/10: 0.10242 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch3/10: 0.12578 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch3/10: 0.13021 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch3/10: 0.10991 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch3/10: 0.1154 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch3/10: 0.11418 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch3/10: 0.10382 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch3/10: 0.10442 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch3/10: 0.11077 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch3/10: 0.12108 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch3/10: 0.11443 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch3/10: 0.09006 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch3/10: 0.11285 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch3/10: 0.08518 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/10: 0.22938 in 0.09 secs
Val Loss for batch 020/136 @epoch3/10: 0.20016 in 0.08 secs
Val Loss for batch 030/136 @epoch3/10: 0.21368 in 0.09 secs
Val Loss for batch 040/136 @epoch3/10: 0.19346 in 0.09 secs
Val Loss for batch 050/136 @epoch3/10: 0.20433 in 0.09 secs
Val Loss for batch 060/136 @epoch3/10: 0.21909 in 0.09 secs
Val Loss for batch 070/136 @epoch3/10: 0.22852 in 0.09 secs
Val Loss for batch 080/136 @epoch3/10: 0.1818 in 0.09 secs
Val Loss for batch 090/136 @epoch3/10: 0.25386 in 0.09 secs
Val Loss for batch 100/136 @epoch3/10: 0.22925 in 0.09 secs
Val Loss for batch 110/136 @epoch3/10: 0.19267 in 0.09 secs
Val Loss for batch 120/136 @epoch3/10: 0.22798 in 0.09 secs
Val Loss for batch 130/136 @epoch3/10: 0.22254 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7533248725068862, 'Cardiomegaly': 0.8825942337461299, 'Consolidation': 0.7002175109536348, 'Edema': 0.8797423542964775, 'Effusion': 0.8725388981054298, 'Emphysema': 0.8354464704502813, 'Fibrosis': 0.7650394012284847, 'Hernia': 0.7376807403123193, 'Infiltration': 0.6448598904281907, 'Mass': 0.7833721455028302, 'Nodule': 0.6201917937289084, 'Pleural_Thickening': 0.706926965917181, 'Pneumonia': 0.6708270201168677, 'Pneumothorax': 0.7848122800239253, 'none': 0.7285795818226224}
AVG Loss in validation set: 0.21669804315516314
0.7598267555226819
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/10: 0.11278 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch4/10: 0.11559 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch4/10: 0.09118 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch4/10: 0.12282 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch4/10: 0.10627 in 0 mins 0.24 secs
Train Loss for batch 060/541 @epoch4/10: 0.11067 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch4/10: 0.10373 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch4/10: 0.11244 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch4/10: 0.10852 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch4/10: 0.09633 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch4/10: 0.09062 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch4/10: 0.10216 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch4/10: 0.0893 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch4/10: 0.10026 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch4/10: 0.08379 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch4/10: 0.10702 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch4/10: 0.09501 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch4/10: 0.11394 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch4/10: 0.09735 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch4/10: 0.09508 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch4/10: 0.09485 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch4/10: 0.10849 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch4/10: 0.09807 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch4/10: 0.09886 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch4/10: 0.1253 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch4/10: 0.08852 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch4/10: 0.1327 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch4/10: 0.08965 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch4/10: 0.09643 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch4/10: 0.08662 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch4/10: 0.1006 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch4/10: 0.11509 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch4/10: 0.09357 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch4/10: 0.12575 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch4/10: 0.11422 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch4/10: 0.09597 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch4/10: 0.09878 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch4/10: 0.08 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch4/10: 0.09099 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch4/10: 0.09732 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch4/10: 0.09634 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch4/10: 0.08637 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch4/10: 0.08213 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch4/10: 0.09011 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch4/10: 0.09774 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch4/10: 0.10853 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch4/10: 0.08088 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch4/10: 0.09425 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch4/10: 0.08517 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch4/10: 0.08857 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch4/10: 0.09492 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch4/10: 0.08739 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch4/10: 0.08251 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch4/10: 0.08988 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/10: 0.23155 in 0.09 secs
Val Loss for batch 020/136 @epoch4/10: 0.20935 in 0.09 secs
Val Loss for batch 030/136 @epoch4/10: 0.22371 in 0.09 secs
Val Loss for batch 040/136 @epoch4/10: 0.20535 in 0.09 secs
Val Loss for batch 050/136 @epoch4/10: 0.21804 in 0.09 secs
Val Loss for batch 060/136 @epoch4/10: 0.21611 in 0.09 secs
Val Loss for batch 070/136 @epoch4/10: 0.23287 in 0.09 secs
Val Loss for batch 080/136 @epoch4/10: 0.19448 in 0.09 secs
Val Loss for batch 090/136 @epoch4/10: 0.25384 in 0.09 secs
Val Loss for batch 100/136 @epoch4/10: 0.21945 in 0.09 secs
Val Loss for batch 110/136 @epoch4/10: 0.18728 in 0.08 secs
Val Loss for batch 120/136 @epoch4/10: 0.23114 in 0.09 secs
Val Loss for batch 130/136 @epoch4/10: 0.2259 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.707465316253927, 'Cardiomegaly': 0.8600561145510837, 'Consolidation': 0.6479014771024018, 'Edema': 0.880106548868689, 'Effusion': 0.847467993203256, 'Emphysema': 0.8230125714912546, 'Fibrosis': 0.7323525706461143, 'Hernia': 0.7372387011484756, 'Infiltration': 0.6339255602817017, 'Mass': 0.7605509633088537, 'Nodule': 0.6697612695784179, 'Pleural_Thickening': 0.6901322626745882, 'Pneumonia': 0.5914613840968391, 'Pneumothorax': 0.7753736916732512, 'none': 0.7252392324731571}
AVG Loss in validation set: 0.22175191219515455
0.7397718874913467
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/10: 0.10234 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch5/10: 0.07794 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch5/10: 0.08262 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch5/10: 0.07312 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch5/10: 0.08299 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch5/10: 0.08743 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch5/10: 0.10374 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch5/10: 0.08216 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch5/10: 0.0797 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch5/10: 0.08403 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch5/10: 0.0829 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch5/10: 0.06629 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch5/10: 0.09479 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch5/10: 0.06591 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch5/10: 0.08868 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch5/10: 0.0913 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch5/10: 0.09791 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch5/10: 0.0893 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch5/10: 0.10308 in 0 mins 0.24 secs
Train Loss for batch 200/541 @epoch5/10: 0.07895 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch5/10: 0.07416 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch5/10: 0.09362 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch5/10: 0.08007 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch5/10: 0.07507 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch5/10: 0.08741 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch5/10: 0.0887 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch5/10: 0.07316 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch5/10: 0.08281 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch5/10: 0.08461 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch5/10: 0.08026 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch5/10: 0.08572 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch5/10: 0.06175 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch5/10: 0.08816 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch5/10: 0.07276 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch5/10: 0.0945 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch5/10: 0.07188 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch5/10: 0.0986 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch5/10: 0.06499 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch5/10: 0.07711 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch5/10: 0.08279 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch5/10: 0.09174 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch5/10: 0.08232 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch5/10: 0.0583 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch5/10: 0.0767 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch5/10: 0.07206 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch5/10: 0.07757 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch5/10: 0.08111 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch5/10: 0.06714 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch5/10: 0.08238 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch5/10: 0.07198 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch5/10: 0.06753 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch5/10: 0.07096 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch5/10: 0.08448 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch5/10: 0.0965 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/10: 0.22184 in 0.09 secs
Val Loss for batch 020/136 @epoch5/10: 0.2033 in 0.09 secs
Val Loss for batch 030/136 @epoch5/10: 0.20143 in 0.09 secs
Val Loss for batch 040/136 @epoch5/10: 0.18379 in 0.09 secs
Val Loss for batch 050/136 @epoch5/10: 0.20604 in 0.09 secs
Val Loss for batch 060/136 @epoch5/10: 0.21456 in 0.08 secs
Val Loss for batch 070/136 @epoch5/10: 0.22048 in 0.08 secs
Val Loss for batch 080/136 @epoch5/10: 0.17749 in 0.08 secs
Val Loss for batch 090/136 @epoch5/10: 0.24586 in 0.09 secs
Val Loss for batch 100/136 @epoch5/10: 0.22068 in 0.09 secs
Val Loss for batch 110/136 @epoch5/10: 0.16805 in 0.09 secs
Val Loss for batch 120/136 @epoch5/10: 0.21737 in 0.09 secs
Val Loss for batch 130/136 @epoch5/10: 0.22867 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7559693752053112, 'Cardiomegaly': 0.8677534829721362, 'Consolidation': 0.7117432233635079, 'Edema': 0.8796220149919601, 'Effusion': 0.8664422306544473, 'Emphysema': 0.812210867048962, 'Fibrosis': 0.7166902732595584, 'Hernia': 0.7794224572420061, 'Infiltration': 0.6592677176596278, 'Mass': 0.7800815141744858, 'Nodule': 0.6715747601989428, 'Pleural_Thickening': 0.7203961656298732, 'Pneumonia': 0.6649680554993548, 'Pneumothorax': 0.7808177098064093, 'none': 0.7358368784381684}
AVG Loss in validation set: 0.20863956553319843
0.761925703407613
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch6/10: 0.06481 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch6/10: 0.0902 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch6/10: 0.07881 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch6/10: 0.07182 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch6/10: 0.08545 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch6/10: 0.0827 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch6/10: 0.06687 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch6/10: 0.06971 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch6/10: 0.07385 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch6/10: 0.07313 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch6/10: 0.06027 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch6/10: 0.07466 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch6/10: 0.06432 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch6/10: 0.07874 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch6/10: 0.07184 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch6/10: 0.07011 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch6/10: 0.04535 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch6/10: 0.0624 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch6/10: 0.07572 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch6/10: 0.05983 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch6/10: 0.07428 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch6/10: 0.07262 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch6/10: 0.06496 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch6/10: 0.06328 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch6/10: 0.05971 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch6/10: 0.07258 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch6/10: 0.08412 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch6/10: 0.06103 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch6/10: 0.0778 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch6/10: 0.06769 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch6/10: 0.06213 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch6/10: 0.05079 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch6/10: 0.08722 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch6/10: 0.07143 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch6/10: 0.06807 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch6/10: 0.07414 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch6/10: 0.07117 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch6/10: 0.06352 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch6/10: 0.04817 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch6/10: 0.08285 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch6/10: 0.05417 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch6/10: 0.05753 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch6/10: 0.06547 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch6/10: 0.08112 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch6/10: 0.09092 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch6/10: 0.07189 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch6/10: 0.06561 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch6/10: 0.07567 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch6/10: 0.05754 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch6/10: 0.0753 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch6/10: 0.06166 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch6/10: 0.0694 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch6/10: 0.0494 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch6/10: 0.07531 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch6/10: 0.23235 in 0.09 secs
Val Loss for batch 020/136 @epoch6/10: 0.20196 in 0.09 secs
Val Loss for batch 030/136 @epoch6/10: 0.2114 in 0.09 secs
Val Loss for batch 040/136 @epoch6/10: 0.18956 in 0.09 secs
Val Loss for batch 050/136 @epoch6/10: 0.21263 in 0.09 secs
Val Loss for batch 060/136 @epoch6/10: 0.21451 in 0.09 secs
Val Loss for batch 070/136 @epoch6/10: 0.21792 in 0.09 secs
Val Loss for batch 080/136 @epoch6/10: 0.18808 in 0.09 secs
Val Loss for batch 090/136 @epoch6/10: 0.26028 in 0.09 secs
Val Loss for batch 100/136 @epoch6/10: 0.20872 in 0.09 secs
Val Loss for batch 110/136 @epoch6/10: 0.19162 in 0.08 secs
Val Loss for batch 120/136 @epoch6/10: 0.23217 in 0.09 secs
Val Loss for batch 130/136 @epoch6/10: 0.22675 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7369711978623092, 'Cardiomegaly': 0.8689903250773995, 'Consolidation': 0.7267042083760856, 'Edema': 0.8766230623550064, 'Effusion': 0.8544868897599098, 'Emphysema': 0.8308976502451128, 'Fibrosis': 0.7198856993497296, 'Hernia': 0.7202429149797571, 'Infiltration': 0.6542828183453534, 'Mass': 0.7785345576260168, 'Nodule': 0.6609681449758471, 'Pleural_Thickening': 0.7136855014534884, 'Pneumonia': 0.6629499243912711, 'Pneumothorax': 0.7742848409866224, 'none': 0.7272829557797993}
AVG Loss in validation set: 0.21619549389520398
0.7556791239845649
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch7/10: 0.07547 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch7/10: 0.06715 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch7/10: 0.06577 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch7/10: 0.05918 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch7/10: 0.06861 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch7/10: 0.06482 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch7/10: 0.05407 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch7/10: 0.06975 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch7/10: 0.04944 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch7/10: 0.06914 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch7/10: 0.06413 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch7/10: 0.07101 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch7/10: 0.05896 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch7/10: 0.07384 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch7/10: 0.05038 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch7/10: 0.05462 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch7/10: 0.05223 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch7/10: 0.06529 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch7/10: 0.08824 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch7/10: 0.06375 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch7/10: 0.05431 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch7/10: 0.05369 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch7/10: 0.05949 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch7/10: 0.06447 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch7/10: 0.05897 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch7/10: 0.0598 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch7/10: 0.05262 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch7/10: 0.05763 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch7/10: 0.06205 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch7/10: 0.04823 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch7/10: 0.06303 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch7/10: 0.06947 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch7/10: 0.06773 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch7/10: 0.05032 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch7/10: 0.06785 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch7/10: 0.06242 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch7/10: 0.06566 in 0 mins 0.24 secs
Train Loss for batch 380/541 @epoch7/10: 0.05584 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch7/10: 0.03905 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch7/10: 0.06585 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch7/10: 0.03929 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch7/10: 0.05107 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch7/10: 0.07121 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch7/10: 0.06814 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch7/10: 0.03951 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch7/10: 0.07532 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch7/10: 0.04759 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch7/10: 0.05174 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch7/10: 0.04397 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch7/10: 0.06101 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch7/10: 0.04314 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch7/10: 0.0571 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch7/10: 0.05333 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch7/10: 0.05104 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch7/10: 0.22895 in 0.09 secs
Val Loss for batch 020/136 @epoch7/10: 0.20924 in 0.09 secs
Val Loss for batch 030/136 @epoch7/10: 0.20523 in 0.09 secs
Val Loss for batch 040/136 @epoch7/10: 0.1837 in 0.09 secs
Val Loss for batch 050/136 @epoch7/10: 0.19655 in 0.09 secs
Val Loss for batch 060/136 @epoch7/10: 0.20393 in 0.09 secs
Val Loss for batch 070/136 @epoch7/10: 0.22912 in 0.09 secs
Val Loss for batch 080/136 @epoch7/10: 0.18406 in 0.09 secs
Val Loss for batch 090/136 @epoch7/10: 0.26465 in 0.09 secs
Val Loss for batch 100/136 @epoch7/10: 0.20142 in 0.08 secs
Val Loss for batch 110/136 @epoch7/10: 0.17356 in 0.08 secs
Val Loss for batch 120/136 @epoch7/10: 0.22483 in 0.09 secs
Val Loss for batch 130/136 @epoch7/10: 0.23019 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7411800499001846, 'Cardiomegaly': 0.8596306114551083, 'Consolidation': 0.7139043486675374, 'Edema': 0.8813199390455262, 'Effusion': 0.8575652868660815, 'Emphysema': 0.8168237551443444, 'Fibrosis': 0.7228119749593509, 'Hernia': 0.7528133520614724, 'Infiltration': 0.6642217761616716, 'Mass': 0.7771700987139124, 'Nodule': 0.6592914524944347, 'Pleural_Thickening': 0.7393133644653874, 'Pneumonia': 0.6574575384675332, 'Pneumothorax': 0.7840078481957433, 'none': 0.7403387678311708}
AVG Loss in validation set: 0.21010848228103632
0.7591079568998778
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch8/10: 0.04866 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch8/10: 0.04332 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch8/10: 0.08698 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch8/10: 0.06258 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch8/10: 0.06021 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch8/10: 0.05043 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch8/10: 0.06683 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch8/10: 0.05417 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch8/10: 0.0504 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch8/10: 0.05873 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch8/10: 0.04721 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch8/10: 0.04622 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch8/10: 0.06113 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch8/10: 0.0563 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch8/10: 0.06783 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch8/10: 0.05702 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch8/10: 0.0574 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch8/10: 0.04181 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch8/10: 0.03741 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch8/10: 0.04217 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch8/10: 0.05324 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch8/10: 0.05491 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch8/10: 0.06239 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch8/10: 0.05656 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch8/10: 0.06874 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch8/10: 0.06086 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch8/10: 0.05529 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch8/10: 0.05088 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch8/10: 0.07904 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch8/10: 0.03464 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch8/10: 0.05979 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch8/10: 0.05152 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch8/10: 0.06009 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch8/10: 0.05155 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch8/10: 0.04836 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch8/10: 0.04287 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch8/10: 0.06019 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch8/10: 0.04393 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch8/10: 0.04574 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch8/10: 0.04839 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch8/10: 0.04615 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch8/10: 0.04622 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch8/10: 0.04829 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch8/10: 0.06261 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch8/10: 0.05201 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch8/10: 0.03529 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch8/10: 0.04202 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch8/10: 0.06618 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch8/10: 0.04973 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch8/10: 0.04315 in 0 mins 0.24 secs
Train Loss for batch 510/541 @epoch8/10: 0.05022 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch8/10: 0.04307 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch8/10: 0.05861 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch8/10: 0.0548 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch8/10: 0.24056 in 0.09 secs
Val Loss for batch 020/136 @epoch8/10: 0.20374 in 0.08 secs
Val Loss for batch 030/136 @epoch8/10: 0.21115 in 0.08 secs
Val Loss for batch 040/136 @epoch8/10: 0.19776 in 0.09 secs
Val Loss for batch 050/136 @epoch8/10: 0.21014 in 0.09 secs
Val Loss for batch 060/136 @epoch8/10: 0.22349 in 0.09 secs
Val Loss for batch 070/136 @epoch8/10: 0.24025 in 0.09 secs
Val Loss for batch 080/136 @epoch8/10: 0.19591 in 0.09 secs
Val Loss for batch 090/136 @epoch8/10: 0.27144 in 0.09 secs
Val Loss for batch 100/136 @epoch8/10: 0.2238 in 0.09 secs
Val Loss for batch 110/136 @epoch8/10: 0.18336 in 0.09 secs
Val Loss for batch 120/136 @epoch8/10: 0.23788 in 0.09 secs
Val Loss for batch 130/136 @epoch8/10: 0.23886 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7466437745818361, 'Cardiomegaly': 0.8527321981424149, 'Consolidation': 0.7206710839147847, 'Edema': 0.8730637097580415, 'Effusion': 0.8504705151765157, 'Emphysema': 0.8217115914180233, 'Fibrosis': 0.7183495636018127, 'Hernia': 0.6891597124679831, 'Infiltration': 0.6556871469902881, 'Mass': 0.7801730502774167, 'Nodule': 0.6491851357949953, 'Pleural_Thickening': 0.741669456403824, 'Pneumonia': 0.6528300444660255, 'Pneumothorax': 0.7804021112055971, 'none': 0.7274704784094548}
AVG Loss in validation set: 0.22044370465679847
0.7523392210142542
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch9/10: 0.04112 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch9/10: 0.04519 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch9/10: 0.03528 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch9/10: 0.0353 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch9/10: 0.04695 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch9/10: 0.05414 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch9/10: 0.06366 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch9/10: 0.05446 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch9/10: 0.0402 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch9/10: 0.05639 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch9/10: 0.05442 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch9/10: 0.04505 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch9/10: 0.05609 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch9/10: 0.05166 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch9/10: 0.04464 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch9/10: 0.04782 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch9/10: 0.0552 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch9/10: 0.06591 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch9/10: 0.05211 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch9/10: 0.0461 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch9/10: 0.0487 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch9/10: 0.0381 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch9/10: 0.05948 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch9/10: 0.06239 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch9/10: 0.0483 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch9/10: 0.05202 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch9/10: 0.04976 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch9/10: 0.03982 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch9/10: 0.04059 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch9/10: 0.04259 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch9/10: 0.05174 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch9/10: 0.03991 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch9/10: 0.0774 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch9/10: 0.05582 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch9/10: 0.06019 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch9/10: 0.04394 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch9/10: 0.04191 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch9/10: 0.04252 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch9/10: 0.04238 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch9/10: 0.05327 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch9/10: 0.04761 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch9/10: 0.04985 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch9/10: 0.04466 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch9/10: 0.05182 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch9/10: 0.03858 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch9/10: 0.0408 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch9/10: 0.05011 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch9/10: 0.04574 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch9/10: 0.05962 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch9/10: 0.0443 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch9/10: 0.03852 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch9/10: 0.05162 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch9/10: 0.04782 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch9/10: 0.04502 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch9/10: 0.24328 in 0.09 secs
Val Loss for batch 020/136 @epoch9/10: 0.21224 in 0.09 secs
Val Loss for batch 030/136 @epoch9/10: 0.21767 in 0.09 secs
Val Loss for batch 040/136 @epoch9/10: 0.1848 in 0.09 secs
Val Loss for batch 050/136 @epoch9/10: 0.20395 in 0.09 secs
Val Loss for batch 060/136 @epoch9/10: 0.21912 in 0.09 secs
Val Loss for batch 070/136 @epoch9/10: 0.25341 in 0.09 secs
Val Loss for batch 080/136 @epoch9/10: 0.19963 in 0.09 secs
Val Loss for batch 090/136 @epoch9/10: 0.27862 in 0.09 secs
Val Loss for batch 100/136 @epoch9/10: 0.2169 in 0.09 secs
Val Loss for batch 110/136 @epoch9/10: 0.17799 in 0.08 secs
Val Loss for batch 120/136 @epoch9/10: 0.23752 in 0.09 secs
Val Loss for batch 130/136 @epoch9/10: 0.24532 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7451527953204781, 'Cardiomegaly': 0.8588330108359132, 'Consolidation': 0.7211338395149083, 'Edema': 0.8798853039361605, 'Effusion': 0.8515851313034439, 'Emphysema': 0.8216593441717605, 'Fibrosis': 0.7186941845364454, 'Hernia': 0.7018466495910104, 'Infiltration': 0.6524047676799719, 'Mass': 0.776197532109098, 'Nodule': 0.6593804652002662, 'Pleural_Thickening': 0.7353597065902774, 'Pneumonia': 0.6347617313424783, 'Pneumothorax': 0.782725757395361, 'none': 0.7267208799327182}
AVG Loss in validation set: 0.21885139207513699
0.752830015680541
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch10/10: 0.05762 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch10/10: 0.03833 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch10/10: 0.04271 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch10/10: 0.04161 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch10/10: 0.04076 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch10/10: 0.03992 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch10/10: 0.05883 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch10/10: 0.051 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch10/10: 0.05057 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch10/10: 0.04954 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch10/10: 0.04065 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch10/10: 0.046 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch10/10: 0.04581 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch10/10: 0.05701 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch10/10: 0.04461 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch10/10: 0.02897 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch10/10: 0.04 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch10/10: 0.04578 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch10/10: 0.03972 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch10/10: 0.06109 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch10/10: 0.04141 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch10/10: 0.04341 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch10/10: 0.05679 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch10/10: 0.0493 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch10/10: 0.05956 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch10/10: 0.04861 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch10/10: 0.03494 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch10/10: 0.04632 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch10/10: 0.06012 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch10/10: 0.03908 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch10/10: 0.05205 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch10/10: 0.04903 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch10/10: 0.0466 in 0 mins 0.24 secs
Train Loss for batch 340/541 @epoch10/10: 0.03695 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch10/10: 0.04883 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch10/10: 0.05015 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch10/10: 0.04536 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch10/10: 0.0427 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch10/10: 0.04086 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch10/10: 0.03705 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch10/10: 0.0325 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch10/10: 0.03046 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch10/10: 0.0375 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch10/10: 0.03442 in 0 mins 0.24 secs
Train Loss for batch 450/541 @epoch10/10: 0.04699 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch10/10: 0.03799 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch10/10: 0.06273 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch10/10: 0.05951 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch10/10: 0.04651 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch10/10: 0.04749 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch10/10: 0.03235 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch10/10: 0.05049 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch10/10: 0.04101 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch10/10: 0.07172 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch10/10: 0.24317 in 0.09 secs
Val Loss for batch 020/136 @epoch10/10: 0.2087 in 0.09 secs
Val Loss for batch 030/136 @epoch10/10: 0.20735 in 0.09 secs
Val Loss for batch 040/136 @epoch10/10: 0.20418 in 0.08 secs
Val Loss for batch 050/136 @epoch10/10: 0.2179 in 0.09 secs
Val Loss for batch 060/136 @epoch10/10: 0.22404 in 0.09 secs
Val Loss for batch 070/136 @epoch10/10: 0.22627 in 0.09 secs
Val Loss for batch 080/136 @epoch10/10: 0.18449 in 0.09 secs
Val Loss for batch 090/136 @epoch10/10: 0.29877 in 0.09 secs
Val Loss for batch 100/136 @epoch10/10: 0.22089 in 0.09 secs
Val Loss for batch 110/136 @epoch10/10: 0.18565 in 0.09 secs
Val Loss for batch 120/136 @epoch10/10: 0.24082 in 0.08 secs
Val Loss for batch 130/136 @epoch10/10: 0.23688 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7433756262196273, 'Cardiomegaly': 0.8491172600619196, 'Consolidation': 0.7234320000881924, 'Edema': 0.8709964524197262, 'Effusion': 0.8487790544424556, 'Emphysema': 0.8043253154693457, 'Fibrosis': 0.7445688941635791, 'Hernia': 0.7289349747996365, 'Infiltration': 0.6555240240996537, 'Mass': 0.7733552086304936, 'Nodule': 0.6632800876475896, 'Pleural_Thickening': 0.7228922299816938, 'Pneumonia': 0.6574455489763222, 'Pneumothorax': 0.7749272099492364, 'none': 0.7232399227805866}
AVG Loss in validation set: 0.22351214793948623
0.7543538490678194
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_2/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/10: 0.52744 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch1/10: 0.41858 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch1/10: 0.36064 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch1/10: 0.32633 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch1/10: 0.29501 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch1/10: 0.28422 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch1/10: 0.27422 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch1/10: 0.26724 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch1/10: 0.26325 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch1/10: 0.24854 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch1/10: 0.26437 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch1/10: 0.2404 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch1/10: 0.24498 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch1/10: 0.24468 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch1/10: 0.2486 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch1/10: 0.24519 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch1/10: 0.23266 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch1/10: 0.23516 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch1/10: 0.24218 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch1/10: 0.22631 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch1/10: 0.2296 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch1/10: 0.22432 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch1/10: 0.22298 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch1/10: 0.21845 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch1/10: 0.22351 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch1/10: 0.22291 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch1/10: 0.21778 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch1/10: 0.20743 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch1/10: 0.21767 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch1/10: 0.21481 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch1/10: 0.21486 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch1/10: 0.22268 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch1/10: 0.22085 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch1/10: 0.22584 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch1/10: 0.20812 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch1/10: 0.19418 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch1/10: 0.20632 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch1/10: 0.23042 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch1/10: 0.2074 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch1/10: 0.19709 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch1/10: 0.19535 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch1/10: 0.18712 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch1/10: 0.1941 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch1/10: 0.1982 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch1/10: 0.1975 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch1/10: 0.21867 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch1/10: 0.19318 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch1/10: 0.21017 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch1/10: 0.19551 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch1/10: 0.18016 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch1/10: 0.1909 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch1/10: 0.2097 in 0 mins 0.24 secs
Train Loss for batch 530/541 @epoch1/10: 0.20275 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch1/10: 0.18176 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/10: 0.24453 in 0.08 secs
Val Loss for batch 020/136 @epoch1/10: 0.21509 in 0.09 secs
Val Loss for batch 030/136 @epoch1/10: 0.22326 in 0.09 secs
Val Loss for batch 040/136 @epoch1/10: 0.22437 in 0.09 secs
Val Loss for batch 050/136 @epoch1/10: 0.21841 in 0.09 secs
Val Loss for batch 060/136 @epoch1/10: 0.23079 in 0.08 secs
Val Loss for batch 070/136 @epoch1/10: 0.22675 in 0.09 secs
Val Loss for batch 080/136 @epoch1/10: 0.20275 in 0.09 secs
Val Loss for batch 090/136 @epoch1/10: 0.24557 in 0.09 secs
Val Loss for batch 100/136 @epoch1/10: 0.23649 in 0.09 secs
Val Loss for batch 110/136 @epoch1/10: 0.20755 in 0.09 secs
Val Loss for batch 120/136 @epoch1/10: 0.23858 in 0.09 secs
Val Loss for batch 130/136 @epoch1/10: 0.23443 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7514028828158473, 'Cardiomegaly': 0.8547389705882353, 'Consolidation': 0.7627582132356573, 'Edema': 0.8894848861121155, 'Effusion': 0.8636704055708282, 'Emphysema': 0.8121276497155479, 'Fibrosis': 0.7116020811478103, 'Hernia': 0.8345286292654714, 'Infiltration': 0.6346021767421457, 'Mass': 0.7257506175903876, 'Nodule': 0.6131416754368801, 'Pleural_Thickening': 0.7056411266229914, 'Pneumonia': 0.5953067136654723, 'Pneumothorax': 0.7638240506704402, 'none': 0.7173015102692627}
AVG Loss in validation set: 0.22836571311818413
0.751327148512845
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/10: 0.18718 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch2/10: 0.18645 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch2/10: 0.18757 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch2/10: 0.17679 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch2/10: 0.18521 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch2/10: 0.18561 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch2/10: 0.17297 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch2/10: 0.17849 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch2/10: 0.19297 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch2/10: 0.18185 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch2/10: 0.17183 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch2/10: 0.17342 in 0 mins 0.24 secs
Train Loss for batch 130/541 @epoch2/10: 0.17027 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch2/10: 0.18081 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch2/10: 0.17101 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch2/10: 0.16594 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch2/10: 0.16705 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch2/10: 0.1857 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch2/10: 0.16542 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch2/10: 0.18193 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch2/10: 0.1504 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch2/10: 0.16466 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch2/10: 0.18609 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch2/10: 0.16654 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch2/10: 0.1695 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch2/10: 0.16005 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch2/10: 0.14634 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch2/10: 0.16128 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch2/10: 0.15485 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch2/10: 0.14725 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch2/10: 0.17093 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch2/10: 0.16014 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch2/10: 0.16599 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch2/10: 0.1627 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch2/10: 0.14861 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch2/10: 0.13691 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch2/10: 0.15267 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch2/10: 0.15799 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch2/10: 0.14291 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch2/10: 0.13534 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch2/10: 0.14445 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch2/10: 0.1481 in 0 mins 0.24 secs
Train Loss for batch 430/541 @epoch2/10: 0.15685 in 0 mins 0.24 secs
Train Loss for batch 440/541 @epoch2/10: 0.13746 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch2/10: 0.13959 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch2/10: 0.15161 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch2/10: 0.13371 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch2/10: 0.13494 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch2/10: 0.14418 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch2/10: 0.14692 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch2/10: 0.14596 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch2/10: 0.15527 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch2/10: 0.13114 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch2/10: 0.14146 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/10: 0.24167 in 0.09 secs
Val Loss for batch 020/136 @epoch2/10: 0.2108 in 0.09 secs
Val Loss for batch 030/136 @epoch2/10: 0.21474 in 0.09 secs
Val Loss for batch 040/136 @epoch2/10: 0.21319 in 0.09 secs
Val Loss for batch 050/136 @epoch2/10: 0.20425 in 0.09 secs
Val Loss for batch 060/136 @epoch2/10: 0.22003 in 0.09 secs
Val Loss for batch 070/136 @epoch2/10: 0.22576 in 0.08 secs
Val Loss for batch 080/136 @epoch2/10: 0.18662 in 0.09 secs
Val Loss for batch 090/136 @epoch2/10: 0.23921 in 0.09 secs
Val Loss for batch 100/136 @epoch2/10: 0.2321 in 0.09 secs
Val Loss for batch 110/136 @epoch2/10: 0.18985 in 0.09 secs
Val Loss for batch 120/136 @epoch2/10: 0.23077 in 0.09 secs
Val Loss for batch 130/136 @epoch2/10: 0.23201 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7389098625710961, 'Cardiomegaly': 0.8642780572755417, 'Consolidation': 0.7504108506210427, 'Edema': 0.8754581629382971, 'Effusion': 0.8649135217081809, 'Emphysema': 0.8121229214579676, 'Fibrosis': 0.6929939635410596, 'Hernia': 0.8382136660332149, 'Infiltration': 0.6238500812637541, 'Mass': 0.7336569093274751, 'Nodule': 0.6127358653649079, 'Pleural_Thickening': 0.6974316849871178, 'Pneumonia': 0.6147903862264725, 'Pneumothorax': 0.7749580342474425, 'none': 0.7238011375543685}
AVG Loss in validation set: 0.2173332583557055
0.749623140540255
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/10: 0.13956 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch3/10: 0.15605 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch3/10: 0.14177 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch3/10: 0.14033 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch3/10: 0.14105 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch3/10: 0.12807 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch3/10: 0.14213 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch3/10: 0.14152 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch3/10: 0.13726 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch3/10: 0.1223 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch3/10: 0.13108 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch3/10: 0.1371 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch3/10: 0.15052 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch3/10: 0.12935 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch3/10: 0.14923 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch3/10: 0.14814 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch3/10: 0.13538 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch3/10: 0.12656 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch3/10: 0.1269 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch3/10: 0.12559 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch3/10: 0.14144 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch3/10: 0.10989 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch3/10: 0.14497 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch3/10: 0.13831 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch3/10: 0.14941 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch3/10: 0.1288 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch3/10: 0.12471 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch3/10: 0.13607 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch3/10: 0.12068 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch3/10: 0.12677 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch3/10: 0.11102 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch3/10: 0.10109 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch3/10: 0.1157 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch3/10: 0.12549 in 0 mins 0.24 secs
Train Loss for batch 350/541 @epoch3/10: 0.10231 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch3/10: 0.13234 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch3/10: 0.11428 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch3/10: 0.11556 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch3/10: 0.12332 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch3/10: 0.12732 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch3/10: 0.11528 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch3/10: 0.12677 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch3/10: 0.13201 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch3/10: 0.12173 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch3/10: 0.13019 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch3/10: 0.12257 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch3/10: 0.11552 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch3/10: 0.11468 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch3/10: 0.12343 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch3/10: 0.12642 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch3/10: 0.12017 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch3/10: 0.10495 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch3/10: 0.1142 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch3/10: 0.09813 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/10: 0.23873 in 0.09 secs
Val Loss for batch 020/136 @epoch3/10: 0.20442 in 0.09 secs
Val Loss for batch 030/136 @epoch3/10: 0.20421 in 0.09 secs
Val Loss for batch 040/136 @epoch3/10: 0.20799 in 0.09 secs
Val Loss for batch 050/136 @epoch3/10: 0.19143 in 0.09 secs
Val Loss for batch 060/136 @epoch3/10: 0.21569 in 0.09 secs
Val Loss for batch 070/136 @epoch3/10: 0.2228 in 0.09 secs
Val Loss for batch 080/136 @epoch3/10: 0.17191 in 0.09 secs
Val Loss for batch 090/136 @epoch3/10: 0.24363 in 0.09 secs
Val Loss for batch 100/136 @epoch3/10: 0.23475 in 0.09 secs
Val Loss for batch 110/136 @epoch3/10: 0.18622 in 0.09 secs
Val Loss for batch 120/136 @epoch3/10: 0.22252 in 0.09 secs
Val Loss for batch 130/136 @epoch3/10: 0.22326 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7410633829446135, 'Cardiomegaly': 0.8487614164086688, 'Consolidation': 0.713483086428272, 'Edema': 0.8751219977071999, 'Effusion': 0.8676044828130537, 'Emphysema': 0.7948418492404526, 'Fibrosis': 0.7101171616986857, 'Hernia': 0.7688837478311161, 'Infiltration': 0.6049827678450119, 'Mass': 0.7477112024102041, 'Nodule': 0.6333098024828432, 'Pleural_Thickening': 0.6702358528544308, 'Pneumonia': 0.6200116597802028, 'Pneumothorax': 0.7730228095100724, 'none': 0.722712652062982}
AVG Loss in validation set: 0.2115688161804783
0.740653658568202
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/10: 0.11883 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch4/10: 0.11955 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch4/10: 0.10298 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch4/10: 0.12517 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch4/10: 0.1096 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch4/10: 0.12067 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch4/10: 0.11242 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch4/10: 0.11552 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch4/10: 0.12052 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch4/10: 0.10624 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch4/10: 0.10015 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch4/10: 0.11191 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch4/10: 0.09762 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch4/10: 0.11234 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch4/10: 0.09202 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch4/10: 0.11973 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch4/10: 0.10039 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch4/10: 0.13322 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch4/10: 0.10228 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch4/10: 0.10178 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch4/10: 0.10415 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch4/10: 0.11203 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch4/10: 0.11611 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch4/10: 0.10514 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch4/10: 0.13594 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch4/10: 0.09658 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch4/10: 0.12549 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch4/10: 0.10511 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch4/10: 0.10632 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch4/10: 0.10066 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch4/10: 0.10047 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch4/10: 0.12171 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch4/10: 0.09268 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch4/10: 0.12075 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch4/10: 0.1186 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch4/10: 0.11024 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch4/10: 0.10875 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch4/10: 0.09292 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch4/10: 0.10315 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch4/10: 0.09349 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch4/10: 0.09949 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch4/10: 0.10591 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch4/10: 0.08866 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch4/10: 0.0974 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch4/10: 0.10664 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch4/10: 0.11044 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch4/10: 0.08744 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch4/10: 0.10684 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch4/10: 0.09654 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch4/10: 0.08752 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch4/10: 0.11209 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch4/10: 0.08814 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch4/10: 0.0924 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch4/10: 0.10137 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/10: 0.23581 in 0.09 secs
Val Loss for batch 020/136 @epoch4/10: 0.20923 in 0.09 secs
Val Loss for batch 030/136 @epoch4/10: 0.21443 in 0.09 secs
Val Loss for batch 040/136 @epoch4/10: 0.20507 in 0.09 secs
Val Loss for batch 050/136 @epoch4/10: 0.19048 in 0.09 secs
Val Loss for batch 060/136 @epoch4/10: 0.22135 in 0.09 secs
Val Loss for batch 070/136 @epoch4/10: 0.21687 in 0.09 secs
Val Loss for batch 080/136 @epoch4/10: 0.18557 in 0.09 secs
Val Loss for batch 090/136 @epoch4/10: 0.24151 in 0.09 secs
Val Loss for batch 100/136 @epoch4/10: 0.22404 in 0.09 secs
Val Loss for batch 110/136 @epoch4/10: 0.18626 in 0.08 secs
Val Loss for batch 120/136 @epoch4/10: 0.22941 in 0.09 secs
Val Loss for batch 130/136 @epoch4/10: 0.23412 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7219139864581018, 'Cardiomegaly': 0.8445493421052631, 'Consolidation': 0.7093484490975984, 'Edema': 0.8738416174050997, 'Effusion': 0.8576171857548347, 'Emphysema': 0.801414363690008, 'Fibrosis': 0.7084974315320501, 'Hernia': 0.6975460629595968, 'Infiltration': 0.6224431329359273, 'Mass': 0.725744440968299, 'Nodule': 0.6468256942115572, 'Pleural_Thickening': 0.6986346267119805, 'Pneumonia': 0.6414455729553048, 'Pneumothorax': 0.7386798941338301, 'none': 0.727784038934837}
AVG Loss in validation set: 0.21546686494785824
0.7348929857799609
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/10: 0.10344 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch5/10: 0.09475 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch5/10: 0.09858 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch5/10: 0.08236 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch5/10: 0.09578 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch5/10: 0.10548 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch5/10: 0.10661 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch5/10: 0.09609 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch5/10: 0.09854 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch5/10: 0.09581 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch5/10: 0.09799 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch5/10: 0.08685 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch5/10: 0.10529 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch5/10: 0.08513 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch5/10: 0.10198 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch5/10: 0.09406 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch5/10: 0.11456 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch5/10: 0.0929 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch5/10: 0.10471 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch5/10: 0.08902 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch5/10: 0.0972 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch5/10: 0.10739 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch5/10: 0.0952 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch5/10: 0.09301 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch5/10: 0.11343 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch5/10: 0.10924 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch5/10: 0.08744 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch5/10: 0.09933 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch5/10: 0.10207 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch5/10: 0.08619 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch5/10: 0.10095 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch5/10: 0.07999 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch5/10: 0.09109 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch5/10: 0.07705 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch5/10: 0.10097 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch5/10: 0.0828 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch5/10: 0.11303 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch5/10: 0.07851 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch5/10: 0.0975 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch5/10: 0.09413 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch5/10: 0.09812 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch5/10: 0.09538 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch5/10: 0.07349 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch5/10: 0.09712 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch5/10: 0.08245 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch5/10: 0.09144 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch5/10: 0.10447 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch5/10: 0.07834 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch5/10: 0.11203 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch5/10: 0.07978 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch5/10: 0.07653 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch5/10: 0.07792 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch5/10: 0.09688 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch5/10: 0.10783 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/10: 0.2421 in 0.09 secs
Val Loss for batch 020/136 @epoch5/10: 0.2084 in 0.09 secs
Val Loss for batch 030/136 @epoch5/10: 0.21952 in 0.09 secs
Val Loss for batch 040/136 @epoch5/10: 0.20498 in 0.09 secs
Val Loss for batch 050/136 @epoch5/10: 0.20217 in 0.09 secs
Val Loss for batch 060/136 @epoch5/10: 0.21886 in 0.08 secs
Val Loss for batch 070/136 @epoch5/10: 0.23347 in 0.08 secs
Val Loss for batch 080/136 @epoch5/10: 0.19252 in 0.08 secs
Val Loss for batch 090/136 @epoch5/10: 0.25892 in 0.09 secs
Val Loss for batch 100/136 @epoch5/10: 0.23264 in 0.08 secs
Val Loss for batch 110/136 @epoch5/10: 0.19443 in 0.09 secs
Val Loss for batch 120/136 @epoch5/10: 0.23113 in 0.09 secs
Val Loss for batch 130/136 @epoch5/10: 0.23279 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.744156559957799, 'Cardiomegaly': 0.8386153250773994, 'Consolidation': 0.7341323876045398, 'Edema': 0.871551433373789, 'Effusion': 0.8620940605928834, 'Emphysema': 0.8272327777945893, 'Fibrosis': 0.7044587614603828, 'Hernia': 0.6733247955052466, 'Infiltration': 0.6330869640649762, 'Mass': 0.7422551263808701, 'Nodule': 0.6340886318231376, 'Pleural_Thickening': 0.7118640723523628, 'Pneumonia': 0.6310324001013111, 'Pneumothorax': 0.7765437208551554, 'none': 0.7269988220927299}
AVG Loss in validation set: 0.2209914589005381
0.7417455012103173
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch6/10: 0.08368 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch6/10: 0.09625 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch6/10: 0.08422 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch6/10: 0.0893 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch6/10: 0.098 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch6/10: 0.09764 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch6/10: 0.07636 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch6/10: 0.075 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch6/10: 0.08996 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch6/10: 0.08904 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch6/10: 0.06737 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch6/10: 0.08246 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch6/10: 0.07687 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch6/10: 0.07992 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch6/10: 0.07767 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch6/10: 0.07737 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch6/10: 0.05553 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch6/10: 0.07324 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch6/10: 0.08231 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch6/10: 0.06597 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch6/10: 0.08472 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch6/10: 0.08038 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch6/10: 0.0838 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch6/10: 0.07079 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch6/10: 0.06759 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch6/10: 0.07532 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch6/10: 0.09006 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch6/10: 0.06204 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch6/10: 0.08319 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch6/10: 0.07538 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch6/10: 0.07382 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch6/10: 0.05404 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch6/10: 0.08846 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch6/10: 0.07658 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch6/10: 0.06884 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch6/10: 0.08467 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch6/10: 0.07533 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch6/10: 0.06719 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch6/10: 0.05918 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch6/10: 0.08434 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch6/10: 0.06591 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch6/10: 0.06877 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch6/10: 0.06929 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch6/10: 0.08374 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch6/10: 0.09993 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch6/10: 0.07153 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch6/10: 0.07563 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch6/10: 0.08299 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch6/10: 0.05681 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch6/10: 0.09071 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch6/10: 0.0716 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch6/10: 0.08751 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch6/10: 0.05501 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch6/10: 0.07014 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch6/10: 0.2291 in 0.09 secs
Val Loss for batch 020/136 @epoch6/10: 0.20729 in 0.09 secs
Val Loss for batch 030/136 @epoch6/10: 0.21953 in 0.09 secs
Val Loss for batch 040/136 @epoch6/10: 0.20268 in 0.09 secs
Val Loss for batch 050/136 @epoch6/10: 0.19011 in 0.09 secs
Val Loss for batch 060/136 @epoch6/10: 0.21994 in 0.09 secs
Val Loss for batch 070/136 @epoch6/10: 0.22231 in 0.09 secs
Val Loss for batch 080/136 @epoch6/10: 0.18613 in 0.09 secs
Val Loss for batch 090/136 @epoch6/10: 0.26111 in 0.09 secs
Val Loss for batch 100/136 @epoch6/10: 0.21832 in 0.09 secs
Val Loss for batch 110/136 @epoch6/10: 0.18483 in 0.08 secs
Val Loss for batch 120/136 @epoch6/10: 0.22971 in 0.09 secs
Val Loss for batch 130/136 @epoch6/10: 0.23974 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.73204289636682, 'Cardiomegaly': 0.8541352554179567, 'Consolidation': 0.6959686010092329, 'Edema': 0.8699113431940555, 'Effusion': 0.8529627601273571, 'Emphysema': 0.8082450410034496, 'Fibrosis': 0.7076203965672128, 'Hernia': 0.6731636784268363, 'Infiltration': 0.6218381290796352, 'Mass': 0.7496545400901556, 'Nodule': 0.6575341837760909, 'Pleural_Thickening': 0.7027290515458675, 'Pneumonia': 0.672264560113061, 'Pneumothorax': 0.7650660228231576, 'none': 0.7272312367105125}
AVG Loss in validation set: 0.2126011883033077
0.7402240328243492
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch7/10: 0.08442 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch7/10: 0.07604 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch7/10: 0.07144 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch7/10: 0.07283 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch7/10: 0.0752 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch7/10: 0.07635 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch7/10: 0.06056 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch7/10: 0.0775 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch7/10: 0.06372 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch7/10: 0.07534 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch7/10: 0.07649 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch7/10: 0.08338 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch7/10: 0.0728 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch7/10: 0.08657 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch7/10: 0.05788 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch7/10: 0.06155 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch7/10: 0.06067 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch7/10: 0.09264 in 0 mins 0.24 secs
Train Loss for batch 190/541 @epoch7/10: 0.11133 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch7/10: 0.06489 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch7/10: 0.06533 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch7/10: 0.06899 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch7/10: 0.07276 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch7/10: 0.08151 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch7/10: 0.06765 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch7/10: 0.06939 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch7/10: 0.07467 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch7/10: 0.06378 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch7/10: 0.07813 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch7/10: 0.05399 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch7/10: 0.06863 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch7/10: 0.07392 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch7/10: 0.07976 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch7/10: 0.06442 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch7/10: 0.08133 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch7/10: 0.07095 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch7/10: 0.07983 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch7/10: 0.06334 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch7/10: 0.05446 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch7/10: 0.07992 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch7/10: 0.04618 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch7/10: 0.05885 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch7/10: 0.07494 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch7/10: 0.07463 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch7/10: 0.05057 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch7/10: 0.08509 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch7/10: 0.06201 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch7/10: 0.06286 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch7/10: 0.06177 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch7/10: 0.06829 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch7/10: 0.05504 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch7/10: 0.06716 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch7/10: 0.06284 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch7/10: 0.06263 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch7/10: 0.23281 in 0.09 secs
Val Loss for batch 020/136 @epoch7/10: 0.18736 in 0.09 secs
Val Loss for batch 030/136 @epoch7/10: 0.2229 in 0.09 secs
Val Loss for batch 040/136 @epoch7/10: 0.19208 in 0.09 secs
Val Loss for batch 050/136 @epoch7/10: 0.1926 in 0.09 secs
Val Loss for batch 060/136 @epoch7/10: 0.21416 in 0.09 secs
Val Loss for batch 070/136 @epoch7/10: 0.22128 in 0.09 secs
Val Loss for batch 080/136 @epoch7/10: 0.18053 in 0.09 secs
Val Loss for batch 090/136 @epoch7/10: 0.25635 in 0.09 secs
Val Loss for batch 100/136 @epoch7/10: 0.22582 in 0.08 secs
Val Loss for batch 110/136 @epoch7/10: 0.18244 in 0.08 secs
Val Loss for batch 120/136 @epoch7/10: 0.23303 in 0.09 secs
Val Loss for batch 130/136 @epoch7/10: 0.24203 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7360362916637437, 'Cardiomegaly': 0.8498693885448916, 'Consolidation': 0.6990737130321205, 'Edema': 0.8736555025801009, 'Effusion': 0.8451283920428655, 'Emphysema': 0.822127796291533, 'Fibrosis': 0.7064897526193898, 'Hernia': 0.7222878625134265, 'Infiltration': 0.6382316640356714, 'Mass': 0.750323590358379, 'Nodule': 0.6519578370116231, 'Pleural_Thickening': 0.6918921145077632, 'Pneumonia': 0.6474422668531032, 'Pneumothorax': 0.7701717972260013, 'none': 0.7312004702608312}
AVG Loss in validation set: 0.2111245124388557
0.7431919978057581
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch8/10: 0.05686 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch8/10: 0.05631 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch8/10: 0.10178 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch8/10: 0.081 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch8/10: 0.05936 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch8/10: 0.06629 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch8/10: 0.06636 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch8/10: 0.06125 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch8/10: 0.05736 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch8/10: 0.07745 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch8/10: 0.06743 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch8/10: 0.06108 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch8/10: 0.06723 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch8/10: 0.0746 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch8/10: 0.07337 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch8/10: 0.07231 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch8/10: 0.06688 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch8/10: 0.0463 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch8/10: 0.04483 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch8/10: 0.05255 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch8/10: 0.05914 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch8/10: 0.06506 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch8/10: 0.06587 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch8/10: 0.06219 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch8/10: 0.07526 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch8/10: 0.0711 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch8/10: 0.0638 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch8/10: 0.06296 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch8/10: 0.09432 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch8/10: 0.04763 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch8/10: 0.06757 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch8/10: 0.05668 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch8/10: 0.06431 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch8/10: 0.06106 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch8/10: 0.05961 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch8/10: 0.05087 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch8/10: 0.08014 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch8/10: 0.05807 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch8/10: 0.05776 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch8/10: 0.06819 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch8/10: 0.05504 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch8/10: 0.06331 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch8/10: 0.05767 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch8/10: 0.07129 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch8/10: 0.06686 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch8/10: 0.04381 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch8/10: 0.06187 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch8/10: 0.06297 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch8/10: 0.06415 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch8/10: 0.06386 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch8/10: 0.06436 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch8/10: 0.05736 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch8/10: 0.06342 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch8/10: 0.06556 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch8/10: 0.25008 in 0.09 secs
Val Loss for batch 020/136 @epoch8/10: 0.2086 in 0.08 secs
Val Loss for batch 030/136 @epoch8/10: 0.22206 in 0.09 secs
Val Loss for batch 040/136 @epoch8/10: 0.21416 in 0.09 secs
Val Loss for batch 050/136 @epoch8/10: 0.19292 in 0.09 secs
Val Loss for batch 060/136 @epoch8/10: 0.22358 in 0.09 secs
Val Loss for batch 070/136 @epoch8/10: 0.22297 in 0.09 secs
Val Loss for batch 080/136 @epoch8/10: 0.18931 in 0.08 secs
Val Loss for batch 090/136 @epoch8/10: 0.25573 in 0.09 secs
Val Loss for batch 100/136 @epoch8/10: 0.2216 in 0.09 secs
Val Loss for batch 110/136 @epoch8/10: 0.19081 in 0.09 secs
Val Loss for batch 120/136 @epoch8/10: 0.2335 in 0.09 secs
Val Loss for batch 130/136 @epoch8/10: 0.25137 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7330608092525718, 'Cardiomegaly': 0.8274458204334366, 'Consolidation': 0.7110817793823011, 'Edema': 0.8781998062238219, 'Effusion': 0.8411328849825317, 'Emphysema': 0.8208690159172063, 'Fibrosis': 0.7071906506118287, 'Hernia': 0.7075766338924234, 'Infiltration': 0.6334941342323133, 'Mass': 0.745869778994716, 'Nodule': 0.6453941050284984, 'Pleural_Thickening': 0.697995481155502, 'Pneumonia': 0.6255068932081029, 'Pneumothorax': 0.7701205018289867, 'none': 0.720828063302774}
AVG Loss in validation set: 0.21839700281702695
0.7389241639388744
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch9/10: 0.05535 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch9/10: 0.05868 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch9/10: 0.04764 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch9/10: 0.0475 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch9/10: 0.04659 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch9/10: 0.06021 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch9/10: 0.06794 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch9/10: 0.08833 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch9/10: 0.04417 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch9/10: 0.06486 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch9/10: 0.06409 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch9/10: 0.05928 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch9/10: 0.07309 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch9/10: 0.06255 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch9/10: 0.05438 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch9/10: 0.05754 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch9/10: 0.06508 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch9/10: 0.06344 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch9/10: 0.06334 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch9/10: 0.05683 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch9/10: 0.06568 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch9/10: 0.04907 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch9/10: 0.07568 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch9/10: 0.06921 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch9/10: 0.0618 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch9/10: 0.06392 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch9/10: 0.05854 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch9/10: 0.0576 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch9/10: 0.04943 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch9/10: 0.04443 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch9/10: 0.06244 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch9/10: 0.05122 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch9/10: 0.09743 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch9/10: 0.06596 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch9/10: 0.07311 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch9/10: 0.05675 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch9/10: 0.05464 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch9/10: 0.05892 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch9/10: 0.04767 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch9/10: 0.06153 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch9/10: 0.05807 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch9/10: 0.05562 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch9/10: 0.05604 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch9/10: 0.065 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch9/10: 0.04954 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch9/10: 0.04948 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch9/10: 0.05802 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch9/10: 0.06263 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch9/10: 0.0692 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch9/10: 0.05918 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch9/10: 0.05535 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch9/10: 0.0657 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch9/10: 0.05976 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch9/10: 0.0518 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch9/10: 0.26059 in 0.09 secs
Val Loss for batch 020/136 @epoch9/10: 0.21445 in 0.09 secs
Val Loss for batch 030/136 @epoch9/10: 0.21965 in 0.09 secs
Val Loss for batch 040/136 @epoch9/10: 0.21657 in 0.09 secs
Val Loss for batch 050/136 @epoch9/10: 0.1872 in 0.09 secs
Val Loss for batch 060/136 @epoch9/10: 0.22784 in 0.09 secs
Val Loss for batch 070/136 @epoch9/10: 0.24244 in 0.08 secs
Val Loss for batch 080/136 @epoch9/10: 0.19568 in 0.09 secs
Val Loss for batch 090/136 @epoch9/10: 0.2652 in 0.09 secs
Val Loss for batch 100/136 @epoch9/10: 0.23091 in 0.09 secs
Val Loss for batch 110/136 @epoch9/10: 0.1908 in 0.09 secs
Val Loss for batch 120/136 @epoch9/10: 0.25462 in 0.09 secs
Val Loss for batch 130/136 @epoch9/10: 0.2447 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7344624414420882, 'Cardiomegaly': 0.8429121517027864, 'Consolidation': 0.6964062462359959, 'Edema': 0.869285915162659, 'Effusion': 0.844744958287292, 'Emphysema': 0.797407047184228, 'Fibrosis': 0.6953854703481177, 'Hernia': 0.6172973642898454, 'Infiltration': 0.6327954290820287, 'Mass': 0.7509238359293819, 'Nodule': 0.6441264380279599, 'Pleural_Thickening': 0.6869791092828328, 'Pneumonia': 0.6191869326535292, 'Pneumothorax': 0.7644301246101667, 'none': 0.7218947691068167}
AVG Loss in validation set: 0.22151595115716735
0.7283102474456365
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch10/10: 0.06339 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch10/10: 0.05256 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch10/10: 0.0538 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch10/10: 0.04974 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch10/10: 0.0478 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch10/10: 0.04826 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch10/10: 0.0685 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch10/10: 0.06037 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch10/10: 0.06237 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch10/10: 0.05518 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch10/10: 0.05197 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch10/10: 0.0588 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch10/10: 0.06049 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch10/10: 0.06586 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch10/10: 0.05613 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch10/10: 0.04133 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch10/10: 0.05368 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch10/10: 0.0544 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch10/10: 0.04347 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch10/10: 0.07204 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch10/10: 0.05828 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch10/10: 0.05524 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch10/10: 0.06688 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch10/10: 0.06592 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch10/10: 0.06575 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch10/10: 0.05224 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch10/10: 0.04494 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch10/10: 0.05715 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch10/10: 0.05942 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch10/10: 0.04126 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch10/10: 0.06059 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch10/10: 0.06469 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch10/10: 0.06146 in 0 mins 0.24 secs
Train Loss for batch 340/541 @epoch10/10: 0.04874 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch10/10: 0.0565 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch10/10: 0.06241 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch10/10: 0.06033 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch10/10: 0.05011 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch10/10: 0.05302 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch10/10: 0.04813 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch10/10: 0.05098 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch10/10: 0.04189 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch10/10: 0.05733 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch10/10: 0.04731 in 0 mins 0.24 secs
Train Loss for batch 450/541 @epoch10/10: 0.04668 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch10/10: 0.05667 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch10/10: 0.07241 in 0 mins 0.24 secs
Train Loss for batch 480/541 @epoch10/10: 0.06662 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch10/10: 0.05268 in 0 mins 0.24 secs
Train Loss for batch 500/541 @epoch10/10: 0.06144 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch10/10: 0.05278 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch10/10: 0.05885 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch10/10: 0.05214 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch10/10: 0.07725 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch10/10: 0.26223 in 0.09 secs
Val Loss for batch 020/136 @epoch10/10: 0.2152 in 0.09 secs
Val Loss for batch 030/136 @epoch10/10: 0.23076 in 0.09 secs
Val Loss for batch 040/136 @epoch10/10: 0.21809 in 0.08 secs
Val Loss for batch 050/136 @epoch10/10: 0.19706 in 0.09 secs
Val Loss for batch 060/136 @epoch10/10: 0.23465 in 0.09 secs
Val Loss for batch 070/136 @epoch10/10: 0.24572 in 0.09 secs
Val Loss for batch 080/136 @epoch10/10: 0.19144 in 0.09 secs
Val Loss for batch 090/136 @epoch10/10: 0.27634 in 0.09 secs
Val Loss for batch 100/136 @epoch10/10: 0.22953 in 0.09 secs
Val Loss for batch 110/136 @epoch10/10: 0.20614 in 0.09 secs
Val Loss for batch 120/136 @epoch10/10: 0.25041 in 0.08 secs
Val Loss for batch 130/136 @epoch10/10: 0.26664 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7278183387889725, 'Cardiomegaly': 0.8320799148606811, 'Consolidation': 0.6884690715735466, 'Edema': 0.862615679426557, 'Effusion': 0.837816642789703, 'Emphysema': 0.7844325901773286, 'Fibrosis': 0.7045189258941366, 'Hernia': 0.6781954887218046, 'Infiltration': 0.6128348981770937, 'Mass': 0.7390411641697313, 'Nodule': 0.6537876911982415, 'Pleural_Thickening': 0.6911027336599092, 'Pneumonia': 0.6186166824778081, 'Pneumothorax': 0.774380549256052, 'none': 0.7163022347052642}
AVG Loss in validation set: 0.22958043935505043
0.7289793122265404
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/0/ft_googlenet_adam_steplr_1/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/5: 0.28977 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch1/5: 0.24525 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch1/5: 0.24981 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch1/5: 0.24262 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch1/5: 0.24786 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch1/5: 0.24514 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch1/5: 0.2398 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch1/5: 0.2406 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch1/5: 0.24083 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch1/5: 0.22336 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch1/5: 0.22604 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch1/5: 0.22869 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch1/5: 0.22192 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch1/5: 0.23845 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch1/5: 0.20984 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch1/5: 0.21889 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch1/5: 0.24513 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch1/5: 0.23074 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch1/5: 0.22816 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch1/5: 0.21111 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch1/5: 0.22436 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch1/5: 0.2199 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch1/5: 0.22255 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch1/5: 0.20471 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch1/5: 0.20945 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch1/5: 0.20515 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch1/5: 0.19946 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch1/5: 0.22544 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch1/5: 0.24266 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch1/5: 0.22359 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch1/5: 0.20683 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch1/5: 0.21319 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch1/5: 0.19565 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch1/5: 0.21983 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch1/5: 0.22954 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch1/5: 0.21916 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch1/5: 0.20434 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch1/5: 0.20723 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch1/5: 0.20125 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch1/5: 0.20724 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch1/5: 0.19704 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch1/5: 0.22085 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch1/5: 0.21793 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch1/5: 0.19181 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch1/5: 0.20035 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch1/5: 0.19812 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch1/5: 0.20321 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch1/5: 0.19022 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch1/5: 0.20731 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch1/5: 0.22309 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch1/5: 0.18706 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch1/5: 0.21121 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch1/5: 0.20326 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch1/5: 0.19226 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/5: 0.27072 in 0.1 secs
Val Loss for batch 020/136 @epoch1/5: 0.23796 in 0.11 secs
Val Loss for batch 030/136 @epoch1/5: 0.24201 in 0.11 secs
Val Loss for batch 040/136 @epoch1/5: 0.24476 in 0.1 secs
Val Loss for batch 050/136 @epoch1/5: 0.23422 in 0.11 secs
Val Loss for batch 060/136 @epoch1/5: 0.25446 in 0.1 secs
Val Loss for batch 070/136 @epoch1/5: 0.25134 in 0.1 secs
Val Loss for batch 080/136 @epoch1/5: 0.23046 in 0.11 secs
Val Loss for batch 090/136 @epoch1/5: 0.27757 in 0.1 secs
Val Loss for batch 100/136 @epoch1/5: 0.26538 in 0.1 secs
Val Loss for batch 110/136 @epoch1/5: 0.23871 in 0.11 secs
Val Loss for batch 120/136 @epoch1/5: 0.2485 in 0.11 secs
Val Loss for batch 130/136 @epoch1/5: 0.26062 in 0.11 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7244552785524874, 'Cardiomegaly': 0.8771845975232198, 'Consolidation': 0.7516202825672356, 'Edema': 0.8613394100944869, 'Effusion': 0.8579397667602882, 'Emphysema': 0.7616021984506446, 'Fibrosis': 0.7107999279439658, 'Hernia': 0.7248946542179624, 'Infiltration': 0.6206859330054205, 'Mass': 0.7610204584087815, 'Nodule': 0.6478856967342206, 'Pleural_Thickening': 0.6993374021120076, 'Pneumonia': 0.6562777725323753, 'Pneumothorax': 0.7222461313152753, 'none': 0.7054289427757064}
AVG Loss in validation set: 0.246648723239762
0.7412349650155979
Model saved to /scratch/group4/out/0/ft_resnet_34_adam_steplr/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/5: 0.19841 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch2/5: 0.1974 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch2/5: 0.21016 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch2/5: 0.18946 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch2/5: 0.18079 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch2/5: 0.18817 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch2/5: 0.19749 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch2/5: 0.19898 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch2/5: 0.1902 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch2/5: 0.19422 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch2/5: 0.20031 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch2/5: 0.16576 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch2/5: 0.19352 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch2/5: 0.18867 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch2/5: 0.18321 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch2/5: 0.17334 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch2/5: 0.18638 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch2/5: 0.19938 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch2/5: 0.18437 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch2/5: 0.16826 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch2/5: 0.20625 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch2/5: 0.1714 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch2/5: 0.16441 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch2/5: 0.18962 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch2/5: 0.1791 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch2/5: 0.17266 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch2/5: 0.18196 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch2/5: 0.19593 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch2/5: 0.1717 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch2/5: 0.19581 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch2/5: 0.18893 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch2/5: 0.17379 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch2/5: 0.15358 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch2/5: 0.16827 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch2/5: 0.16 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch2/5: 0.17404 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch2/5: 0.19095 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch2/5: 0.18604 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch2/5: 0.18098 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch2/5: 0.17337 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch2/5: 0.18326 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch2/5: 0.17966 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch2/5: 0.20239 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch2/5: 0.16878 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch2/5: 0.16895 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch2/5: 0.162 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch2/5: 0.16582 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch2/5: 0.17497 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch2/5: 0.16481 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch2/5: 0.15112 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch2/5: 0.15494 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch2/5: 0.17371 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch2/5: 0.14976 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch2/5: 0.15749 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/5: 0.25366 in 0.11 secs
Val Loss for batch 020/136 @epoch2/5: 0.21228 in 0.11 secs
Val Loss for batch 030/136 @epoch2/5: 0.21285 in 0.1 secs
Val Loss for batch 040/136 @epoch2/5: 0.21701 in 0.1 secs
Val Loss for batch 050/136 @epoch2/5: 0.21842 in 0.11 secs
Val Loss for batch 060/136 @epoch2/5: 0.23817 in 0.1 secs
Val Loss for batch 070/136 @epoch2/5: 0.23278 in 0.1 secs
Val Loss for batch 080/136 @epoch2/5: 0.1939 in 0.1 secs
Val Loss for batch 090/136 @epoch2/5: 0.23093 in 0.11 secs
Val Loss for batch 100/136 @epoch2/5: 0.23166 in 0.1 secs
Val Loss for batch 110/136 @epoch2/5: 0.201 in 0.11 secs
Val Loss for batch 120/136 @epoch2/5: 0.23148 in 0.11 secs
Val Loss for batch 130/136 @epoch2/5: 0.2567 in 0.1 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7315349287912756, 'Cardiomegaly': 0.8324701044891641, 'Consolidation': 0.7102369071859356, 'Edema': 0.8689704916439862, 'Effusion': 0.8425156143428574, 'Emphysema': 0.7665213594307935, 'Fibrosis': 0.705824293950943, 'Hernia': 0.7973105841526894, 'Infiltration': 0.6164232802645118, 'Mass': 0.703181707316022, 'Nodule': 0.5905151295176256, 'Pleural_Thickening': 0.625999273255814, 'Pneumonia': 0.5870885169149241, 'Pneumothorax': 0.7038744966345043, 'none': 0.7243443312940977}
AVG Loss in validation set: 0.2274343941052424
0.7201761919922176
Model saved to /scratch/group4/out/0/ft_resnet_34_adam_steplr/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/5: 0.14884 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch3/5: 0.17384 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch3/5: 0.16351 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch3/5: 0.1492 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch3/5: 0.15405 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch3/5: 0.14099 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch3/5: 0.16289 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch3/5: 0.13176 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch3/5: 0.14029 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch3/5: 0.15532 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch3/5: 0.14459 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch3/5: 0.15046 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch3/5: 0.14327 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch3/5: 0.14021 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch3/5: 0.14232 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch3/5: 0.1371 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch3/5: 0.116 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch3/5: 0.1106 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch3/5: 0.1381 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch3/5: 0.14694 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch3/5: 0.13644 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch3/5: 0.14065 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch3/5: 0.11647 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch3/5: 0.1075 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch3/5: 0.1463 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch3/5: 0.12105 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch3/5: 0.11869 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch3/5: 0.14575 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch3/5: 0.12845 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch3/5: 0.13711 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch3/5: 0.13254 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch3/5: 0.1411 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch3/5: 0.13047 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch3/5: 0.14057 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch3/5: 0.13873 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch3/5: 0.12751 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch3/5: 0.14057 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch3/5: 0.15002 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch3/5: 0.12003 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch3/5: 0.12794 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch3/5: 0.14217 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch3/5: 0.12032 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch3/5: 0.10366 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch3/5: 0.10634 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch3/5: 0.112 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch3/5: 0.13646 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch3/5: 0.13798 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch3/5: 0.10596 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch3/5: 0.14138 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch3/5: 0.12811 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch3/5: 0.13672 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch3/5: 0.14635 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch3/5: 0.14753 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch3/5: 0.14505 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/5: 0.23603 in 0.11 secs
Val Loss for batch 020/136 @epoch3/5: 0.20434 in 0.1 secs
Val Loss for batch 030/136 @epoch3/5: 0.20127 in 0.1 secs
Val Loss for batch 040/136 @epoch3/5: 0.1966 in 0.11 secs
Val Loss for batch 050/136 @epoch3/5: 0.19106 in 0.11 secs
Val Loss for batch 060/136 @epoch3/5: 0.20719 in 0.1 secs
Val Loss for batch 070/136 @epoch3/5: 0.22431 in 0.1 secs
Val Loss for batch 080/136 @epoch3/5: 0.18301 in 0.11 secs
Val Loss for batch 090/136 @epoch3/5: 0.23276 in 0.11 secs
Val Loss for batch 100/136 @epoch3/5: 0.21883 in 0.11 secs
Val Loss for batch 110/136 @epoch3/5: 0.17968 in 0.1 secs
Val Loss for batch 120/136 @epoch3/5: 0.21804 in 0.1 secs
Val Loss for batch 130/136 @epoch3/5: 0.22815 in 0.11 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7561458589396651, 'Cardiomegaly': 0.8596904024767802, 'Consolidation': 0.7448212406810913, 'Edema': 0.876841691215698, 'Effusion': 0.8671206950728073, 'Emphysema': 0.8425050497790958, 'Fibrosis': 0.7435124255450415, 'Hernia': 0.7895026026604974, 'Infiltration': 0.6297878068765008, 'Mass': 0.775788043610974, 'Nodule': 0.6276896815872889, 'Pleural_Thickening': 0.6882466078208692, 'Pneumonia': 0.6662305489238682, 'Pneumothorax': 0.762418074427268, 'none': 0.7359316921759176}
AVG Loss in validation set: 0.20765577497109736
0.7593071949726747
Model saved to /scratch/group4/out/0/ft_resnet_34_adam_steplr/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/5: 0.13455 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch4/5: 0.12585 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch4/5: 0.12107 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch4/5: 0.10987 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch4/5: 0.11416 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch4/5: 0.12123 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch4/5: 0.12771 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch4/5: 0.13853 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch4/5: 0.11102 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch4/5: 0.12352 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch4/5: 0.1123 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch4/5: 0.12476 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch4/5: 0.13065 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch4/5: 0.09945 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch4/5: 0.12027 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch4/5: 0.1151 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch4/5: 0.11532 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch4/5: 0.1209 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch4/5: 0.10964 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch4/5: 0.1395 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch4/5: 0.11127 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch4/5: 0.11933 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch4/5: 0.11071 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch4/5: 0.11381 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch4/5: 0.13294 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch4/5: 0.12517 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch4/5: 0.11489 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch4/5: 0.10661 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch4/5: 0.12462 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch4/5: 0.10335 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch4/5: 0.12258 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch4/5: 0.11674 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch4/5: 0.10934 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch4/5: 0.12723 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch4/5: 0.10797 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch4/5: 0.11884 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch4/5: 0.11906 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch4/5: 0.14183 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch4/5: 0.13657 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch4/5: 0.10391 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch4/5: 0.114 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch4/5: 0.11913 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch4/5: 0.11562 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch4/5: 0.12016 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch4/5: 0.12211 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch4/5: 0.12217 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch4/5: 0.10411 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch4/5: 0.09634 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch4/5: 0.10039 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch4/5: 0.11546 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch4/5: 0.09326 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch4/5: 0.09982 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch4/5: 0.09021 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch4/5: 0.11856 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/5: 0.22744 in 0.11 secs
Val Loss for batch 020/136 @epoch4/5: 0.20428 in 0.11 secs
Val Loss for batch 030/136 @epoch4/5: 0.20156 in 0.1 secs
Val Loss for batch 040/136 @epoch4/5: 0.19118 in 0.11 secs
Val Loss for batch 050/136 @epoch4/5: 0.18334 in 0.11 secs
Val Loss for batch 060/136 @epoch4/5: 0.21221 in 0.11 secs
Val Loss for batch 070/136 @epoch4/5: 0.21634 in 0.11 secs
Val Loss for batch 080/136 @epoch4/5: 0.17311 in 0.11 secs
Val Loss for batch 090/136 @epoch4/5: 0.2346 in 0.1 secs
Val Loss for batch 100/136 @epoch4/5: 0.21114 in 0.1 secs
Val Loss for batch 110/136 @epoch4/5: 0.18121 in 0.1 secs
Val Loss for batch 120/136 @epoch4/5: 0.21477 in 0.11 secs
Val Loss for batch 130/136 @epoch4/5: 0.23148 in 0.11 secs
ROC_AUC_SCORE: {'Atelectasis': 0.740984428674531, 'Cardiomegaly': 0.8435563080495356, 'Consolidation': 0.7217269444921927, 'Edema': 0.8697830622428891, 'Effusion': 0.8608241573318164, 'Emphysema': 0.8313229570144647, 'Fibrosis': 0.73544956725171, 'Hernia': 0.7616045608526811, 'Infiltration': 0.6281828105220278, 'Mass': 0.7621465428009747, 'Nodule': 0.6410641908315258, 'Pleural_Thickening': 0.6805339556919113, 'Pneumonia': 0.6425641924852866, 'Pneumothorax': 0.7377973427101947, 'none': 0.7376714839435183}
AVG Loss in validation set: 0.20592137389970058
0.7469672157822672
Model saved to /scratch/group4/out/0/ft_resnet_34_adam_steplr/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/5: 0.10667 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch5/5: 0.09187 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch5/5: 0.1039 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch5/5: 0.10563 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch5/5: 0.12138 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch5/5: 0.10037 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch5/5: 0.13221 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch5/5: 0.10672 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch5/5: 0.10401 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch5/5: 0.09743 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch5/5: 0.12997 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch5/5: 0.12554 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch5/5: 0.14364 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch5/5: 0.10945 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch5/5: 0.10028 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch5/5: 0.11415 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch5/5: 0.10979 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch5/5: 0.11223 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch5/5: 0.08737 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch5/5: 0.12406 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch5/5: 0.10563 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch5/5: 0.10586 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch5/5: 0.12166 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch5/5: 0.09882 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch5/5: 0.10342 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch5/5: 0.1042 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch5/5: 0.11399 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch5/5: 0.12188 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch5/5: 0.08452 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch5/5: 0.09295 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch5/5: 0.09661 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch5/5: 0.09922 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch5/5: 0.11422 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch5/5: 0.1002 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch5/5: 0.09211 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch5/5: 0.11233 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch5/5: 0.09236 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch5/5: 0.11708 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch5/5: 0.14569 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch5/5: 0.10524 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch5/5: 0.11845 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch5/5: 0.10883 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch5/5: 0.11016 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch5/5: 0.12498 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch5/5: 0.09573 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch5/5: 0.09693 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch5/5: 0.09971 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch5/5: 0.09129 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch5/5: 0.09491 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch5/5: 0.102 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch5/5: 0.10196 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch5/5: 0.1119 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch5/5: 0.10501 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch5/5: 0.10455 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/5: 0.23534 in 0.11 secs
Val Loss for batch 020/136 @epoch5/5: 0.21633 in 0.11 secs
Val Loss for batch 030/136 @epoch5/5: 0.20478 in 0.11 secs
Val Loss for batch 040/136 @epoch5/5: 0.19377 in 0.1 secs
Val Loss for batch 050/136 @epoch5/5: 0.18259 in 0.1 secs
Val Loss for batch 060/136 @epoch5/5: 0.21106 in 0.1 secs
Val Loss for batch 070/136 @epoch5/5: 0.22207 in 0.1 secs
Val Loss for batch 080/136 @epoch5/5: 0.18487 in 0.1 secs
Val Loss for batch 090/136 @epoch5/5: 0.2364 in 0.1 secs
Val Loss for batch 100/136 @epoch5/5: 0.22339 in 0.1 secs
Val Loss for batch 110/136 @epoch5/5: 0.18419 in 0.11 secs
Val Loss for batch 120/136 @epoch5/5: 0.21568 in 0.11 secs
Val Loss for batch 130/136 @epoch5/5: 0.22955 in 0.1 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7362880456526307, 'Cardiomegaly': 0.8539433049535603, 'Consolidation': 0.7190116557045256, 'Edema': 0.8722834663325569, 'Effusion': 0.8637593485014103, 'Emphysema': 0.8278008779428675, 'Fibrosis': 0.734967780827208, 'Hernia': 0.7634346856151367, 'Infiltration': 0.6164510250878695, 'Mass': 0.7660783577769562, 'Nodule': 0.6307925511773713, 'Pleural_Thickening': 0.6957461893602955, 'Pneumonia': 0.6426574107794519, 'Pneumothorax': 0.7536452673878454, 'none': 0.7353571170981643}
AVG Loss in validation set: 0.2113737946189337
0.7483471405071205
Model saved to /scratch/group4/out/0/ft_resnet_34_adam_steplr/models/model_weights_epoch_5.pth
Model saved to /scratch/group4/out/0/ft_resnet_34_adam_steplr/models/model_weights_final_0.pth
