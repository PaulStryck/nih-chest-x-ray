-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch1/10: 0.29078 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch1/10: 0.27403 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch1/10: 0.24083 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch1/10: 0.22507 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch1/10: 0.22285 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch1/10: 0.21376 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch1/10: 0.216 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch1/10: 0.23005 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch1/10: 0.20049 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch1/10: 0.21065 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch1/10: 0.21618 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch1/10: 0.22229 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch1/10: 0.22783 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch1/10: 0.21987 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch1/10: 0.20237 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch1/10: 0.2276 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch1/10: 0.18531 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch1/10: 0.22971 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch1/10: 0.20202 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch1/10: 0.20265 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch1/10: 0.19011 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch1/10: 0.16921 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch1/10: 0.17896 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch1/10: 0.16122 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch1/10: 0.20705 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch1/10: 0.17391 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch1/10: 0.16241 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch1/10: 0.17303 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch1/10: 0.17783 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch1/10: 0.18023 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch1/10: 0.18169 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch1/10: 0.21524 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch1/10: 0.17445 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch1/10: 0.18672 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch1/10: 0.19252 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch1/10: 0.17082 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch1/10: 0.1505 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch1/10: 0.14052 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch1/10: 0.17849 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch1/10: 0.153 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch1/10: 0.21239 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch1/10: 0.18054 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch1/10: 0.20559 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch1/10: 0.17818 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch1/10: 0.1803 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch1/10: 0.1559 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch1/10: 0.16846 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch1/10: 0.15287 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch1/10: 0.16229 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch1/10: 0.13819 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch1/10: 0.1453 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch1/10: 0.14843 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch1/10: 0.15607 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch1/10: 0.15484 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch1/10: 0.22048 in 0.09 secs
Val Loss for batch 040/271 @epoch1/10: 0.21262 in 0.09 secs
Val Loss for batch 060/271 @epoch1/10: 0.23192 in 0.09 secs
Val Loss for batch 080/271 @epoch1/10: 0.224 in 0.09 secs
Val Loss for batch 100/271 @epoch1/10: 0.23656 in 0.09 secs
Val Loss for batch 120/271 @epoch1/10: 0.21321 in 0.09 secs
Val Loss for batch 140/271 @epoch1/10: 0.25254 in 0.09 secs
Val Loss for batch 160/271 @epoch1/10: 0.27747 in 0.09 secs
Val Loss for batch 180/271 @epoch1/10: 0.24 in 0.09 secs
Val Loss for batch 200/271 @epoch1/10: 0.19324 in 0.09 secs
Val Loss for batch 220/271 @epoch1/10: 0.20491 in 0.09 secs
Val Loss for batch 240/271 @epoch1/10: 0.18469 in 0.09 secs
Val Loss for batch 260/271 @epoch1/10: 0.20649 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7307250702634573, 'Cardiomegaly': 0.8673559826723175, 'Consolidation': 0.7382419237890804, 'Edema': 0.8621397232681894, 'Effusion': 0.8568882883068796, 'Emphysema': 0.833852939565505, 'Fibrosis': 0.7326345401202302, 'Hernia': 0.7783470340781907, 'Infiltration': 0.6333822863648533, 'Mass': 0.7331288652309507, 'Nodule': 0.6190170343854245, 'Pleural_Thickening': 0.691654293021051, 'Pneumonia': 0.6144771269032794, 'Pneumothorax': 0.7543546450838401, 'none': 0.7403317945463442}
AVG Loss in validation set: 0.22939068513009156
0.7461571252180892
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch2/10: 0.13944 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch2/10: 0.15156 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch2/10: 0.11566 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch2/10: 0.1424 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch2/10: 0.15584 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch2/10: 0.14163 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch2/10: 0.14558 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch2/10: 0.13665 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch2/10: 0.12022 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch2/10: 0.12279 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch2/10: 0.17077 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch2/10: 0.12502 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch2/10: 0.13862 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch2/10: 0.11494 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch2/10: 0.1254 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch2/10: 0.1277 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch2/10: 0.12609 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch2/10: 0.15124 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch2/10: 0.12629 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch2/10: 0.14304 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch2/10: 0.13396 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch2/10: 0.14384 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch2/10: 0.14952 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch2/10: 0.15631 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch2/10: 0.14298 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch2/10: 0.19123 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch2/10: 0.11534 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch2/10: 0.12534 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch2/10: 0.10294 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch2/10: 0.11635 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch2/10: 0.12937 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch2/10: 0.14709 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch2/10: 0.10669 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch2/10: 0.14268 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch2/10: 0.12123 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch2/10: 0.10316 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch2/10: 0.13414 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch2/10: 0.153 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch2/10: 0.10854 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch2/10: 0.12954 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch2/10: 0.12119 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch2/10: 0.12392 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch2/10: 0.10501 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch2/10: 0.11352 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch2/10: 0.11546 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch2/10: 0.12693 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch2/10: 0.1025 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch2/10: 0.10303 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch2/10: 0.11484 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch2/10: 0.13516 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch2/10: 0.12064 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch2/10: 0.12322 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch2/10: 0.13434 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch2/10: 0.11033 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch2/10: 0.19293 in 0.09 secs
Val Loss for batch 040/271 @epoch2/10: 0.1805 in 0.09 secs
Val Loss for batch 060/271 @epoch2/10: 0.21889 in 0.09 secs
Val Loss for batch 080/271 @epoch2/10: 0.20836 in 0.09 secs
Val Loss for batch 100/271 @epoch2/10: 0.21824 in 0.09 secs
Val Loss for batch 120/271 @epoch2/10: 0.22085 in 0.09 secs
Val Loss for batch 140/271 @epoch2/10: 0.26215 in 0.09 secs
Val Loss for batch 160/271 @epoch2/10: 0.27615 in 0.09 secs
Val Loss for batch 180/271 @epoch2/10: 0.21565 in 0.09 secs
Val Loss for batch 200/271 @epoch2/10: 0.14079 in 0.09 secs
Val Loss for batch 220/271 @epoch2/10: 0.18251 in 0.09 secs
Val Loss for batch 240/271 @epoch2/10: 0.17245 in 0.09 secs
Val Loss for batch 260/271 @epoch2/10: 0.18012 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7528431978704369, 'Cardiomegaly': 0.8528349548235971, 'Consolidation': 0.7103496550763584, 'Edema': 0.8590560872378428, 'Effusion': 0.8579641768472442, 'Emphysema': 0.8330915370359633, 'Fibrosis': 0.733091584924192, 'Hernia': 0.7975821079850257, 'Infiltration': 0.6404217464278409, 'Mass': 0.7437907864889858, 'Nodule': 0.6412062421247144, 'Pleural_Thickening': 0.6619903951072185, 'Pneumonia': 0.6724244987581441, 'Pneumothorax': 0.8005482377282709, 'none': 0.7361475127638524}
AVG Loss in validation set: 0.2121303730673995
0.754085372031131
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch3/10: 0.10064 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch3/10: 0.14672 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch3/10: 0.08886 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch3/10: 0.11004 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch3/10: 0.09715 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch3/10: 0.09894 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch3/10: 0.09634 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch3/10: 0.07989 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch3/10: 0.13335 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch3/10: 0.10089 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch3/10: 0.09564 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch3/10: 0.09847 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch3/10: 0.07476 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch3/10: 0.09168 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch3/10: 0.08893 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch3/10: 0.09451 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch3/10: 0.09752 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch3/10: 0.09641 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch3/10: 0.09802 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch3/10: 0.07349 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch3/10: 0.0786 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch3/10: 0.05667 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch3/10: 0.11361 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch3/10: 0.10763 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch3/10: 0.07342 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch3/10: 0.10385 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch3/10: 0.07833 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch3/10: 0.07568 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch3/10: 0.08 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch3/10: 0.09919 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch3/10: 0.0742 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch3/10: 0.07643 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch3/10: 0.09606 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch3/10: 0.08409 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch3/10: 0.08476 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch3/10: 0.08318 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch3/10: 0.07377 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch3/10: 0.07949 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch3/10: 0.08492 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch3/10: 0.0545 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch3/10: 0.09497 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch3/10: 0.08452 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch3/10: 0.08589 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch3/10: 0.08347 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch3/10: 0.07978 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch3/10: 0.0745 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch3/10: 0.07519 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch3/10: 0.04713 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch3/10: 0.08512 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch3/10: 0.10541 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch3/10: 0.08535 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch3/10: 0.08066 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch3/10: 0.08651 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch3/10: 0.08725 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch3/10: 0.18189 in 0.09 secs
Val Loss for batch 040/271 @epoch3/10: 0.16513 in 0.09 secs
Val Loss for batch 060/271 @epoch3/10: 0.22565 in 0.09 secs
Val Loss for batch 080/271 @epoch3/10: 0.2148 in 0.09 secs
Val Loss for batch 100/271 @epoch3/10: 0.22732 in 0.09 secs
Val Loss for batch 120/271 @epoch3/10: 0.21394 in 0.09 secs
Val Loss for batch 140/271 @epoch3/10: 0.25572 in 0.09 secs
Val Loss for batch 160/271 @epoch3/10: 0.27715 in 0.09 secs
Val Loss for batch 180/271 @epoch3/10: 0.20463 in 0.09 secs
Val Loss for batch 200/271 @epoch3/10: 0.12741 in 0.09 secs
Val Loss for batch 220/271 @epoch3/10: 0.16808 in 0.09 secs
Val Loss for batch 240/271 @epoch3/10: 0.14331 in 0.09 secs
Val Loss for batch 260/271 @epoch3/10: 0.16865 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7499215170976488, 'Cardiomegaly': 0.8482778058472084, 'Consolidation': 0.6916543430884183, 'Edema': 0.8698376292849948, 'Effusion': 0.8551923893304403, 'Emphysema': 0.8524905486772962, 'Fibrosis': 0.70137032935058, 'Hernia': 0.8095712245764347, 'Infiltration': 0.6326731245520621, 'Mass': 0.7590760935167589, 'Nodule': 0.6763442753670635, 'Pleural_Thickening': 0.6920264999066323, 'Pneumonia': 0.6254493853712968, 'Pneumothorax': 0.80883874287042, 'none': 0.7348864453251058}
AVG Loss in validation set: 0.20491644192419833
0.7551945649169468
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch4/10: 0.09855 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch4/10: 0.09207 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch4/10: 0.10522 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch4/10: 0.08663 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch4/10: 0.05793 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch4/10: 0.06698 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch4/10: 0.08656 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch4/10: 0.08605 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch4/10: 0.08226 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch4/10: 0.09456 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch4/10: 0.07034 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch4/10: 0.09575 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch4/10: 0.09018 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch4/10: 0.05765 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch4/10: 0.10235 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch4/10: 0.09802 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch4/10: 0.09401 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch4/10: 0.08867 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch4/10: 0.07271 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch4/10: 0.07265 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch4/10: 0.06979 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch4/10: 0.07832 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch4/10: 0.10437 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch4/10: 0.08761 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch4/10: 0.05922 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch4/10: 0.07579 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch4/10: 0.11933 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch4/10: 0.05813 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch4/10: 0.0794 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch4/10: 0.06586 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch4/10: 0.08693 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch4/10: 0.0939 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch4/10: 0.05828 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch4/10: 0.06967 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch4/10: 0.0689 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch4/10: 0.05369 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch4/10: 0.0735 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch4/10: 0.06606 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch4/10: 0.06878 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch4/10: 0.08607 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch4/10: 0.07988 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch4/10: 0.07848 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch4/10: 0.06802 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch4/10: 0.0805 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch4/10: 0.07924 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch4/10: 0.07883 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch4/10: 0.04601 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch4/10: 0.07169 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch4/10: 0.07785 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch4/10: 0.07126 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch4/10: 0.0448 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch4/10: 0.05897 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch4/10: 0.06542 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch4/10: 0.08749 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch4/10: 0.19345 in 0.09 secs
Val Loss for batch 040/271 @epoch4/10: 0.19526 in 0.09 secs
Val Loss for batch 060/271 @epoch4/10: 0.22184 in 0.09 secs
Val Loss for batch 080/271 @epoch4/10: 0.23622 in 0.09 secs
Val Loss for batch 100/271 @epoch4/10: 0.23863 in 0.09 secs
Val Loss for batch 120/271 @epoch4/10: 0.20755 in 0.09 secs
Val Loss for batch 140/271 @epoch4/10: 0.28027 in 0.09 secs
Val Loss for batch 160/271 @epoch4/10: 0.28639 in 0.09 secs
Val Loss for batch 180/271 @epoch4/10: 0.18901 in 0.09 secs
Val Loss for batch 200/271 @epoch4/10: 0.15272 in 0.09 secs
Val Loss for batch 220/271 @epoch4/10: 0.1821 in 0.09 secs
Val Loss for batch 240/271 @epoch4/10: 0.15007 in 0.09 secs
Val Loss for batch 260/271 @epoch4/10: 0.16464 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7488812235248936, 'Cardiomegaly': 0.8339873895198743, 'Consolidation': 0.7218078689290162, 'Edema': 0.8612353966194681, 'Effusion': 0.8451746421074974, 'Emphysema': 0.849640154543647, 'Fibrosis': 0.6905005066135786, 'Hernia': 0.8548492918065685, 'Infiltration': 0.6294813424182863, 'Mass': 0.7530719978451267, 'Nodule': 0.6500224299295146, 'Pleural_Thickening': 0.6763700698049175, 'Pneumonia': 0.6662925538137576, 'Pneumothorax': 0.801339287285924, 'none': 0.7290860009271058}
AVG Loss in validation set: 0.21178182081194097
0.7559038681972907
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch5/10: 0.09223 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch5/10: 0.06538 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch5/10: 0.07254 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch5/10: 0.06529 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch5/10: 0.07526 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch5/10: 0.0443 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch5/10: 0.06352 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch5/10: 0.09514 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch5/10: 0.08463 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch5/10: 0.06734 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch5/10: 0.07488 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch5/10: 0.07417 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch5/10: 0.06866 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch5/10: 0.06461 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch5/10: 0.07248 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch5/10: 0.07515 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch5/10: 0.07685 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch5/10: 0.04749 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch5/10: 0.0616 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch5/10: 0.06544 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch5/10: 0.03733 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch5/10: 0.05428 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch5/10: 0.04615 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch5/10: 0.0774 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch5/10: 0.07554 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch5/10: 0.03203 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch5/10: 0.06373 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch5/10: 0.08008 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch5/10: 0.04613 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch5/10: 0.06758 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch5/10: 0.05411 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch5/10: 0.05119 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch5/10: 0.06166 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch5/10: 0.06798 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch5/10: 0.03069 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch5/10: 0.05342 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch5/10: 0.05202 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch5/10: 0.03396 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch5/10: 0.06382 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch5/10: 0.04675 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch5/10: 0.06725 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch5/10: 0.05914 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch5/10: 0.05608 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch5/10: 0.02932 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch5/10: 0.04798 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch5/10: 0.07064 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch5/10: 0.06557 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch5/10: 0.06808 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch5/10: 0.05998 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch5/10: 0.0316 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch5/10: 0.0582 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch5/10: 0.07081 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch5/10: 0.05063 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch5/10: 0.05054 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch5/10: 0.19875 in 0.09 secs
Val Loss for batch 040/271 @epoch5/10: 0.17914 in 0.09 secs
Val Loss for batch 060/271 @epoch5/10: 0.23414 in 0.09 secs
Val Loss for batch 080/271 @epoch5/10: 0.23277 in 0.09 secs
Val Loss for batch 100/271 @epoch5/10: 0.24259 in 0.09 secs
Val Loss for batch 120/271 @epoch5/10: 0.21392 in 0.09 secs
Val Loss for batch 140/271 @epoch5/10: 0.27859 in 0.09 secs
Val Loss for batch 160/271 @epoch5/10: 0.30996 in 0.09 secs
Val Loss for batch 180/271 @epoch5/10: 0.20255 in 0.09 secs
Val Loss for batch 200/271 @epoch5/10: 0.1395 in 0.09 secs
Val Loss for batch 220/271 @epoch5/10: 0.1717 in 0.09 secs
Val Loss for batch 240/271 @epoch5/10: 0.14496 in 0.09 secs
Val Loss for batch 260/271 @epoch5/10: 0.19504 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7414525012338855, 'Cardiomegaly': 0.838387368909991, 'Consolidation': 0.7376487022350395, 'Edema': 0.8570037851220371, 'Effusion': 0.8464025022994739, 'Emphysema': 0.8347908992033461, 'Fibrosis': 0.7297931337471348, 'Hernia': 0.882727413067809, 'Infiltration': 0.645498697577833, 'Mass': 0.757126319163283, 'Nodule': 0.6847424139266023, 'Pleural_Thickening': 0.6699701330076019, 'Pneumonia': 0.6561240146143048, 'Pneumothorax': 0.8092353992288159, 'none': 0.7255798585926416}
AVG Loss in validation set: 0.2128995240037771
0.763635948809797
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch6/10: 0.05598 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch6/10: 0.06013 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch6/10: 0.04614 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch6/10: 0.0509 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch6/10: 0.05095 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch6/10: 0.04252 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch6/10: 0.07403 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch6/10: 0.04331 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch6/10: 0.04686 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch6/10: 0.03674 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch6/10: 0.05726 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch6/10: 0.03534 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch6/10: 0.04085 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch6/10: 0.05604 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch6/10: 0.05227 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch6/10: 0.03512 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch6/10: 0.03743 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch6/10: 0.0459 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch6/10: 0.03648 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch6/10: 0.03596 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch6/10: 0.04017 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch6/10: 0.04405 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch6/10: 0.05712 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch6/10: 0.05589 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch6/10: 0.04579 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch6/10: 0.05293 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch6/10: 0.04396 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch6/10: 0.03859 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch6/10: 0.05415 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch6/10: 0.04128 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch6/10: 0.05907 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch6/10: 0.0366 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch6/10: 0.04299 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch6/10: 0.04458 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch6/10: 0.02686 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch6/10: 0.04258 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch6/10: 0.03559 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch6/10: 0.05296 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch6/10: 0.04394 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch6/10: 0.03928 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch6/10: 0.04705 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch6/10: 0.05618 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch6/10: 0.05185 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch6/10: 0.05477 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch6/10: 0.04241 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch6/10: 0.02996 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch6/10: 0.04446 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch6/10: 0.04217 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch6/10: 0.03825 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch6/10: 0.04587 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch6/10: 0.0336 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch6/10: 0.0323 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch6/10: 0.02495 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch6/10: 0.03513 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch6/10: 0.20637 in 0.09 secs
Val Loss for batch 040/271 @epoch6/10: 0.16989 in 0.09 secs
Val Loss for batch 060/271 @epoch6/10: 0.21536 in 0.09 secs
Val Loss for batch 080/271 @epoch6/10: 0.2341 in 0.09 secs
Val Loss for batch 100/271 @epoch6/10: 0.22636 in 0.09 secs
Val Loss for batch 120/271 @epoch6/10: 0.21947 in 0.09 secs
Val Loss for batch 140/271 @epoch6/10: 0.29623 in 0.09 secs
Val Loss for batch 160/271 @epoch6/10: 0.26299 in 0.09 secs
Val Loss for batch 180/271 @epoch6/10: 0.20366 in 0.09 secs
Val Loss for batch 200/271 @epoch6/10: 0.12921 in 0.09 secs
Val Loss for batch 220/271 @epoch6/10: 0.18255 in 0.08 secs
Val Loss for batch 240/271 @epoch6/10: 0.12143 in 0.09 secs
Val Loss for batch 260/271 @epoch6/10: 0.17867 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7569060773480663, 'Cardiomegaly': 0.8453014849113353, 'Consolidation': 0.7399904552008914, 'Edema': 0.859490137842164, 'Effusion': 0.8446743590953044, 'Emphysema': 0.8436409245733988, 'Fibrosis': 0.7096389990097745, 'Hernia': 0.8517695187372158, 'Infiltration': 0.6428913723936984, 'Mass': 0.7663099572983831, 'Nodule': 0.6794456166210475, 'Pleural_Thickening': 0.7096915969690376, 'Pneumonia': 0.6555112419459342, 'Pneumothorax': 0.8089175511008762, 'none': 0.7226131608231992}
AVG Loss in validation set: 0.21126812171506154
0.7652985209319376
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch7/10: 0.03551 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch7/10: 0.03409 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch7/10: 0.0409 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch7/10: 0.03653 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch7/10: 0.04935 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch7/10: 0.0358 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch7/10: 0.03743 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch7/10: 0.03928 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch7/10: 0.02353 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch7/10: 0.06279 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch7/10: 0.04308 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch7/10: 0.05581 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch7/10: 0.03188 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch7/10: 0.03701 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch7/10: 0.03595 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch7/10: 0.05973 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch7/10: 0.03644 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch7/10: 0.0367 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch7/10: 0.03936 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch7/10: 0.05117 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch7/10: 0.03134 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch7/10: 0.04718 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch7/10: 0.03183 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch7/10: 0.03887 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch7/10: 0.0515 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch7/10: 0.04445 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch7/10: 0.03806 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch7/10: 0.03201 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch7/10: 0.0369 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch7/10: 0.04906 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch7/10: 0.04058 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch7/10: 0.02651 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch7/10: 0.01643 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch7/10: 0.04621 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch7/10: 0.02266 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch7/10: 0.05212 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch7/10: 0.0329 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch7/10: 0.04154 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch7/10: 0.04183 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch7/10: 0.02601 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch7/10: 0.0422 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch7/10: 0.0594 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch7/10: 0.05098 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch7/10: 0.01694 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch7/10: 0.0408 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch7/10: 0.04029 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch7/10: 0.03665 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch7/10: 0.03785 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch7/10: 0.04506 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch7/10: 0.04347 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch7/10: 0.04434 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch7/10: 0.01968 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch7/10: 0.0575 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch7/10: 0.04131 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch7/10: 0.21756 in 0.09 secs
Val Loss for batch 040/271 @epoch7/10: 0.1841 in 0.09 secs
Val Loss for batch 060/271 @epoch7/10: 0.22948 in 0.09 secs
Val Loss for batch 080/271 @epoch7/10: 0.25709 in 0.09 secs
Val Loss for batch 100/271 @epoch7/10: 0.24009 in 0.09 secs
Val Loss for batch 120/271 @epoch7/10: 0.21649 in 0.09 secs
Val Loss for batch 140/271 @epoch7/10: 0.28605 in 0.09 secs
Val Loss for batch 160/271 @epoch7/10: 0.29235 in 0.09 secs
Val Loss for batch 180/271 @epoch7/10: 0.193 in 0.09 secs
Val Loss for batch 200/271 @epoch7/10: 0.12845 in 0.09 secs
Val Loss for batch 220/271 @epoch7/10: 0.16317 in 0.09 secs
Val Loss for batch 240/271 @epoch7/10: 0.12873 in 0.09 secs
Val Loss for batch 260/271 @epoch7/10: 0.18323 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7504068936232728, 'Cardiomegaly': 0.8324935574888856, 'Consolidation': 0.7423416300714426, 'Edema': 0.8713586613172312, 'Effusion': 0.8522632684075847, 'Emphysema': 0.8499904598971595, 'Fibrosis': 0.701667972016069, 'Hernia': 0.8458415344834241, 'Infiltration': 0.6555247277158732, 'Mass': 0.7692124789464556, 'Nodule': 0.6724707243684108, 'Pleural_Thickening': 0.6994582019049119, 'Pneumonia': 0.6718465970447428, 'Pneumothorax': 0.8157077829036937, 'none': 0.7315810934971976}
AVG Loss in validation set: 0.21784180462002148
0.766470320727797
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch8/10: 0.03093 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch8/10: 0.04452 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch8/10: 0.03389 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch8/10: 0.03458 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch8/10: 0.0261 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch8/10: 0.03032 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch8/10: 0.03373 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch8/10: 0.02022 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch8/10: 0.03109 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch8/10: 0.06306 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch8/10: 0.03686 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch8/10: 0.02189 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch8/10: 0.0391 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch8/10: 0.0297 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch8/10: 0.01931 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch8/10: 0.01625 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch8/10: 0.04665 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch8/10: 0.04216 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch8/10: 0.0352 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch8/10: 0.02229 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch8/10: 0.0311 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch8/10: 0.03999 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch8/10: 0.03379 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch8/10: 0.03338 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch8/10: 0.04198 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch8/10: 0.02838 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch8/10: 0.01994 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch8/10: 0.04726 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch8/10: 0.03073 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch8/10: 0.05239 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch8/10: 0.02792 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch8/10: 0.03797 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch8/10: 0.01873 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch8/10: 0.03644 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch8/10: 0.02924 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch8/10: 0.03548 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch8/10: 0.0447 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch8/10: 0.0291 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch8/10: 0.03194 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch8/10: 0.03665 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch8/10: 0.04461 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch8/10: 0.02908 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch8/10: 0.03059 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch8/10: 0.03284 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch8/10: 0.04072 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch8/10: 0.0313 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch8/10: 0.01624 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch8/10: 0.01468 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch8/10: 0.02092 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch8/10: 0.0374 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch8/10: 0.01562 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch8/10: 0.02884 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch8/10: 0.03896 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch8/10: 0.02009 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch8/10: 0.24405 in 0.09 secs
Val Loss for batch 040/271 @epoch8/10: 0.2051 in 0.08 secs
Val Loss for batch 060/271 @epoch8/10: 0.26009 in 0.09 secs
Val Loss for batch 080/271 @epoch8/10: 0.25866 in 0.09 secs
Val Loss for batch 100/271 @epoch8/10: 0.24343 in 0.09 secs
Val Loss for batch 120/271 @epoch8/10: 0.21268 in 0.09 secs
Val Loss for batch 140/271 @epoch8/10: 0.328 in 0.09 secs
Val Loss for batch 160/271 @epoch8/10: 0.3032 in 0.09 secs
Val Loss for batch 180/271 @epoch8/10: 0.20549 in 0.09 secs
Val Loss for batch 200/271 @epoch8/10: 0.13871 in 0.09 secs
Val Loss for batch 220/271 @epoch8/10: 0.19024 in 0.09 secs
Val Loss for batch 240/271 @epoch8/10: 0.15052 in 0.09 secs
Val Loss for batch 260/271 @epoch8/10: 0.15641 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.745139902681609, 'Cardiomegaly': 0.8094262531462756, 'Consolidation': 0.7302654621649078, 'Edema': 0.8495422173679164, 'Effusion': 0.8431080450637957, 'Emphysema': 0.8317312447697465, 'Fibrosis': 0.6867699675330277, 'Hernia': 0.8803403959708233, 'Infiltration': 0.6482666758642776, 'Mass': 0.7588812475310933, 'Nodule': 0.681722160876312, 'Pleural_Thickening': 0.6989066414423406, 'Pneumonia': 0.663557152370325, 'Pneumothorax': 0.8104416127573777, 'none': 0.7206061420527736}
AVG Loss in validation set: 0.2244552989910997
0.7598642128242734
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch9/10: 0.01867 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch9/10: 0.03163 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch9/10: 0.03152 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch9/10: 0.0223 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch9/10: 0.02608 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch9/10: 0.0235 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch9/10: 0.02253 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch9/10: 0.03309 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch9/10: 0.0186 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch9/10: 0.02003 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch9/10: 0.02389 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch9/10: 0.03136 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch9/10: 0.04935 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch9/10: 0.05003 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch9/10: 0.03275 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch9/10: 0.02304 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch9/10: 0.0284 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch9/10: 0.02056 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch9/10: 0.0224 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch9/10: 0.01896 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch9/10: 0.04269 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch9/10: 0.01804 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch9/10: 0.02603 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch9/10: 0.03152 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch9/10: 0.0385 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch9/10: 0.03406 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch9/10: 0.03233 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch9/10: 0.014 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch9/10: 0.02384 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch9/10: 0.01741 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch9/10: 0.02051 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch9/10: 0.02029 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch9/10: 0.02968 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch9/10: 0.01454 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch9/10: 0.01834 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch9/10: 0.02573 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch9/10: 0.02669 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch9/10: 0.03162 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch9/10: 0.02114 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch9/10: 0.02432 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch9/10: 0.01681 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch9/10: 0.04161 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch9/10: 0.01893 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch9/10: 0.02204 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch9/10: 0.02109 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch9/10: 0.02405 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch9/10: 0.02316 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch9/10: 0.01763 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch9/10: 0.03285 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch9/10: 0.02187 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch9/10: 0.03114 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch9/10: 0.01705 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch9/10: 0.02386 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch9/10: 0.03431 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch9/10: 0.20535 in 0.09 secs
Val Loss for batch 040/271 @epoch9/10: 0.19853 in 0.09 secs
Val Loss for batch 060/271 @epoch9/10: 0.26371 in 0.09 secs
Val Loss for batch 080/271 @epoch9/10: 0.25198 in 0.09 secs
Val Loss for batch 100/271 @epoch9/10: 0.23325 in 0.09 secs
Val Loss for batch 120/271 @epoch9/10: 0.23129 in 0.09 secs
Val Loss for batch 140/271 @epoch9/10: 0.29537 in 0.09 secs
Val Loss for batch 160/271 @epoch9/10: 0.28171 in 0.09 secs
Val Loss for batch 180/271 @epoch9/10: 0.20692 in 0.09 secs
Val Loss for batch 200/271 @epoch9/10: 0.13199 in 0.09 secs
Val Loss for batch 220/271 @epoch9/10: 0.18495 in 0.09 secs
Val Loss for batch 240/271 @epoch9/10: 0.1267 in 0.09 secs
Val Loss for batch 260/271 @epoch9/10: 0.17538 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7505132845032435, 'Cardiomegaly': 0.8168621529484053, 'Consolidation': 0.7227441707085273, 'Edema': 0.8548572095718088, 'Effusion': 0.8482499675715195, 'Emphysema': 0.8337215248996684, 'Fibrosis': 0.7160215250391317, 'Hernia': 0.8450735208984601, 'Infiltration': 0.647390791296735, 'Mass': 0.7620400960589208, 'Nodule': 0.6754719061512819, 'Pleural_Thickening': 0.7033161990927117, 'Pneumonia': 0.668946120999964, 'Pneumothorax': 0.8061529764817532, 'none': 0.7176264933815396}
AVG Loss in validation set: 0.2284676949706719
0.7608115318730093
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch10/10: 0.02769 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch10/10: 0.02497 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch10/10: 0.03575 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch10/10: 0.01826 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch10/10: 0.03838 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch10/10: 0.04789 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch10/10: 0.02322 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch10/10: 0.01618 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch10/10: 0.02795 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch10/10: 0.02446 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch10/10: 0.02771 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch10/10: 0.0219 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch10/10: 0.0181 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch10/10: 0.03473 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch10/10: 0.02774 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch10/10: 0.02221 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch10/10: 0.02357 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch10/10: 0.03669 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch10/10: 0.01692 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch10/10: 0.02054 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch10/10: 0.02867 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch10/10: 0.02063 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch10/10: 0.01744 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch10/10: 0.02298 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch10/10: 0.04616 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch10/10: 0.02466 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch10/10: 0.03444 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch10/10: 0.02191 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch10/10: 0.03634 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch10/10: 0.02791 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch10/10: 0.01096 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch10/10: 0.01551 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch10/10: 0.02872 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch10/10: 0.02232 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch10/10: 0.01783 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch10/10: 0.02864 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch10/10: 0.01895 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch10/10: 0.0263 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch10/10: 0.01983 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch10/10: 0.01396 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch10/10: 0.017 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch10/10: 0.04211 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch10/10: 0.01693 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch10/10: 0.00978 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch10/10: 0.0167 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch10/10: 0.02592 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch10/10: 0.02223 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch10/10: 0.01116 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch10/10: 0.03135 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch10/10: 0.01484 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch10/10: 0.03343 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch10/10: 0.01404 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch10/10: 0.03359 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch10/10: 0.02755 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch10/10: 0.20709 in 0.09 secs
Val Loss for batch 040/271 @epoch10/10: 0.20548 in 0.09 secs
Val Loss for batch 060/271 @epoch10/10: 0.25491 in 0.09 secs
Val Loss for batch 080/271 @epoch10/10: 0.25295 in 0.09 secs
Val Loss for batch 100/271 @epoch10/10: 0.25708 in 0.09 secs
Val Loss for batch 120/271 @epoch10/10: 0.22179 in 0.09 secs
Val Loss for batch 140/271 @epoch10/10: 0.31845 in 0.09 secs
Val Loss for batch 160/271 @epoch10/10: 0.30924 in 0.09 secs
Val Loss for batch 180/271 @epoch10/10: 0.20869 in 0.09 secs
Val Loss for batch 200/271 @epoch10/10: 0.13252 in 0.09 secs
Val Loss for batch 220/271 @epoch10/10: 0.19046 in 0.09 secs
Val Loss for batch 240/271 @epoch10/10: 0.12796 in 0.09 secs
Val Loss for batch 260/271 @epoch10/10: 0.17035 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7500147340254512, 'Cardiomegaly': 0.8133544353930144, 'Consolidation': 0.7292278749098775, 'Edema': 0.8641447795540125, 'Effusion': 0.8503140035022759, 'Emphysema': 0.8325940673200216, 'Fibrosis': 0.6793413218416583, 'Hernia': 0.875884759368608, 'Infiltration': 0.65569867624734, 'Mass': 0.7594831368461045, 'Nodule': 0.6742711932814327, 'Pleural_Thickening': 0.7087533988733111, 'Pneumonia': 0.6743906300619129, 'Pneumothorax': 0.8112682190597228, 'none': 0.722782051575369}
AVG Loss in validation set: 0.23342337587807832
0.7627672307346245
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_steplr_0/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch1/10: 0.27616 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch1/10: 0.29335 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch1/10: 0.26065 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch1/10: 0.24982 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch1/10: 0.25974 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch1/10: 0.24617 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch1/10: 0.2734 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch1/10: 0.25658 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch1/10: 0.24724 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch1/10: 0.26857 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch1/10: 0.27615 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch1/10: 0.26291 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch1/10: 0.2766 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch1/10: 0.26412 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch1/10: 0.25534 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch1/10: 0.25793 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch1/10: 0.24269 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch1/10: 0.2682 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch1/10: 0.25011 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch1/10: 0.25378 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch1/10: 0.25221 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch1/10: 0.23508 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch1/10: 0.2531 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch1/10: 0.22617 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch1/10: 0.25304 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch1/10: 0.2335 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch1/10: 0.24751 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch1/10: 0.23961 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch1/10: 0.24542 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch1/10: 0.24935 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch1/10: 0.24759 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch1/10: 0.26892 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch1/10: 0.24039 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch1/10: 0.25187 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch1/10: 0.24746 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch1/10: 0.25005 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch1/10: 0.23173 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch1/10: 0.2291 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch1/10: 0.24406 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch1/10: 0.2278 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch1/10: 0.26885 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch1/10: 0.23396 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch1/10: 0.24226 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch1/10: 0.23106 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch1/10: 0.24437 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch1/10: 0.22356 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch1/10: 0.23369 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch1/10: 0.21491 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch1/10: 0.2311 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch1/10: 0.21052 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch1/10: 0.22544 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch1/10: 0.20763 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch1/10: 0.21672 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch1/10: 0.20991 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch1/10: 0.23226 in 0.09 secs
Val Loss for batch 040/271 @epoch1/10: 0.19682 in 0.09 secs
Val Loss for batch 060/271 @epoch1/10: 0.22795 in 0.09 secs
Val Loss for batch 080/271 @epoch1/10: 0.23041 in 0.09 secs
Val Loss for batch 100/271 @epoch1/10: 0.21871 in 0.09 secs
Val Loss for batch 120/271 @epoch1/10: 0.20675 in 0.09 secs
Val Loss for batch 140/271 @epoch1/10: 0.22314 in 0.09 secs
Val Loss for batch 160/271 @epoch1/10: 0.25851 in 0.09 secs
Val Loss for batch 180/271 @epoch1/10: 0.22719 in 0.09 secs
Val Loss for batch 200/271 @epoch1/10: 0.16435 in 0.09 secs
Val Loss for batch 220/271 @epoch1/10: 0.20084 in 0.09 secs
Val Loss for batch 240/271 @epoch1/10: 0.19389 in 0.09 secs
Val Loss for batch 260/271 @epoch1/10: 0.18643 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7305124516484347, 'Cardiomegaly': 0.7928872062610981, 'Consolidation': 0.7366639083699285, 'Edema': 0.866618911643751, 'Effusion': 0.8416052982240986, 'Emphysema': 0.7512049521058749, 'Fibrosis': 0.6919011982762489, 'Hernia': 0.7865771294045001, 'Infiltration': 0.5955095217913529, 'Mass': 0.5886784341924208, 'Nodule': 0.5607594687253463, 'Pleural_Thickening': 0.6690045364418272, 'Pneumonia': 0.6327195576563118, 'Pneumothorax': 0.7037008687010623, 'none': 0.7110043365940062}
AVG Loss in validation set: 0.2232314788573217
0.7105959602458755
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch2/10: 0.22755 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch2/10: 0.21235 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch2/10: 0.17798 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch2/10: 0.20817 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch2/10: 0.22375 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch2/10: 0.19568 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch2/10: 0.21582 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch2/10: 0.21795 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch2/10: 0.18874 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch2/10: 0.20515 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch2/10: 0.22074 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch2/10: 0.18766 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch2/10: 0.20003 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch2/10: 0.20067 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch2/10: 0.1909 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch2/10: 0.21122 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch2/10: 0.19819 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch2/10: 0.21084 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch2/10: 0.20364 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch2/10: 0.19612 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch2/10: 0.20697 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch2/10: 0.21593 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch2/10: 0.21632 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch2/10: 0.21429 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch2/10: 0.22366 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch2/10: 0.24945 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch2/10: 0.18873 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch2/10: 0.21695 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch2/10: 0.20296 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch2/10: 0.18216 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch2/10: 0.21106 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch2/10: 0.21232 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch2/10: 0.18401 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch2/10: 0.2143 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch2/10: 0.20919 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch2/10: 0.20041 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch2/10: 0.20326 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch2/10: 0.20286 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch2/10: 0.18134 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch2/10: 0.20546 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch2/10: 0.19688 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch2/10: 0.20817 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch2/10: 0.20377 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch2/10: 0.20321 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch2/10: 0.18312 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch2/10: 0.19841 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch2/10: 0.18625 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch2/10: 0.17909 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch2/10: 0.20705 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch2/10: 0.22667 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch2/10: 0.21022 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch2/10: 0.21464 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch2/10: 0.21673 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch2/10: 0.19377 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch2/10: 0.21783 in 0.09 secs
Val Loss for batch 040/271 @epoch2/10: 0.21088 in 0.09 secs
Val Loss for batch 060/271 @epoch2/10: 0.23207 in 0.09 secs
Val Loss for batch 080/271 @epoch2/10: 0.22901 in 0.09 secs
Val Loss for batch 100/271 @epoch2/10: 0.22664 in 0.09 secs
Val Loss for batch 120/271 @epoch2/10: 0.20335 in 0.09 secs
Val Loss for batch 140/271 @epoch2/10: 0.2279 in 0.09 secs
Val Loss for batch 160/271 @epoch2/10: 0.26961 in 0.09 secs
Val Loss for batch 180/271 @epoch2/10: 0.24785 in 0.09 secs
Val Loss for batch 200/271 @epoch2/10: 0.16229 in 0.09 secs
Val Loss for batch 220/271 @epoch2/10: 0.19603 in 0.09 secs
Val Loss for batch 240/271 @epoch2/10: 0.20421 in 0.09 secs
Val Loss for batch 260/271 @epoch2/10: 0.18582 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7229075940248011, 'Cardiomegaly': 0.8661695685843854, 'Consolidation': 0.7338753318149046, 'Edema': 0.8554092110819295, 'Effusion': 0.8658747361500909, 'Emphysema': 0.7631466328854065, 'Fibrosis': 0.706486378937756, 'Hernia': 0.7198892362317163, 'Infiltration': 0.5885584811494419, 'Mass': 0.6392403665598319, 'Nodule': 0.5673307917690953, 'Pleural_Thickening': 0.6728502309185616, 'Pneumonia': 0.6133514137360065, 'Pneumothorax': 0.7480667340249882, 'none': 0.7242641019346585}
AVG Loss in validation set: 0.22147445934572763
0.7187969077049225
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch3/10: 0.18956 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch3/10: 0.22356 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch3/10: 0.17262 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch3/10: 0.19408 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch3/10: 0.18648 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch3/10: 0.17672 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch3/10: 0.1959 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch3/10: 0.20249 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch3/10: 0.21542 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch3/10: 0.18324 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch3/10: 0.19783 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch3/10: 0.20628 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch3/10: 0.16235 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch3/10: 0.18537 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch3/10: 0.18363 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch3/10: 0.19234 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch3/10: 0.20824 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch3/10: 0.19266 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch3/10: 0.19626 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch3/10: 0.18482 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch3/10: 0.2103 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch3/10: 0.16798 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch3/10: 0.20257 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch3/10: 0.18166 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch3/10: 0.1926 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch3/10: 0.18735 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch3/10: 0.17405 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch3/10: 0.19358 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch3/10: 0.17032 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch3/10: 0.19866 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch3/10: 0.18053 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch3/10: 0.16046 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch3/10: 0.19235 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch3/10: 0.18573 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch3/10: 0.20549 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch3/10: 0.18404 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch3/10: 0.20199 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch3/10: 0.19906 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch3/10: 0.19571 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch3/10: 0.16458 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch3/10: 0.21631 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch3/10: 0.179 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch3/10: 0.17779 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch3/10: 0.19273 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch3/10: 0.19692 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch3/10: 0.20033 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch3/10: 0.17302 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch3/10: 0.15973 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch3/10: 0.19787 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch3/10: 0.20285 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch3/10: 0.17914 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch3/10: 0.19408 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch3/10: 0.17108 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch3/10: 0.19639 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch3/10: 0.21441 in 0.09 secs
Val Loss for batch 040/271 @epoch3/10: 0.21139 in 0.09 secs
Val Loss for batch 060/271 @epoch3/10: 0.22884 in 0.09 secs
Val Loss for batch 080/271 @epoch3/10: 0.22982 in 0.09 secs
Val Loss for batch 100/271 @epoch3/10: 0.23269 in 0.09 secs
Val Loss for batch 120/271 @epoch3/10: 0.20928 in 0.09 secs
Val Loss for batch 140/271 @epoch3/10: 0.2368 in 0.09 secs
Val Loss for batch 160/271 @epoch3/10: 0.27393 in 0.09 secs
Val Loss for batch 180/271 @epoch3/10: 0.24902 in 0.09 secs
Val Loss for batch 200/271 @epoch3/10: 0.16759 in 0.09 secs
Val Loss for batch 220/271 @epoch3/10: 0.20213 in 0.09 secs
Val Loss for batch 240/271 @epoch3/10: 0.20451 in 0.09 secs
Val Loss for batch 260/271 @epoch3/10: 0.18841 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7157365387394339, 'Cardiomegaly': 0.8636352450538204, 'Consolidation': 0.7223302725797994, 'Edema': 0.8323338239770951, 'Effusion': 0.8660560961121199, 'Emphysema': 0.7695578628805333, 'Fibrosis': 0.6825769782368928, 'Hernia': 0.7707325074292771, 'Infiltration': 0.5871017766065383, 'Mass': 0.6324378455201836, 'Nodule': 0.5463191641586185, 'Pleural_Thickening': 0.6630165077112063, 'Pneumonia': 0.6122578999586048, 'Pneumothorax': 0.7430757137375267, 'none': 0.7255571584443555}
AVG Loss in validation set: 0.22528292393717456
0.7147977309072607
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch4/10: 0.19455 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch4/10: 0.19979 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch4/10: 0.20854 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch4/10: 0.22105 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch4/10: 0.18739 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch4/10: 0.17862 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch4/10: 0.18719 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch4/10: 0.20447 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch4/10: 0.19503 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch4/10: 0.2059 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch4/10: 0.1799 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch4/10: 0.19121 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch4/10: 0.19656 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch4/10: 0.18954 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch4/10: 0.19853 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch4/10: 0.21212 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch4/10: 0.20113 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch4/10: 0.21542 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch4/10: 0.20135 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch4/10: 0.1902 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch4/10: 0.20213 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch4/10: 0.2094 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch4/10: 0.21139 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch4/10: 0.21431 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch4/10: 0.19694 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch4/10: 0.20351 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch4/10: 0.22608 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch4/10: 0.16077 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch4/10: 0.19044 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch4/10: 0.17671 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch4/10: 0.21604 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch4/10: 0.19281 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch4/10: 0.18978 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch4/10: 0.17823 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch4/10: 0.18675 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch4/10: 0.15844 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch4/10: 0.16503 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch4/10: 0.199 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch4/10: 0.19757 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch4/10: 0.19678 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch4/10: 0.18363 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch4/10: 0.2058 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch4/10: 0.19553 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch4/10: 0.18793 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch4/10: 0.18736 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch4/10: 0.18234 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch4/10: 0.1665 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch4/10: 0.18009 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch4/10: 0.20982 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch4/10: 0.18178 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch4/10: 0.17415 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch4/10: 0.17996 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch4/10: 0.15956 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch4/10: 0.20011 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch4/10: 0.21301 in 0.09 secs
Val Loss for batch 040/271 @epoch4/10: 0.2089 in 0.09 secs
Val Loss for batch 060/271 @epoch4/10: 0.22954 in 0.09 secs
Val Loss for batch 080/271 @epoch4/10: 0.22416 in 0.09 secs
Val Loss for batch 100/271 @epoch4/10: 0.23405 in 0.09 secs
Val Loss for batch 120/271 @epoch4/10: 0.21104 in 0.09 secs
Val Loss for batch 140/271 @epoch4/10: 0.24225 in 0.09 secs
Val Loss for batch 160/271 @epoch4/10: 0.27081 in 0.09 secs
Val Loss for batch 180/271 @epoch4/10: 0.24443 in 0.09 secs
Val Loss for batch 200/271 @epoch4/10: 0.16538 in 0.09 secs
Val Loss for batch 220/271 @epoch4/10: 0.19932 in 0.09 secs
Val Loss for batch 240/271 @epoch4/10: 0.20473 in 0.09 secs
Val Loss for batch 260/271 @epoch4/10: 0.18529 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7173025260257951, 'Cardiomegaly': 0.867609953343223, 'Consolidation': 0.7338608917218326, 'Edema': 0.8517515327616552, 'Effusion': 0.867517828294144, 'Emphysema': 0.7751921412826032, 'Fibrosis': 0.6733194632771285, 'Hernia': 0.7382289375168847, 'Infiltration': 0.5805541631216204, 'Mass': 0.6452739445172675, 'Nodule': 0.5513891193333702, 'Pleural_Thickening': 0.6526575584930735, 'Pneumonia': 0.6344027842770239, 'Pneumothorax': 0.744729932190723, 'none': 0.725653393606899}
AVG Loss in validation set: 0.22314651491627668
0.7166993411540247
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch5/10: 0.2105 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch5/10: 0.18326 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch5/10: 0.19206 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch5/10: 0.18977 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch5/10: 0.20233 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch5/10: 0.17586 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch5/10: 0.20705 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch5/10: 0.20648 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch5/10: 0.22207 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch5/10: 0.19728 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch5/10: 0.19663 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch5/10: 0.19622 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch5/10: 0.2178 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch5/10: 0.1785 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch5/10: 0.21092 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch5/10: 0.20773 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch5/10: 0.18851 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch5/10: 0.19595 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch5/10: 0.18054 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch5/10: 0.219 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch5/10: 0.18409 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch5/10: 0.1925 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch5/10: 0.19412 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch5/10: 0.18838 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch5/10: 0.19676 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch5/10: 0.17153 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch5/10: 0.18457 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch5/10: 0.20489 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch5/10: 0.18341 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch5/10: 0.17918 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch5/10: 0.20547 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch5/10: 0.17064 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch5/10: 0.16651 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch5/10: 0.18581 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch5/10: 0.16306 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch5/10: 0.16786 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch5/10: 0.19136 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch5/10: 0.172 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch5/10: 0.19479 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch5/10: 0.19165 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch5/10: 0.17904 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch5/10: 0.19069 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch5/10: 0.17344 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch5/10: 0.1822 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch5/10: 0.19047 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch5/10: 0.20807 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch5/10: 0.19966 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch5/10: 0.18878 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch5/10: 0.19099 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch5/10: 0.1928 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch5/10: 0.184 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch5/10: 0.19878 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch5/10: 0.17272 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch5/10: 0.19093 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch5/10: 0.21591 in 0.09 secs
Val Loss for batch 040/271 @epoch5/10: 0.21421 in 0.09 secs
Val Loss for batch 060/271 @epoch5/10: 0.23112 in 0.09 secs
Val Loss for batch 080/271 @epoch5/10: 0.23632 in 0.09 secs
Val Loss for batch 100/271 @epoch5/10: 0.23489 in 0.09 secs
Val Loss for batch 120/271 @epoch5/10: 0.19906 in 0.09 secs
Val Loss for batch 140/271 @epoch5/10: 0.2437 in 0.09 secs
Val Loss for batch 160/271 @epoch5/10: 0.27455 in 0.09 secs
Val Loss for batch 180/271 @epoch5/10: 0.2472 in 0.09 secs
Val Loss for batch 200/271 @epoch5/10: 0.16866 in 0.09 secs
Val Loss for batch 220/271 @epoch5/10: 0.19834 in 0.09 secs
Val Loss for batch 240/271 @epoch5/10: 0.20536 in 0.09 secs
Val Loss for batch 260/271 @epoch5/10: 0.19071 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7211095330918871, 'Cardiomegaly': 0.8699737454694784, 'Consolidation': 0.7290997574883659, 'Edema': 0.8455109369186335, 'Effusion': 0.8646488106117779, 'Emphysema': 0.771018271052479, 'Fibrosis': 0.6829105036348518, 'Hernia': 0.7413550229632203, 'Infiltration': 0.5869869590145274, 'Mass': 0.6448387709559898, 'Nodule': 0.5499823661410695, 'Pleural_Thickening': 0.6487865935827994, 'Pneumonia': 0.5982851926676505, 'Pneumothorax': 0.748828563683538, 'none': 0.7253944099235924}
AVG Loss in validation set: 0.22534390172085386
0.7145239305197335
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch6/10: 0.2134 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch6/10: 0.20785 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch6/10: 0.18347 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch6/10: 0.20373 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch6/10: 0.20106 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch6/10: 0.19646 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch6/10: 0.18248 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch6/10: 0.15212 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch6/10: 0.18432 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch6/10: 0.18705 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch6/10: 0.1967 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch6/10: 0.17728 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch6/10: 0.17771 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch6/10: 0.19844 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch6/10: 0.16576 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch6/10: 0.18995 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch6/10: 0.18674 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch6/10: 0.2169 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch6/10: 0.1841 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch6/10: 0.18079 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch6/10: 0.17884 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch6/10: 0.19852 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch6/10: 0.19518 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch6/10: 0.19842 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch6/10: 0.16706 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch6/10: 0.19885 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch6/10: 0.19319 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch6/10: 0.20764 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch6/10: 0.19316 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch6/10: 0.19086 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch6/10: 0.20486 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch6/10: 0.16237 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch6/10: 0.18226 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch6/10: 0.18631 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch6/10: 0.19386 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch6/10: 0.19936 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch6/10: 0.18679 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch6/10: 0.17843 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch6/10: 0.19764 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch6/10: 0.22002 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch6/10: 0.19761 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch6/10: 0.21341 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch6/10: 0.21918 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch6/10: 0.19356 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch6/10: 0.1857 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch6/10: 0.17842 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch6/10: 0.1757 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch6/10: 0.19354 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch6/10: 0.15735 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch6/10: 0.19748 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch6/10: 0.17025 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch6/10: 0.17922 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch6/10: 0.18414 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch6/10: 0.20268 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch6/10: 0.21229 in 0.09 secs
Val Loss for batch 040/271 @epoch6/10: 0.21351 in 0.09 secs
Val Loss for batch 060/271 @epoch6/10: 0.22804 in 0.09 secs
Val Loss for batch 080/271 @epoch6/10: 0.23169 in 0.09 secs
Val Loss for batch 100/271 @epoch6/10: 0.23736 in 0.09 secs
Val Loss for batch 120/271 @epoch6/10: 0.20943 in 0.09 secs
Val Loss for batch 140/271 @epoch6/10: 0.23562 in 0.09 secs
Val Loss for batch 160/271 @epoch6/10: 0.26353 in 0.09 secs
Val Loss for batch 180/271 @epoch6/10: 0.25277 in 0.09 secs
Val Loss for batch 200/271 @epoch6/10: 0.16972 in 0.09 secs
Val Loss for batch 220/271 @epoch6/10: 0.20004 in 0.08 secs
Val Loss for batch 240/271 @epoch6/10: 0.20453 in 0.09 secs
Val Loss for batch 260/271 @epoch6/10: 0.18968 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7168139477811455, 'Cardiomegaly': 0.8645419261166443, 'Consolidation': 0.7294750974962313, 'Edema': 0.8533210108643585, 'Effusion': 0.8644535764191884, 'Emphysema': 0.7784196252856264, 'Fibrosis': 0.6806301099828753, 'Hernia': 0.7243004901393231, 'Infiltration': 0.5877427150441731, 'Mass': 0.6350467085788344, 'Nodule': 0.5483035295335882, 'Pleural_Thickening': 0.6493835078234602, 'Pneumonia': 0.592273327544005, 'Pneumothorax': 0.7502009936777392, 'none': 0.726631306925998}
AVG Loss in validation set: 0.22510524953866634
0.7124933261633709
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch7/10: 0.193 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch7/10: 0.17851 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch7/10: 0.16169 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch7/10: 0.18442 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch7/10: 0.17297 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch7/10: 0.18659 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch7/10: 0.17543 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch7/10: 0.17956 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch7/10: 0.18183 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch7/10: 0.2107 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch7/10: 0.2008 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch7/10: 0.21703 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch7/10: 0.17509 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch7/10: 0.17575 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch7/10: 0.16432 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch7/10: 0.20934 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch7/10: 0.1882 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch7/10: 0.17796 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch7/10: 0.17425 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch7/10: 0.19511 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch7/10: 0.19333 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch7/10: 0.18559 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch7/10: 0.1675 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch7/10: 0.19505 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch7/10: 0.18696 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch7/10: 0.18406 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch7/10: 0.18337 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch7/10: 0.21013 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch7/10: 0.19707 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch7/10: 0.17918 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch7/10: 0.20099 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch7/10: 0.19059 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch7/10: 0.16879 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch7/10: 0.19589 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch7/10: 0.19393 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch7/10: 0.18008 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch7/10: 0.16313 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch7/10: 0.19146 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch7/10: 0.21724 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch7/10: 0.19822 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch7/10: 0.19063 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch7/10: 0.21533 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch7/10: 0.20947 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch7/10: 0.18552 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch7/10: 0.17959 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch7/10: 0.18764 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch7/10: 0.17223 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch7/10: 0.18355 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch7/10: 0.19703 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch7/10: 0.18769 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch7/10: 0.18163 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch7/10: 0.1981 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch7/10: 0.21017 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch7/10: 0.18347 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch7/10: 0.21808 in 0.09 secs
Val Loss for batch 040/271 @epoch7/10: 0.21722 in 0.09 secs
Val Loss for batch 060/271 @epoch7/10: 0.23333 in 0.09 secs
Val Loss for batch 080/271 @epoch7/10: 0.23348 in 0.09 secs
Val Loss for batch 100/271 @epoch7/10: 0.23626 in 0.09 secs
Val Loss for batch 120/271 @epoch7/10: 0.20249 in 0.09 secs
Val Loss for batch 140/271 @epoch7/10: 0.23844 in 0.09 secs
Val Loss for batch 160/271 @epoch7/10: 0.27725 in 0.09 secs
Val Loss for batch 180/271 @epoch7/10: 0.25469 in 0.09 secs
Val Loss for batch 200/271 @epoch7/10: 0.16787 in 0.09 secs
Val Loss for batch 220/271 @epoch7/10: 0.19904 in 0.09 secs
Val Loss for batch 240/271 @epoch7/10: 0.20751 in 0.09 secs
Val Loss for batch 260/271 @epoch7/10: 0.18946 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7206715093788547, 'Cardiomegaly': 0.8664808316549351, 'Consolidation': 0.7295307584223635, 'Edema': 0.8512096787392673, 'Effusion': 0.8649119419353318, 'Emphysema': 0.7767395238936942, 'Fibrosis': 0.6747234901937783, 'Hernia': 0.7333642082513219, 'Infiltration': 0.5819774123183308, 'Mass': 0.6410007031431271, 'Nodule': 0.5479228811627653, 'Pleural_Thickening': 0.6583671469467731, 'Pneumonia': 0.6102979554371692, 'Pneumothorax': 0.7436974286991713, 'none': 0.7253170136855649}
AVG Loss in validation set: 0.225140460197208
0.714349676441206
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch8/10: 0.19711 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch8/10: 0.18891 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch8/10: 0.18644 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch8/10: 0.17532 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch8/10: 0.16173 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch8/10: 0.17533 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch8/10: 0.18196 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch8/10: 0.17084 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch8/10: 0.16805 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch8/10: 0.20395 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch8/10: 0.19302 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch8/10: 0.18798 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch8/10: 0.18514 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch8/10: 0.17841 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch8/10: 0.17774 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch8/10: 0.18451 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch8/10: 0.20315 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch8/10: 0.1799 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch8/10: 0.19406 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch8/10: 0.17582 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch8/10: 0.18582 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch8/10: 0.18844 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch8/10: 0.17523 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch8/10: 0.20784 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch8/10: 0.18665 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch8/10: 0.19456 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch8/10: 0.20449 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch8/10: 0.16667 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch8/10: 0.17685 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch8/10: 0.21556 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch8/10: 0.17876 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch8/10: 0.20464 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch8/10: 0.20217 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch8/10: 0.2048 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch8/10: 0.16672 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch8/10: 0.18275 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch8/10: 0.21398 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch8/10: 0.19101 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch8/10: 0.19286 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch8/10: 0.20279 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch8/10: 0.21121 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch8/10: 0.18083 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch8/10: 0.18657 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch8/10: 0.18319 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch8/10: 0.1822 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch8/10: 0.20264 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch8/10: 0.17878 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch8/10: 0.16773 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch8/10: 0.16884 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch8/10: 0.18339 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch8/10: 0.17504 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch8/10: 0.19472 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch8/10: 0.18566 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch8/10: 0.17383 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch8/10: 0.21668 in 0.09 secs
Val Loss for batch 040/271 @epoch8/10: 0.21403 in 0.08 secs
Val Loss for batch 060/271 @epoch8/10: 0.22738 in 0.09 secs
Val Loss for batch 080/271 @epoch8/10: 0.22732 in 0.09 secs
Val Loss for batch 100/271 @epoch8/10: 0.23585 in 0.09 secs
Val Loss for batch 120/271 @epoch8/10: 0.20475 in 0.09 secs
Val Loss for batch 140/271 @epoch8/10: 0.23027 in 0.09 secs
Val Loss for batch 160/271 @epoch8/10: 0.27305 in 0.09 secs
Val Loss for batch 180/271 @epoch8/10: 0.2458 in 0.09 secs
Val Loss for batch 200/271 @epoch8/10: 0.1715 in 0.09 secs
Val Loss for batch 220/271 @epoch8/10: 0.20246 in 0.09 secs
Val Loss for batch 240/271 @epoch8/10: 0.20612 in 0.09 secs
Val Loss for batch 260/271 @epoch8/10: 0.19056 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7174128119906946, 'Cardiomegaly': 0.8673058037585353, 'Consolidation': 0.7298168975716065, 'Edema': 0.8443997324554847, 'Effusion': 0.8643403531166718, 'Emphysema': 0.7713958625045468, 'Fibrosis': 0.6842354045260547, 'Hernia': 0.7390027401489715, 'Infiltration': 0.5819807361756199, 'Mass': 0.648962572820307, 'Nodule': 0.5498129497154955, 'Pleural_Thickening': 0.6490133624732466, 'Pneumonia': 0.5982539775386055, 'Pneumothorax': 0.7523391761396641, 'none': 0.7254804217748012}
AVG Loss in validation set: 0.2252077208422865
0.7141623129239646
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch9/10: 0.17476 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch9/10: 0.17831 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch9/10: 0.18249 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch9/10: 0.16558 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch9/10: 0.18357 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch9/10: 0.17752 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch9/10: 0.19026 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch9/10: 0.19201 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch9/10: 0.19633 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch9/10: 0.18981 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch9/10: 0.17475 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch9/10: 0.17273 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch9/10: 0.18395 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch9/10: 0.20817 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch9/10: 0.19802 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch9/10: 0.16714 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch9/10: 0.18885 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch9/10: 0.2155 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch9/10: 0.18571 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch9/10: 0.17006 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch9/10: 0.20911 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch9/10: 0.16964 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch9/10: 0.18993 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch9/10: 0.1996 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch9/10: 0.20803 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch9/10: 0.19235 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch9/10: 0.22311 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch9/10: 0.18599 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch9/10: 0.20167 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch9/10: 0.20725 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch9/10: 0.18599 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch9/10: 0.19758 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch9/10: 0.18269 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch9/10: 0.19488 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch9/10: 0.19074 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch9/10: 0.17456 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch9/10: 0.17265 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch9/10: 0.21946 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch9/10: 0.1828 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch9/10: 0.17607 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch9/10: 0.20536 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch9/10: 0.2234 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch9/10: 0.19193 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch9/10: 0.16802 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch9/10: 0.18912 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch9/10: 0.19176 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch9/10: 0.18151 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch9/10: 0.18256 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch9/10: 0.19018 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch9/10: 0.1915 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch9/10: 0.18553 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch9/10: 0.18206 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch9/10: 0.16829 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch9/10: 0.20992 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch9/10: 0.20904 in 0.09 secs
Val Loss for batch 040/271 @epoch9/10: 0.21551 in 0.09 secs
Val Loss for batch 060/271 @epoch9/10: 0.2294 in 0.09 secs
Val Loss for batch 080/271 @epoch9/10: 0.2339 in 0.09 secs
Val Loss for batch 100/271 @epoch9/10: 0.22929 in 0.09 secs
Val Loss for batch 120/271 @epoch9/10: 0.20891 in 0.09 secs
Val Loss for batch 140/271 @epoch9/10: 0.24263 in 0.09 secs
Val Loss for batch 160/271 @epoch9/10: 0.26698 in 0.09 secs
Val Loss for batch 180/271 @epoch9/10: 0.24837 in 0.09 secs
Val Loss for batch 200/271 @epoch9/10: 0.16718 in 0.09 secs
Val Loss for batch 220/271 @epoch9/10: 0.1958 in 0.09 secs
Val Loss for batch 240/271 @epoch9/10: 0.20158 in 0.09 secs
Val Loss for batch 260/271 @epoch9/10: 0.18779 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7180594980544764, 'Cardiomegaly': 0.8719918606341232, 'Consolidation': 0.7334565691158157, 'Edema': 0.8457492392112019, 'Effusion': 0.864754848057829, 'Emphysema': 0.7679911191774526, 'Fibrosis': 0.6903837727242929, 'Hernia': 0.7567558179923584, 'Infiltration': 0.5838416145391105, 'Mass': 0.6329637944760937, 'Nodule': 0.551044988907939, 'Pleural_Thickening': 0.6563842824287494, 'Pneumonia': 0.5975894608725388, 'Pneumothorax': 0.7484076160837188, 'none': 0.7251837671129677}
AVG Loss in validation set: 0.22449929208955002
0.7156696058768357
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch10/10: 0.1783 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch10/10: 0.18829 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch10/10: 0.18542 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch10/10: 0.19808 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch10/10: 0.19002 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch10/10: 0.20606 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch10/10: 0.17958 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch10/10: 0.16347 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch10/10: 0.18486 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch10/10: 0.18453 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch10/10: 0.19215 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch10/10: 0.21386 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch10/10: 0.17713 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch10/10: 0.23772 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch10/10: 0.19754 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch10/10: 0.20157 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch10/10: 0.18762 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch10/10: 0.18862 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch10/10: 0.17301 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch10/10: 0.19698 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch10/10: 0.18665 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch10/10: 0.1631 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch10/10: 0.19485 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch10/10: 0.20525 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch10/10: 0.21438 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch10/10: 0.1715 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch10/10: 0.20918 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch10/10: 0.18907 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch10/10: 0.21515 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch10/10: 0.19154 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch10/10: 0.16304 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch10/10: 0.18595 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch10/10: 0.22737 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch10/10: 0.18547 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch10/10: 0.18729 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch10/10: 0.19527 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch10/10: 0.17474 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch10/10: 0.17899 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch10/10: 0.19228 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch10/10: 0.1927 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch10/10: 0.19221 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch10/10: 0.21856 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch10/10: 0.19132 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch10/10: 0.17745 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch10/10: 0.18615 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch10/10: 0.1922 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch10/10: 0.18893 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch10/10: 0.17781 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch10/10: 0.1972 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch10/10: 0.18778 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch10/10: 0.21043 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch10/10: 0.18816 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch10/10: 0.19915 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch10/10: 0.19174 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch10/10: 0.21423 in 0.09 secs
Val Loss for batch 040/271 @epoch10/10: 0.21521 in 0.09 secs
Val Loss for batch 060/271 @epoch10/10: 0.2246 in 0.09 secs
Val Loss for batch 080/271 @epoch10/10: 0.23336 in 0.09 secs
Val Loss for batch 100/271 @epoch10/10: 0.23842 in 0.09 secs
Val Loss for batch 120/271 @epoch10/10: 0.20469 in 0.09 secs
Val Loss for batch 140/271 @epoch10/10: 0.23376 in 0.09 secs
Val Loss for batch 160/271 @epoch10/10: 0.26779 in 0.09 secs
Val Loss for batch 180/271 @epoch10/10: 0.25172 in 0.09 secs
Val Loss for batch 200/271 @epoch10/10: 0.16841 in 0.09 secs
Val Loss for batch 220/271 @epoch10/10: 0.19576 in 0.09 secs
Val Loss for batch 240/271 @epoch10/10: 0.20663 in 0.09 secs
Val Loss for batch 260/271 @epoch10/10: 0.19007 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7185593740847316, 'Cardiomegaly': 0.8681042444824343, 'Consolidation': 0.72840571131284, 'Edema': 0.8426412710328507, 'Effusion': 0.8648101423020683, 'Emphysema': 0.7748238792686444, 'Fibrosis': 0.684370424807849, 'Hernia': 0.770593570298329, 'Infiltration': 0.5852183658626561, 'Mass': 0.6400710534354976, 'Nodule': 0.5512724314304941, 'Pleural_Thickening': 0.6521963730809766, 'Pneumonia': 0.6018068779021634, 'Pneumothorax': 0.7473507710583186, 'none': 0.7240423769995832}
AVG Loss in validation set: 0.22495164386359728
0.7164446064542752
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/2/ft_resnet_50_adam_exponential/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch1/10: 0.26521 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch1/10: 0.2703 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch1/10: 0.22979 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch1/10: 0.28458 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch1/10: 0.30853 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch1/10: 0.26324 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch1/10: 0.22822 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch1/10: 0.27106 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch1/10: 0.23775 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch1/10: 0.24856 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch1/10: 0.24397 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch1/10: 0.17837 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch1/10: 0.24086 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch1/10: 0.20638 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch1/10: 0.24396 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch1/10: 0.23136 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch1/10: 0.18667 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch1/10: 0.2221 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch1/10: 0.25303 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch1/10: 0.21682 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch1/10: 0.22016 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch1/10: 0.24115 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch1/10: 0.22968 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch1/10: 0.24048 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch1/10: 0.21298 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch1/10: 0.20123 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch1/10: 0.26111 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch1/10: 0.21552 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch1/10: 0.22104 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch1/10: 0.20169 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch1/10: 0.26623 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch1/10: 0.20221 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch1/10: 0.2351 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch1/10: 0.21874 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch1/10: 0.21518 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch1/10: 0.18095 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch1/10: 0.20836 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch1/10: 0.23383 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch1/10: 0.24156 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch1/10: 0.20875 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch1/10: 0.29802 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch1/10: 0.20088 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch1/10: 0.22562 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch1/10: 0.20429 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch1/10: 0.19097 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch1/10: 0.19663 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch1/10: 0.2114 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch1/10: 0.20273 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch1/10: 0.20725 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch1/10: 0.22303 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch1/10: 0.18496 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch1/10: 0.19794 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch1/10: 0.20016 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch1/10: 0.19392 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch1/10: 0.26255 in 0.05 secs
Val Loss for batch 160/1082 @epoch1/10: 0.2105 in 0.05 secs
Val Loss for batch 240/1082 @epoch1/10: 0.24937 in 0.05 secs
Val Loss for batch 320/1082 @epoch1/10: 0.18816 in 0.05 secs
Val Loss for batch 400/1082 @epoch1/10: 0.30753 in 0.05 secs
Val Loss for batch 480/1082 @epoch1/10: 0.20251 in 0.05 secs
Val Loss for batch 560/1082 @epoch1/10: 0.27971 in 0.05 secs
Val Loss for batch 640/1082 @epoch1/10: 0.24023 in 0.05 secs
Val Loss for batch 720/1082 @epoch1/10: 0.2103 in 0.05 secs
Val Loss for batch 800/1082 @epoch1/10: 0.16303 in 0.05 secs
Val Loss for batch 880/1082 @epoch1/10: 0.21023 in 0.05 secs
Val Loss for batch 960/1082 @epoch1/10: 0.17589 in 0.05 secs
Val Loss for batch 1040/1082 @epoch1/10: 0.25066 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7183669446533719, 'Cardiomegaly': 0.8392084958860981, 'Consolidation': 0.7196578824474011, 'Edema': 0.8280072843686135, 'Effusion': 0.8692826930673806, 'Emphysema': 0.7688879490343831, 'Fibrosis': 0.69747245252726, 'Hernia': 0.8661726679788507, 'Infiltration': 0.5698641684041448, 'Mass': 0.7722149399098435, 'Nodule': 0.6415962142262756, 'Pleural_Thickening': 0.6557685483652158, 'Pneumonia': 0.5547032481732119, 'Pneumothorax': 0.7772178330905047, 'none': 0.7366637418927182}
AVG Loss in validation set: 0.23491362501254415
0.7341729515808968
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch2/10: 0.21182 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch2/10: 0.23663 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch2/10: 0.24459 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch2/10: 0.21212 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch2/10: 0.21764 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch2/10: 0.20175 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch2/10: 0.21467 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch2/10: 0.1925 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch2/10: 0.15408 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch2/10: 0.20284 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch2/10: 0.23401 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch2/10: 0.18893 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch2/10: 0.24102 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch2/10: 0.21624 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch2/10: 0.20028 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch2/10: 0.18738 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch2/10: 0.2038 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch2/10: 0.24202 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch2/10: 0.19607 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch2/10: 0.14349 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch2/10: 0.20825 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch2/10: 0.18633 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch2/10: 0.17704 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch2/10: 0.24642 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch2/10: 0.16448 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch2/10: 0.23348 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch2/10: 0.15816 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch2/10: 0.18575 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch2/10: 0.24372 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch2/10: 0.16753 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch2/10: 0.26404 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch2/10: 0.18239 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch2/10: 0.19429 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch2/10: 0.2142 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch2/10: 0.16077 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch2/10: 0.20726 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch2/10: 0.17635 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch2/10: 0.15212 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch2/10: 0.19687 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch2/10: 0.15876 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch2/10: 0.1916 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch2/10: 0.1753 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch2/10: 0.15824 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch2/10: 0.20071 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch2/10: 0.22392 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch2/10: 0.16886 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch2/10: 0.18043 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch2/10: 0.14921 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch2/10: 0.1822 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch2/10: 0.15582 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch2/10: 0.20098 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch2/10: 0.18253 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch2/10: 0.17909 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch2/10: 0.16968 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch2/10: 0.24098 in 0.05 secs
Val Loss for batch 160/1082 @epoch2/10: 0.19966 in 0.05 secs
Val Loss for batch 240/1082 @epoch2/10: 0.22487 in 0.05 secs
Val Loss for batch 320/1082 @epoch2/10: 0.19184 in 0.05 secs
Val Loss for batch 400/1082 @epoch2/10: 0.35401 in 0.05 secs
Val Loss for batch 480/1082 @epoch2/10: 0.19626 in 0.05 secs
Val Loss for batch 560/1082 @epoch2/10: 0.23927 in 0.05 secs
Val Loss for batch 640/1082 @epoch2/10: 0.24149 in 0.05 secs
Val Loss for batch 720/1082 @epoch2/10: 0.16742 in 0.05 secs
Val Loss for batch 800/1082 @epoch2/10: 0.17263 in 0.05 secs
Val Loss for batch 880/1082 @epoch2/10: 0.20757 in 0.05 secs
Val Loss for batch 960/1082 @epoch2/10: 0.16259 in 0.05 secs
Val Loss for batch 1040/1082 @epoch2/10: 0.21971 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7216503992829127, 'Cardiomegaly': 0.8779143182550503, 'Consolidation': 0.6861869756505211, 'Edema': 0.8451216225505548, 'Effusion': 0.8476547207023418, 'Emphysema': 0.8535386558747473, 'Fibrosis': 0.7126135855245378, 'Hernia': 0.8699027440083362, 'Infiltration': 0.562861884962359, 'Mass': 0.7230935833851809, 'Nodule': 0.6407931019649551, 'Pleural_Thickening': 0.6541201180847459, 'Pneumonia': 0.6182341910838344, 'Pneumothorax': 0.7562962847476652, 'none': 0.7305967012919503}
AVG Loss in validation set: 0.23265317674180286
0.7407130132912674
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch3/10: 0.1491 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch3/10: 0.23401 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch3/10: 0.26365 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch3/10: 0.18441 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch3/10: 0.2023 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch3/10: 0.17281 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch3/10: 0.16277 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch3/10: 0.11867 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch3/10: 0.13907 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch3/10: 0.11768 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch3/10: 0.15815 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch3/10: 0.13004 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch3/10: 0.16275 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch3/10: 0.21701 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch3/10: 0.14699 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch3/10: 0.2391 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch3/10: 0.16162 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch3/10: 0.12863 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch3/10: 0.10806 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch3/10: 0.16219 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch3/10: 0.10905 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch3/10: 0.16052 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch3/10: 0.13084 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch3/10: 0.2468 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch3/10: 0.13203 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch3/10: 0.22522 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch3/10: 0.12025 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch3/10: 0.11317 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch3/10: 0.15563 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch3/10: 0.14407 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch3/10: 0.11031 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch3/10: 0.12162 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch3/10: 0.21125 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch3/10: 0.13204 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch3/10: 0.10937 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch3/10: 0.08659 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch3/10: 0.18905 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch3/10: 0.1576 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch3/10: 0.12736 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch3/10: 0.11152 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch3/10: 0.11939 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch3/10: 0.08278 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch3/10: 0.14827 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch3/10: 0.12224 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch3/10: 0.16185 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch3/10: 0.13021 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch3/10: 0.12843 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch3/10: 0.19981 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch3/10: 0.14826 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch3/10: 0.09503 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch3/10: 0.2153 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch3/10: 0.18476 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch3/10: 0.16988 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch3/10: 0.14496 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch3/10: 0.22145 in 0.05 secs
Val Loss for batch 160/1082 @epoch3/10: 0.19941 in 0.05 secs
Val Loss for batch 240/1082 @epoch3/10: 0.2256 in 0.05 secs
Val Loss for batch 320/1082 @epoch3/10: 0.16207 in 0.05 secs
Val Loss for batch 400/1082 @epoch3/10: 0.34502 in 0.05 secs
Val Loss for batch 480/1082 @epoch3/10: 0.19254 in 0.05 secs
Val Loss for batch 560/1082 @epoch3/10: 0.28284 in 0.05 secs
Val Loss for batch 640/1082 @epoch3/10: 0.23367 in 0.05 secs
Val Loss for batch 720/1082 @epoch3/10: 0.19479 in 0.05 secs
Val Loss for batch 800/1082 @epoch3/10: 0.13467 in 0.05 secs
Val Loss for batch 880/1082 @epoch3/10: 0.19418 in 0.05 secs
Val Loss for batch 960/1082 @epoch3/10: 0.16964 in 0.05 secs
Val Loss for batch 1040/1082 @epoch3/10: 0.21442 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7471256618432462, 'Cardiomegaly': 0.864045520157312, 'Consolidation': 0.7099758000426034, 'Edema': 0.8654729002065505, 'Effusion': 0.8697875086967289, 'Emphysema': 0.842006868472779, 'Fibrosis': 0.7065753957163838, 'Hernia': 0.8699992281270503, 'Infiltration': 0.6035688279799801, 'Mass': 0.7915279403059202, 'Nodule': 0.6554945769438407, 'Pleural_Thickening': 0.6543272026374884, 'Pneumonia': 0.6579880640095749, 'Pneumothorax': 0.7803148406409066, 'none': 0.7371263536011168}
AVG Loss in validation set: 0.22774449808560088
0.7584435954128832
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch4/10: 0.13545 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch4/10: 0.21478 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch4/10: 0.11908 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch4/10: 0.20747 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch4/10: 0.14528 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch4/10: 0.22497 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch4/10: 0.15432 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch4/10: 0.15164 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch4/10: 0.13243 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch4/10: 0.11356 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch4/10: 0.13311 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch4/10: 0.09562 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch4/10: 0.15219 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch4/10: 0.14485 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch4/10: 0.09905 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch4/10: 0.15665 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch4/10: 0.0689 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch4/10: 0.18463 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch4/10: 0.08681 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch4/10: 0.07697 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch4/10: 0.15595 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch4/10: 0.11883 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch4/10: 0.14969 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch4/10: 0.21209 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch4/10: 0.17774 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch4/10: 0.08432 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch4/10: 0.12293 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch4/10: 0.14221 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch4/10: 0.0806 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch4/10: 0.06993 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch4/10: 0.12625 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch4/10: 0.12119 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch4/10: 0.08502 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch4/10: 0.11735 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch4/10: 0.09097 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch4/10: 0.0856 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch4/10: 0.13406 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch4/10: 0.13263 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch4/10: 0.10379 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch4/10: 0.09626 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch4/10: 0.10488 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch4/10: 0.07069 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch4/10: 0.16159 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch4/10: 0.10173 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch4/10: 0.06321 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch4/10: 0.19896 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch4/10: 0.1048 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch4/10: 0.16073 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch4/10: 0.10128 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch4/10: 0.15952 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch4/10: 0.11097 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch4/10: 0.16691 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch4/10: 0.12556 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch4/10: 0.08943 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch4/10: 0.21794 in 0.05 secs
Val Loss for batch 160/1082 @epoch4/10: 0.20351 in 0.05 secs
Val Loss for batch 240/1082 @epoch4/10: 0.20368 in 0.05 secs
Val Loss for batch 320/1082 @epoch4/10: 0.15294 in 0.05 secs
Val Loss for batch 400/1082 @epoch4/10: 0.33623 in 0.05 secs
Val Loss for batch 480/1082 @epoch4/10: 0.21181 in 0.05 secs
Val Loss for batch 560/1082 @epoch4/10: 0.26099 in 0.05 secs
Val Loss for batch 640/1082 @epoch4/10: 0.25561 in 0.05 secs
Val Loss for batch 720/1082 @epoch4/10: 0.15914 in 0.05 secs
Val Loss for batch 800/1082 @epoch4/10: 0.12064 in 0.05 secs
Val Loss for batch 880/1082 @epoch4/10: 0.1942 in 0.05 secs
Val Loss for batch 960/1082 @epoch4/10: 0.17295 in 0.05 secs
Val Loss for batch 1040/1082 @epoch4/10: 0.18922 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7396278680723722, 'Cardiomegaly': 0.8420062106499265, 'Consolidation': 0.6567010736874878, 'Edema': 0.8292231279794606, 'Effusion': 0.8701443509587038, 'Emphysema': 0.8554069510934803, 'Fibrosis': 0.6941300680046786, 'Hernia': 0.8649492493535564, 'Infiltration': 0.6350358812802959, 'Mass': 0.7684112367995413, 'Nodule': 0.6562665041512145, 'Pleural_Thickening': 0.6358147480378173, 'Pneumonia': 0.6261638181220979, 'Pneumothorax': 0.7736845890429905, 'none': 0.7422214307400543}
AVG Loss in validation set: 0.22153352085936692
0.7462546912309731
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch5/10: 0.13078 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch5/10: 0.13915 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch5/10: 0.17531 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch5/10: 0.09547 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch5/10: 0.16404 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch5/10: 0.10169 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch5/10: 0.15821 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch5/10: 0.07474 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch5/10: 0.10347 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch5/10: 0.11664 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch5/10: 0.09449 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch5/10: 0.11178 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch5/10: 0.22001 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch5/10: 0.12744 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch5/10: 0.10175 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch5/10: 0.11796 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch5/10: 0.09722 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch5/10: 0.06966 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch5/10: 0.09694 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch5/10: 0.12532 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch5/10: 0.07368 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch5/10: 0.11341 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch5/10: 0.04574 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch5/10: 0.07896 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch5/10: 0.13365 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch5/10: 0.08291 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch5/10: 0.12136 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch5/10: 0.07968 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch5/10: 0.06869 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch5/10: 0.12665 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch5/10: 0.1381 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch5/10: 0.07587 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch5/10: 0.09585 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch5/10: 0.06268 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch5/10: 0.11467 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch5/10: 0.11851 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch5/10: 0.17423 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch5/10: 0.12341 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch5/10: 0.10998 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch5/10: 0.0702 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch5/10: 0.11321 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch5/10: 0.10763 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch5/10: 0.1208 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch5/10: 0.10701 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch5/10: 0.12474 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch5/10: 0.07635 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch5/10: 0.0589 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch5/10: 0.09935 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch5/10: 0.06483 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch5/10: 0.0774 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch5/10: 0.09942 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch5/10: 0.09877 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch5/10: 0.07908 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch5/10: 0.06674 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch5/10: 0.18649 in 0.05 secs
Val Loss for batch 160/1082 @epoch5/10: 0.23227 in 0.05 secs
Val Loss for batch 240/1082 @epoch5/10: 0.2156 in 0.05 secs
Val Loss for batch 320/1082 @epoch5/10: 0.14419 in 0.05 secs
Val Loss for batch 400/1082 @epoch5/10: 0.35683 in 0.05 secs
Val Loss for batch 480/1082 @epoch5/10: 0.25889 in 0.05 secs
Val Loss for batch 560/1082 @epoch5/10: 0.34735 in 0.05 secs
Val Loss for batch 640/1082 @epoch5/10: 0.2609 in 0.05 secs
Val Loss for batch 720/1082 @epoch5/10: 0.16231 in 0.05 secs
Val Loss for batch 800/1082 @epoch5/10: 0.10433 in 0.05 secs
Val Loss for batch 880/1082 @epoch5/10: 0.22206 in 0.05 secs
Val Loss for batch 960/1082 @epoch5/10: 0.14157 in 0.05 secs
Val Loss for batch 1040/1082 @epoch5/10: 0.21121 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7424147503562575, 'Cardiomegaly': 0.8542066079284991, 'Consolidation': 0.6781878809726682, 'Edema': 0.851793432065843, 'Effusion': 0.863978443904625, 'Emphysema': 0.8444047346998721, 'Fibrosis': 0.7016162180750064, 'Hernia': 0.8288873451429895, 'Infiltration': 0.6056335936764627, 'Mass': 0.7771901976995703, 'Nodule': 0.6510247663010422, 'Pleural_Thickening': 0.6551556738507406, 'Pneumonia': 0.6453062850959289, 'Pneumothorax': 0.7696540534940411, 'none': 0.7435843877669011}
AVG Loss in validation set: 0.22845208337612302
0.7478181416616819
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch6/10: 0.08192 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch6/10: 0.0841 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch6/10: 0.0743 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch6/10: 0.10155 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch6/10: 0.08821 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch6/10: 0.1289 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch6/10: 0.11051 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch6/10: 0.12005 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch6/10: 0.06584 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch6/10: 0.05134 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch6/10: 0.06008 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch6/10: 0.11538 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch6/10: 0.07875 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch6/10: 0.14009 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch6/10: 0.04976 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch6/10: 0.06092 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch6/10: 0.08832 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch6/10: 0.04859 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch6/10: 0.04739 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch6/10: 0.11949 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch6/10: 0.07967 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch6/10: 0.15532 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch6/10: 0.15282 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch6/10: 0.04941 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch6/10: 0.10057 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch6/10: 0.0945 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch6/10: 0.05644 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch6/10: 0.06314 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch6/10: 0.08586 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch6/10: 0.05726 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch6/10: 0.0427 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch6/10: 0.05584 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch6/10: 0.05833 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch6/10: 0.08123 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch6/10: 0.04658 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch6/10: 0.07755 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch6/10: 0.10176 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch6/10: 0.04091 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch6/10: 0.08056 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch6/10: 0.06525 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch6/10: 0.09295 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch6/10: 0.06612 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch6/10: 0.08319 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch6/10: 0.09267 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch6/10: 0.07132 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch6/10: 0.15189 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch6/10: 0.08122 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch6/10: 0.07906 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch6/10: 0.10263 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch6/10: 0.06457 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch6/10: 0.08487 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch6/10: 0.08604 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch6/10: 0.17755 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch6/10: 0.07669 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch6/10: 0.18529 in 0.05 secs
Val Loss for batch 160/1082 @epoch6/10: 0.20585 in 0.05 secs
Val Loss for batch 240/1082 @epoch6/10: 0.24203 in 0.05 secs
Val Loss for batch 320/1082 @epoch6/10: 0.14964 in 0.05 secs
Val Loss for batch 400/1082 @epoch6/10: 0.33298 in 0.05 secs
Val Loss for batch 480/1082 @epoch6/10: 0.25577 in 0.05 secs
Val Loss for batch 560/1082 @epoch6/10: 0.32581 in 0.05 secs
Val Loss for batch 640/1082 @epoch6/10: 0.21451 in 0.05 secs
Val Loss for batch 720/1082 @epoch6/10: 0.14561 in 0.05 secs
Val Loss for batch 800/1082 @epoch6/10: 0.10222 in 0.05 secs
Val Loss for batch 880/1082 @epoch6/10: 0.21744 in 0.05 secs
Val Loss for batch 960/1082 @epoch6/10: 0.15272 in 0.05 secs
Val Loss for batch 1040/1082 @epoch6/10: 0.15553 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.739847522312005, 'Cardiomegaly': 0.8305245638279629, 'Consolidation': 0.6908354054696204, 'Edema': 0.8471605037954877, 'Effusion': 0.864876897066107, 'Emphysema': 0.8196470141885706, 'Fibrosis': 0.6893003902247157, 'Hernia': 0.8139554629308017, 'Infiltration': 0.5995007638609425, 'Mass': 0.7940817447263703, 'Nodule': 0.6440609283200762, 'Pleural_Thickening': 0.6771833122569051, 'Pneumonia': 0.6314708118858213, 'Pneumothorax': 0.7633177611220441, 'none': 0.7474725920099737}
AVG Loss in validation set: 0.23246321542997136
0.7432687915705307
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch7/10: 0.11211 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch7/10: 0.04944 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch7/10: 0.05533 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch7/10: 0.10783 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch7/10: 0.1244 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch7/10: 0.06717 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch7/10: 0.05511 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch7/10: 0.05884 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch7/10: 0.04943 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch7/10: 0.05797 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch7/10: 0.05084 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch7/10: 0.04546 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch7/10: 0.04909 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch7/10: 0.04937 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch7/10: 0.10518 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch7/10: 0.0743 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch7/10: 0.08954 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch7/10: 0.05511 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch7/10: 0.02579 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch7/10: 0.0547 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch7/10: 0.03686 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch7/10: 0.06228 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch7/10: 0.13752 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch7/10: 0.04881 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch7/10: 0.07879 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch7/10: 0.08009 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch7/10: 0.04395 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch7/10: 0.05075 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch7/10: 0.04683 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch7/10: 0.04098 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch7/10: 0.04031 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch7/10: 0.06873 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch7/10: 0.04397 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch7/10: 0.08779 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch7/10: 0.08161 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch7/10: 0.05815 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch7/10: 0.05031 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch7/10: 0.02498 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch7/10: 0.08003 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch7/10: 0.08009 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch7/10: 0.07667 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch7/10: 0.07097 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch7/10: 0.05486 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch7/10: 0.08046 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch7/10: 0.05064 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch7/10: 0.08357 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch7/10: 0.06722 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch7/10: 0.02867 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch7/10: 0.10399 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch7/10: 0.04444 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch7/10: 0.04102 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch7/10: 0.06028 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch7/10: 0.06214 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch7/10: 0.04319 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch7/10: 0.20323 in 0.05 secs
Val Loss for batch 160/1082 @epoch7/10: 0.22348 in 0.05 secs
Val Loss for batch 240/1082 @epoch7/10: 0.23646 in 0.05 secs
Val Loss for batch 320/1082 @epoch7/10: 0.15246 in 0.05 secs
Val Loss for batch 400/1082 @epoch7/10: 0.3062 in 0.05 secs
Val Loss for batch 480/1082 @epoch7/10: 0.23095 in 0.05 secs
Val Loss for batch 560/1082 @epoch7/10: 0.3236 in 0.05 secs
Val Loss for batch 640/1082 @epoch7/10: 0.24996 in 0.05 secs
Val Loss for batch 720/1082 @epoch7/10: 0.16455 in 0.05 secs
Val Loss for batch 800/1082 @epoch7/10: 0.09065 in 0.05 secs
Val Loss for batch 880/1082 @epoch7/10: 0.24704 in 0.05 secs
Val Loss for batch 960/1082 @epoch7/10: 0.1526 in 0.05 secs
Val Loss for batch 1040/1082 @epoch7/10: 0.18681 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7534538900865766, 'Cardiomegaly': 0.8331898139496612, 'Consolidation': 0.6958091982368748, 'Edema': 0.851803252215262, 'Effusion': 0.8578608847668687, 'Emphysema': 0.8328708406505889, 'Fibrosis': 0.6696559743024432, 'Hernia': 0.8183763652502799, 'Infiltration': 0.6099649048842107, 'Mass': 0.7837755638646777, 'Nodule': 0.6425978442545652, 'Pleural_Thickening': 0.6741484661910859, 'Pneumonia': 0.621657590844462, 'Pneumothorax': 0.7748315580945406, 'none': 0.7417454696405784}
AVG Loss in validation set: 0.23203587466252384
0.7442854391137212
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch8/10: 0.0878 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch8/10: 0.03271 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch8/10: 0.07855 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch8/10: 0.06723 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch8/10: 0.07852 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch8/10: 0.03697 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch8/10: 0.0564 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch8/10: 0.04927 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch8/10: 0.2044 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch8/10: 0.11213 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch8/10: 0.03945 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch8/10: 0.05016 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch8/10: 0.07528 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch8/10: 0.05404 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch8/10: 0.02683 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch8/10: 0.08514 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch8/10: 0.06353 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch8/10: 0.04677 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch8/10: 0.0893 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch8/10: 0.04335 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch8/10: 0.07704 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch8/10: 0.03764 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch8/10: 0.08684 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch8/10: 0.04541 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch8/10: 0.05744 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch8/10: 0.03115 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch8/10: 0.01937 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch8/10: 0.05681 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch8/10: 0.04176 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch8/10: 0.04515 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch8/10: 0.05135 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch8/10: 0.02695 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch8/10: 0.04188 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch8/10: 0.07237 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch8/10: 0.06167 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch8/10: 0.04312 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch8/10: 0.04058 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch8/10: 0.05505 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch8/10: 0.0267 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch8/10: 0.04755 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch8/10: 0.07023 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch8/10: 0.03855 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch8/10: 0.03618 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch8/10: 0.06473 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch8/10: 0.07985 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch8/10: 0.02264 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch8/10: 0.05071 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch8/10: 0.10828 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch8/10: 0.10249 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch8/10: 0.05992 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch8/10: 0.07937 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch8/10: 0.02271 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch8/10: 0.04362 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch8/10: 0.05986 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch8/10: 0.20788 in 0.05 secs
Val Loss for batch 160/1082 @epoch8/10: 0.19256 in 0.05 secs
Val Loss for batch 240/1082 @epoch8/10: 0.25394 in 0.05 secs
Val Loss for batch 320/1082 @epoch8/10: 0.156 in 0.05 secs
Val Loss for batch 400/1082 @epoch8/10: 0.32398 in 0.05 secs
Val Loss for batch 480/1082 @epoch8/10: 0.30759 in 0.05 secs
Val Loss for batch 560/1082 @epoch8/10: 0.30387 in 0.05 secs
Val Loss for batch 640/1082 @epoch8/10: 0.23534 in 0.05 secs
Val Loss for batch 720/1082 @epoch8/10: 0.14859 in 0.05 secs
Val Loss for batch 800/1082 @epoch8/10: 0.08946 in 0.05 secs
Val Loss for batch 880/1082 @epoch8/10: 0.21752 in 0.05 secs
Val Loss for batch 960/1082 @epoch8/10: 0.15863 in 0.05 secs
Val Loss for batch 1040/1082 @epoch8/10: 0.16592 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7424544965370248, 'Cardiomegaly': 0.8098032678969537, 'Consolidation': 0.6557722991905354, 'Edema': 0.8363788526355644, 'Effusion': 0.844658310682531, 'Emphysema': 0.8284021401129122, 'Fibrosis': 0.6761650099655089, 'Hernia': 0.8468970707421559, 'Infiltration': 0.6165224658550739, 'Mass': 0.7680933163545414, 'Nodule': 0.642281296532568, 'Pleural_Thickening': 0.6943409391131514, 'Pneumonia': 0.6162229243907705, 'Pneumothorax': 0.7607632579634285, 'none': 0.7386983869634642}
AVG Loss in validation set: 0.23707710989112388
0.7384825462837658
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch9/10: 0.02072 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch9/10: 0.05118 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch9/10: 0.04672 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch9/10: 0.03453 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch9/10: 0.03179 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch9/10: 0.0416 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch9/10: 0.03942 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch9/10: 0.06274 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch9/10: 0.05778 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch9/10: 0.0728 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch9/10: 0.04938 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch9/10: 0.08591 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch9/10: 0.04579 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch9/10: 0.07053 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch9/10: 0.02243 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch9/10: 0.03023 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch9/10: 0.03225 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch9/10: 0.05383 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch9/10: 0.05269 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch9/10: 0.09118 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch9/10: 0.03274 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch9/10: 0.09758 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch9/10: 0.03503 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch9/10: 0.03263 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch9/10: 0.03806 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch9/10: 0.022 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch9/10: 0.11086 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch9/10: 0.03609 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch9/10: 0.08007 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch9/10: 0.037 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch9/10: 0.0955 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch9/10: 0.10814 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch9/10: 0.07207 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch9/10: 0.05918 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch9/10: 0.02126 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch9/10: 0.07627 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch9/10: 0.07158 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch9/10: 0.09008 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch9/10: 0.0247 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch9/10: 0.0445 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch9/10: 0.10786 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch9/10: 0.04144 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch9/10: 0.10528 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch9/10: 0.02891 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch9/10: 0.04128 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch9/10: 0.04188 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch9/10: 0.03079 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch9/10: 0.0945 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch9/10: 0.11707 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch9/10: 0.04804 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch9/10: 0.05145 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch9/10: 0.11878 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch9/10: 0.03398 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch9/10: 0.01936 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch9/10: 0.23528 in 0.05 secs
Val Loss for batch 160/1082 @epoch9/10: 0.20329 in 0.05 secs
Val Loss for batch 240/1082 @epoch9/10: 0.23994 in 0.05 secs
Val Loss for batch 320/1082 @epoch9/10: 0.13613 in 0.05 secs
Val Loss for batch 400/1082 @epoch9/10: 0.38864 in 0.05 secs
Val Loss for batch 480/1082 @epoch9/10: 0.30871 in 0.05 secs
Val Loss for batch 560/1082 @epoch9/10: 0.34936 in 0.05 secs
Val Loss for batch 640/1082 @epoch9/10: 0.22668 in 0.05 secs
Val Loss for batch 720/1082 @epoch9/10: 0.15197 in 0.05 secs
Val Loss for batch 800/1082 @epoch9/10: 0.06576 in 0.05 secs
Val Loss for batch 880/1082 @epoch9/10: 0.20254 in 0.05 secs
Val Loss for batch 960/1082 @epoch9/10: 0.15457 in 0.05 secs
Val Loss for batch 1040/1082 @epoch9/10: 0.17254 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7384457607792193, 'Cardiomegaly': 0.823688407786537, 'Consolidation': 0.6966359191682506, 'Edema': 0.8581920232017397, 'Effusion': 0.849618596849131, 'Emphysema': 0.8297608273145083, 'Fibrosis': 0.6756773728319412, 'Hernia': 0.8463529003126086, 'Infiltration': 0.619097949449815, 'Mass': 0.7828288632554498, 'Nodule': 0.6641399709537533, 'Pleural_Thickening': 0.6845946649060711, 'Pneumonia': 0.6492876201360642, 'Pneumothorax': 0.7714986790694495, 'none': 0.741899836145328}
AVG Loss in validation set: 0.23813475337063775
0.7492728254296099
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch10/10: 0.08077 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch10/10: 0.04307 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch10/10: 0.05012 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch10/10: 0.01461 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch10/10: 0.04272 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch10/10: 0.06097 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch10/10: 0.04044 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch10/10: 0.02691 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch10/10: 0.04904 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch10/10: 0.03195 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch10/10: 0.03904 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch10/10: 0.03449 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch10/10: 0.02268 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch10/10: 0.0437 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch10/10: 0.01509 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch10/10: 0.02102 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch10/10: 0.03033 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch10/10: 0.03695 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch10/10: 0.038 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch10/10: 0.03109 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch10/10: 0.03973 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch10/10: 0.0881 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch10/10: 0.14012 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch10/10: 0.03698 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch10/10: 0.04559 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch10/10: 0.03294 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch10/10: 0.07584 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch10/10: 0.06184 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch10/10: 0.04535 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch10/10: 0.04661 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch10/10: 0.04376 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch10/10: 0.03209 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch10/10: 0.03354 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch10/10: 0.0216 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch10/10: 0.03875 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch10/10: 0.02611 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch10/10: 0.033 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch10/10: 0.05926 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch10/10: 0.02616 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch10/10: 0.0242 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch10/10: 0.05567 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch10/10: 0.06949 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch10/10: 0.01739 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch10/10: 0.04457 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch10/10: 0.08465 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch10/10: 0.05618 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch10/10: 0.0497 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch10/10: 0.09972 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch10/10: 0.07884 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch10/10: 0.01784 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch10/10: 0.02613 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch10/10: 0.05603 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch10/10: 0.03707 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch10/10: 0.03746 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch10/10: 0.24419 in 0.05 secs
Val Loss for batch 160/1082 @epoch10/10: 0.1987 in 0.05 secs
Val Loss for batch 240/1082 @epoch10/10: 0.22749 in 0.05 secs
Val Loss for batch 320/1082 @epoch10/10: 0.15167 in 0.05 secs
Val Loss for batch 400/1082 @epoch10/10: 0.35455 in 0.05 secs
Val Loss for batch 480/1082 @epoch10/10: 0.2812 in 0.05 secs
Val Loss for batch 560/1082 @epoch10/10: 0.33945 in 0.05 secs
Val Loss for batch 640/1082 @epoch10/10: 0.22417 in 0.05 secs
Val Loss for batch 720/1082 @epoch10/10: 0.15728 in 0.05 secs
Val Loss for batch 800/1082 @epoch10/10: 0.05136 in 0.05 secs
Val Loss for batch 880/1082 @epoch10/10: 0.19281 in 0.05 secs
Val Loss for batch 960/1082 @epoch10/10: 0.15732 in 0.05 secs
Val Loss for batch 1040/1082 @epoch10/10: 0.19227 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7428213278862508, 'Cardiomegaly': 0.8248325254720471, 'Consolidation': 0.6748172969784361, 'Edema': 0.8396160103351618, 'Effusion': 0.8496637387679536, 'Emphysema': 0.8296767620549883, 'Fibrosis': 0.6806756534510103, 'Hernia': 0.8199181814673304, 'Infiltration': 0.6188719753259957, 'Mass': 0.7743482180192877, 'Nodule': 0.661956240199929, 'Pleural_Thickening': 0.6924619493772034, 'Pneumonia': 0.6272278040747273, 'Pneumothorax': 0.7754301385405439, 'none': 0.7377485465275059}
AVG Loss in validation set: 0.24174498507285416
0.7437369872822047
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/2/ft_dense161_adam_steplr_0/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/10: 0.30473 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch1/10: 0.26712 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch1/10: 0.25686 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch1/10: 0.2356 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch1/10: 0.24859 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch1/10: 0.22452 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch1/10: 0.22577 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch1/10: 0.21658 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch1/10: 0.21979 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch1/10: 0.20884 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch1/10: 0.20214 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch1/10: 0.19267 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch1/10: 0.2055 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch1/10: 0.2115 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch1/10: 0.21558 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch1/10: 0.20963 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch1/10: 0.19788 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch1/10: 0.2055 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch1/10: 0.20268 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch1/10: 0.19881 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch1/10: 0.20548 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch1/10: 0.18825 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch1/10: 0.18519 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch1/10: 0.20094 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch1/10: 0.21068 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch1/10: 0.19707 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch1/10: 0.2108 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch1/10: 0.186 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch1/10: 0.20957 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch1/10: 0.20326 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch1/10: 0.18983 in 0 mins 0.24 secs
Train Loss for batch 320/541 @epoch1/10: 0.19172 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch1/10: 0.1864 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch1/10: 0.16816 in 0 mins 0.24 secs
Train Loss for batch 350/541 @epoch1/10: 0.19027 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch1/10: 0.18702 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch1/10: 0.18326 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch1/10: 0.19265 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch1/10: 0.17159 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch1/10: 0.18432 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch1/10: 0.19172 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch1/10: 0.1916 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch1/10: 0.18102 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch1/10: 0.17326 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch1/10: 0.20509 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch1/10: 0.19011 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch1/10: 0.16947 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch1/10: 0.16323 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch1/10: 0.17754 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch1/10: 0.17023 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch1/10: 0.16482 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch1/10: 0.17924 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch1/10: 0.14655 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch1/10: 0.1732 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/10: 0.23186 in 0.08 secs
Val Loss for batch 020/136 @epoch1/10: 0.20592 in 0.09 secs
Val Loss for batch 030/136 @epoch1/10: 0.22215 in 0.09 secs
Val Loss for batch 040/136 @epoch1/10: 0.24444 in 0.09 secs
Val Loss for batch 050/136 @epoch1/10: 0.21848 in 0.09 secs
Val Loss for batch 060/136 @epoch1/10: 0.22035 in 0.09 secs
Val Loss for batch 070/136 @epoch1/10: 0.26499 in 0.09 secs
Val Loss for batch 080/136 @epoch1/10: 0.24295 in 0.09 secs
Val Loss for batch 090/136 @epoch1/10: 0.23542 in 0.09 secs
Val Loss for batch 100/136 @epoch1/10: 0.18594 in 0.09 secs
Val Loss for batch 110/136 @epoch1/10: 0.20891 in 0.09 secs
Val Loss for batch 120/136 @epoch1/10: 0.18517 in 0.09 secs
Val Loss for batch 130/136 @epoch1/10: 0.20298 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7533318576875456, 'Cardiomegaly': 0.8723088913959121, 'Consolidation': 0.7505353587697451, 'Edema': 0.8778606913603417, 'Effusion': 0.8689709927242283, 'Emphysema': 0.806066060848401, 'Fibrosis': 0.6886487506023583, 'Hernia': 0.8269943267338197, 'Infiltration': 0.631083068299872, 'Mass': 0.750468092317337, 'Nodule': 0.6616762104233235, 'Pleural_Thickening': 0.669062126429841, 'Pneumonia': 0.6622119490389116, 'Pneumothorax': 0.7343665241546975, 'none': 0.745151522459234}
AVG Loss in validation set: 0.22421102889202504
0.7538274929133096
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/10: 0.16139 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch2/10: 0.1797 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch2/10: 0.17238 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch2/10: 0.16466 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch2/10: 0.16662 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch2/10: 0.17492 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch2/10: 0.18016 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch2/10: 0.15391 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch2/10: 0.17483 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch2/10: 0.15856 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch2/10: 0.16317 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch2/10: 0.14087 in 0 mins 0.24 secs
Train Loss for batch 130/541 @epoch2/10: 0.19064 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch2/10: 0.1553 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch2/10: 0.17384 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch2/10: 0.16373 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch2/10: 0.18591 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch2/10: 0.15553 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch2/10: 0.15613 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch2/10: 0.13945 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch2/10: 0.18332 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch2/10: 0.14674 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch2/10: 0.14855 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch2/10: 0.15696 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch2/10: 0.1495 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch2/10: 0.12958 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch2/10: 0.16678 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch2/10: 0.15492 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch2/10: 0.15524 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch2/10: 0.15285 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch2/10: 0.15885 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch2/10: 0.15571 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch2/10: 0.1513 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch2/10: 0.15919 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch2/10: 0.17478 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch2/10: 0.14417 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch2/10: 0.15305 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch2/10: 0.13805 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch2/10: 0.14803 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch2/10: 0.12788 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch2/10: 0.1316 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch2/10: 0.1551 in 0 mins 0.24 secs
Train Loss for batch 430/541 @epoch2/10: 0.15844 in 0 mins 0.24 secs
Train Loss for batch 440/541 @epoch2/10: 0.1463 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch2/10: 0.16396 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch2/10: 0.12999 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch2/10: 0.15647 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch2/10: 0.1439 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch2/10: 0.1436 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch2/10: 0.1306 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch2/10: 0.13956 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch2/10: 0.14451 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch2/10: 0.13558 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch2/10: 0.15701 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/10: 0.23506 in 0.09 secs
Val Loss for batch 020/136 @epoch2/10: 0.19343 in 0.09 secs
Val Loss for batch 030/136 @epoch2/10: 0.23459 in 0.09 secs
Val Loss for batch 040/136 @epoch2/10: 0.27085 in 0.08 secs
Val Loss for batch 050/136 @epoch2/10: 0.226 in 0.09 secs
Val Loss for batch 060/136 @epoch2/10: 0.22511 in 0.09 secs
Val Loss for batch 070/136 @epoch2/10: 0.25919 in 0.08 secs
Val Loss for batch 080/136 @epoch2/10: 0.26242 in 0.09 secs
Val Loss for batch 090/136 @epoch2/10: 0.24842 in 0.09 secs
Val Loss for batch 100/136 @epoch2/10: 0.18021 in 0.09 secs
Val Loss for batch 110/136 @epoch2/10: 0.20918 in 0.09 secs
Val Loss for batch 120/136 @epoch2/10: 0.19922 in 0.09 secs
Val Loss for batch 130/136 @epoch2/10: 0.21313 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7198094516295506, 'Cardiomegaly': 0.8727305096255078, 'Consolidation': 0.7323756615815691, 'Edema': 0.8480609023844414, 'Effusion': 0.8664760265088086, 'Emphysema': 0.852052566668867, 'Fibrosis': 0.6808603575162249, 'Hernia': 0.7838910115395007, 'Infiltration': 0.5980180585648239, 'Mass': 0.7737301791719257, 'Nodule': 0.6284204406409275, 'Pleural_Thickening': 0.6877332527516842, 'Pneumonia': 0.6374717095316944, 'Pneumothorax': 0.7796662695241482, 'none': 0.7313576852884146}
AVG Loss in validation set: 0.23128761188525376
0.7472354569742624
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/10: 0.15756 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch3/10: 0.14124 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch3/10: 0.12359 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch3/10: 0.12019 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch3/10: 0.13355 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch3/10: 0.11746 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch3/10: 0.11468 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch3/10: 0.10969 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch3/10: 0.12928 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch3/10: 0.1132 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch3/10: 0.11527 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch3/10: 0.12 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch3/10: 0.13617 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch3/10: 0.12385 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch3/10: 0.13009 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch3/10: 0.1194 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch3/10: 0.11514 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch3/10: 0.11116 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch3/10: 0.12882 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch3/10: 0.11623 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch3/10: 0.10962 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch3/10: 0.11648 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch3/10: 0.12405 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch3/10: 0.11672 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch3/10: 0.12794 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch3/10: 0.12661 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch3/10: 0.11108 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch3/10: 0.11323 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch3/10: 0.13446 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch3/10: 0.11397 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch3/10: 0.10567 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch3/10: 0.09304 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch3/10: 0.11665 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch3/10: 0.11371 in 0 mins 0.24 secs
Train Loss for batch 350/541 @epoch3/10: 0.11624 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch3/10: 0.1082 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch3/10: 0.1271 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch3/10: 0.10571 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch3/10: 0.11382 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch3/10: 0.13636 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch3/10: 0.08245 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch3/10: 0.11199 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch3/10: 0.12259 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch3/10: 0.1208 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch3/10: 0.09366 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch3/10: 0.11019 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch3/10: 0.11152 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch3/10: 0.11998 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch3/10: 0.10323 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch3/10: 0.12203 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch3/10: 0.11856 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch3/10: 0.0913 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch3/10: 0.11409 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch3/10: 0.09742 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/10: 0.2067 in 0.09 secs
Val Loss for batch 020/136 @epoch3/10: 0.18447 in 0.09 secs
Val Loss for batch 030/136 @epoch3/10: 0.22397 in 0.09 secs
Val Loss for batch 040/136 @epoch3/10: 0.23438 in 0.09 secs
Val Loss for batch 050/136 @epoch3/10: 0.22019 in 0.09 secs
Val Loss for batch 060/136 @epoch3/10: 0.22358 in 0.09 secs
Val Loss for batch 070/136 @epoch3/10: 0.24861 in 0.09 secs
Val Loss for batch 080/136 @epoch3/10: 0.25428 in 0.09 secs
Val Loss for batch 090/136 @epoch3/10: 0.24484 in 0.09 secs
Val Loss for batch 100/136 @epoch3/10: 0.16829 in 0.09 secs
Val Loss for batch 110/136 @epoch3/10: 0.18658 in 0.09 secs
Val Loss for batch 120/136 @epoch3/10: 0.1784 in 0.09 secs
Val Loss for batch 130/136 @epoch3/10: 0.1853 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7566929285120585, 'Cardiomegaly': 0.8540205037578431, 'Consolidation': 0.7395826505866161, 'Edema': 0.8711057379133055, 'Effusion': 0.8663927442748993, 'Emphysema': 0.8444808749528261, 'Fibrosis': 0.7320512157000757, 'Hernia': 0.7827833738566631, 'Infiltration': 0.6692816190595565, 'Mass': 0.7207537790469057, 'Nodule': 0.648751577176157, 'Pleural_Thickening': 0.6759170640331504, 'Pneumonia': 0.654930809276124, 'Pneumothorax': 0.7809938889674009, 'none': 0.7431786500983066}
AVG Loss in validation set: 0.21738320648311962
0.7569813405081129
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/10: 0.09519 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch4/10: 0.09321 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch4/10: 0.12339 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch4/10: 0.10921 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch4/10: 0.09557 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch4/10: 0.11818 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch4/10: 0.10808 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch4/10: 0.1001 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch4/10: 0.12817 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch4/10: 0.08889 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch4/10: 0.08163 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch4/10: 0.09258 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch4/10: 0.10899 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch4/10: 0.0863 in 0 mins 0.24 secs
Train Loss for batch 150/541 @epoch4/10: 0.10098 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch4/10: 0.09236 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch4/10: 0.11764 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch4/10: 0.10077 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch4/10: 0.09412 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch4/10: 0.09027 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch4/10: 0.09838 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch4/10: 0.10298 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch4/10: 0.09159 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch4/10: 0.09026 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch4/10: 0.1032 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch4/10: 0.10966 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch4/10: 0.10605 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch4/10: 0.08668 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch4/10: 0.08367 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch4/10: 0.09427 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch4/10: 0.07426 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch4/10: 0.10189 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch4/10: 0.09777 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch4/10: 0.08468 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch4/10: 0.09855 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch4/10: 0.08766 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch4/10: 0.10946 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch4/10: 0.08847 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch4/10: 0.09024 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch4/10: 0.10308 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch4/10: 0.09279 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch4/10: 0.09653 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch4/10: 0.07321 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch4/10: 0.10546 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch4/10: 0.09597 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch4/10: 0.08244 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch4/10: 0.09877 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch4/10: 0.08468 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch4/10: 0.09387 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch4/10: 0.10676 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch4/10: 0.11345 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch4/10: 0.09288 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch4/10: 0.09021 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch4/10: 0.10854 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/10: 0.21278 in 0.09 secs
Val Loss for batch 020/136 @epoch4/10: 0.19154 in 0.09 secs
Val Loss for batch 030/136 @epoch4/10: 0.21417 in 0.09 secs
Val Loss for batch 040/136 @epoch4/10: 0.25004 in 0.09 secs
Val Loss for batch 050/136 @epoch4/10: 0.21195 in 0.09 secs
Val Loss for batch 060/136 @epoch4/10: 0.25325 in 0.09 secs
Val Loss for batch 070/136 @epoch4/10: 0.25989 in 0.09 secs
Val Loss for batch 080/136 @epoch4/10: 0.25309 in 0.09 secs
Val Loss for batch 090/136 @epoch4/10: 0.24332 in 0.09 secs
Val Loss for batch 100/136 @epoch4/10: 0.16867 in 0.09 secs
Val Loss for batch 110/136 @epoch4/10: 0.21002 in 0.08 secs
Val Loss for batch 120/136 @epoch4/10: 0.15038 in 0.09 secs
Val Loss for batch 130/136 @epoch4/10: 0.19364 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7668899753524736, 'Cardiomegaly': 0.8622078376002714, 'Consolidation': 0.7128740086517664, 'Edema': 0.8715923808734042, 'Effusion': 0.8609269238933045, 'Emphysema': 0.834244976599161, 'Fibrosis': 0.7172380876803768, 'Hernia': 0.8697802091775694, 'Infiltration': 0.6462331375661676, 'Mass': 0.7696772099076404, 'Nodule': 0.6740829881257345, 'Pleural_Thickening': 0.6389099771395679, 'Pneumonia': 0.6688229477880565, 'Pneumothorax': 0.7908266616240128, 'none': 0.734475596000844}
AVG Loss in validation set: 0.2167968880962124
0.7631648087128219
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/10: 0.09289 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch5/10: 0.08521 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch5/10: 0.08369 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch5/10: 0.11527 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch5/10: 0.08217 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch5/10: 0.08463 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch5/10: 0.08812 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch5/10: 0.0871 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch5/10: 0.07877 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch5/10: 0.07781 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch5/10: 0.07951 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch5/10: 0.08043 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch5/10: 0.0729 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch5/10: 0.08395 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch5/10: 0.08896 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch5/10: 0.08467 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch5/10: 0.07778 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch5/10: 0.07663 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch5/10: 0.08563 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch5/10: 0.09143 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch5/10: 0.07819 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch5/10: 0.08182 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch5/10: 0.09547 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch5/10: 0.05798 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch5/10: 0.06575 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch5/10: 0.08995 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch5/10: 0.09326 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch5/10: 0.08911 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch5/10: 0.06317 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch5/10: 0.08577 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch5/10: 0.05785 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch5/10: 0.07294 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch5/10: 0.0645 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch5/10: 0.0872 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch5/10: 0.09453 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch5/10: 0.09087 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch5/10: 0.08594 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch5/10: 0.06442 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch5/10: 0.07228 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch5/10: 0.0712 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch5/10: 0.07185 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch5/10: 0.06681 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch5/10: 0.07393 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch5/10: 0.06572 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch5/10: 0.07864 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch5/10: 0.06169 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch5/10: 0.07446 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch5/10: 0.08419 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch5/10: 0.08768 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch5/10: 0.07063 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch5/10: 0.0585 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch5/10: 0.08126 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch5/10: 0.07397 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch5/10: 0.06188 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/10: 0.20072 in 0.09 secs
Val Loss for batch 020/136 @epoch5/10: 0.17476 in 0.09 secs
Val Loss for batch 030/136 @epoch5/10: 0.22741 in 0.09 secs
Val Loss for batch 040/136 @epoch5/10: 0.24878 in 0.09 secs
Val Loss for batch 050/136 @epoch5/10: 0.20051 in 0.08 secs
Val Loss for batch 060/136 @epoch5/10: 0.21592 in 0.08 secs
Val Loss for batch 070/136 @epoch5/10: 0.26641 in 0.09 secs
Val Loss for batch 080/136 @epoch5/10: 0.24637 in 0.08 secs
Val Loss for batch 090/136 @epoch5/10: 0.23495 in 0.09 secs
Val Loss for batch 100/136 @epoch5/10: 0.15349 in 0.08 secs
Val Loss for batch 110/136 @epoch5/10: 0.19371 in 0.09 secs
Val Loss for batch 120/136 @epoch5/10: 0.14962 in 0.09 secs
Val Loss for batch 130/136 @epoch5/10: 0.1757 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7499784954604314, 'Cardiomegaly': 0.8444328706106908, 'Consolidation': 0.7235826178147735, 'Edema': 0.8731797534706045, 'Effusion': 0.8694692858069386, 'Emphysema': 0.8417309979910611, 'Fibrosis': 0.6880434595094417, 'Hernia': 0.8682326039133959, 'Infiltration': 0.6343308381602324, 'Mass': 0.7732345011999101, 'Nodule': 0.6576971670621129, 'Pleural_Thickening': 0.7019827182155136, 'Pneumonia': 0.6699987176487527, 'Pneumothorax': 0.8106574678467952, 'none': 0.7479650491917846}
AVG Loss in validation set: 0.2105472217099952
0.7647536781936182
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch6/10: 0.07952 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch6/10: 0.0688 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch6/10: 0.08385 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch6/10: 0.05608 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch6/10: 0.06957 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch6/10: 0.0696 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch6/10: 0.07573 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch6/10: 0.07879 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch6/10: 0.06967 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch6/10: 0.06572 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch6/10: 0.07421 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch6/10: 0.05317 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch6/10: 0.0819 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch6/10: 0.06328 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch6/10: 0.06259 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch6/10: 0.0611 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch6/10: 0.07186 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch6/10: 0.06315 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch6/10: 0.07245 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch6/10: 0.06602 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch6/10: 0.07304 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch6/10: 0.08166 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch6/10: 0.05294 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch6/10: 0.09393 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch6/10: 0.08132 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch6/10: 0.06086 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch6/10: 0.06588 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch6/10: 0.08755 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch6/10: 0.0733 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch6/10: 0.06768 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch6/10: 0.06434 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch6/10: 0.04569 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch6/10: 0.07345 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch6/10: 0.05898 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch6/10: 0.07439 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch6/10: 0.07104 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch6/10: 0.05837 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch6/10: 0.08618 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch6/10: 0.06038 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch6/10: 0.07599 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch6/10: 0.06665 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch6/10: 0.07429 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch6/10: 0.07474 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch6/10: 0.06284 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch6/10: 0.05945 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch6/10: 0.06845 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch6/10: 0.05602 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch6/10: 0.05812 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch6/10: 0.06941 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch6/10: 0.07073 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch6/10: 0.06221 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch6/10: 0.07273 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch6/10: 0.07252 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch6/10: 0.06429 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch6/10: 0.21526 in 0.09 secs
Val Loss for batch 020/136 @epoch6/10: 0.18122 in 0.09 secs
Val Loss for batch 030/136 @epoch6/10: 0.2327 in 0.09 secs
Val Loss for batch 040/136 @epoch6/10: 0.23441 in 0.09 secs
Val Loss for batch 050/136 @epoch6/10: 0.20521 in 0.09 secs
Val Loss for batch 060/136 @epoch6/10: 0.21215 in 0.09 secs
Val Loss for batch 070/136 @epoch6/10: 0.25275 in 0.09 secs
Val Loss for batch 080/136 @epoch6/10: 0.24108 in 0.09 secs
Val Loss for batch 090/136 @epoch6/10: 0.25773 in 0.08 secs
Val Loss for batch 100/136 @epoch6/10: 0.16009 in 0.09 secs
Val Loss for batch 110/136 @epoch6/10: 0.19301 in 0.08 secs
Val Loss for batch 120/136 @epoch6/10: 0.15982 in 0.09 secs
Val Loss for batch 130/136 @epoch6/10: 0.18031 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7442298803262687, 'Cardiomegaly': 0.8346152988394636, 'Consolidation': 0.71483499377335, 'Edema': 0.8805828367792965, 'Effusion': 0.858818538330464, 'Emphysema': 0.8373850848968837, 'Fibrosis': 0.7090064508412315, 'Hernia': 0.8360657635753155, 'Infiltration': 0.6422635607837637, 'Mass': 0.767917098666657, 'Nodule': 0.6852207495672058, 'Pleural_Thickening': 0.6919772225612303, 'Pneumonia': 0.6778587433857672, 'Pneumothorax': 0.7839381081297202, 'none': 0.7422237254887007}
AVG Loss in validation set: 0.21340006888188315
0.7617653093183299
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch7/10: 0.05378 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch7/10: 0.07248 in 0 mins 0.24 secs
Train Loss for batch 030/541 @epoch7/10: 0.06562 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch7/10: 0.0631 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch7/10: 0.05357 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch7/10: 0.05986 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch7/10: 0.08186 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch7/10: 0.07511 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch7/10: 0.0627 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch7/10: 0.05304 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch7/10: 0.04996 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch7/10: 0.05445 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch7/10: 0.04828 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch7/10: 0.05248 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch7/10: 0.07168 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch7/10: 0.06726 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch7/10: 0.06119 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch7/10: 0.05395 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch7/10: 0.05267 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch7/10: 0.05615 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch7/10: 0.0606 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch7/10: 0.06078 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch7/10: 0.04616 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch7/10: 0.07496 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch7/10: 0.06201 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch7/10: 0.06687 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch7/10: 0.05712 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch7/10: 0.05969 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch7/10: 0.04984 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch7/10: 0.05347 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch7/10: 0.04828 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch7/10: 0.07079 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch7/10: 0.05638 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch7/10: 0.05667 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch7/10: 0.06591 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch7/10: 0.06541 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch7/10: 0.06504 in 0 mins 0.24 secs
Train Loss for batch 380/541 @epoch7/10: 0.04771 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch7/10: 0.06741 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch7/10: 0.07086 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch7/10: 0.05261 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch7/10: 0.05044 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch7/10: 0.06145 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch7/10: 0.06017 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch7/10: 0.04774 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch7/10: 0.06944 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch7/10: 0.04706 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch7/10: 0.03684 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch7/10: 0.05135 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch7/10: 0.04625 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch7/10: 0.05682 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch7/10: 0.06063 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch7/10: 0.05232 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch7/10: 0.05181 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch7/10: 0.2111 in 0.09 secs
Val Loss for batch 020/136 @epoch7/10: 0.18403 in 0.09 secs
Val Loss for batch 030/136 @epoch7/10: 0.22446 in 0.09 secs
Val Loss for batch 040/136 @epoch7/10: 0.25309 in 0.09 secs
Val Loss for batch 050/136 @epoch7/10: 0.20359 in 0.09 secs
Val Loss for batch 060/136 @epoch7/10: 0.22909 in 0.09 secs
Val Loss for batch 070/136 @epoch7/10: 0.2619 in 0.09 secs
Val Loss for batch 080/136 @epoch7/10: 0.24709 in 0.09 secs
Val Loss for batch 090/136 @epoch7/10: 0.23396 in 0.09 secs
Val Loss for batch 100/136 @epoch7/10: 0.15922 in 0.08 secs
Val Loss for batch 110/136 @epoch7/10: 0.19831 in 0.08 secs
Val Loss for batch 120/136 @epoch7/10: 0.15304 in 0.09 secs
Val Loss for batch 130/136 @epoch7/10: 0.16587 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.747253669424917, 'Cardiomegaly': 0.8350567194756477, 'Consolidation': 0.7120995178442683, 'Edema': 0.8704283658289352, 'Effusion': 0.8589260129478078, 'Emphysema': 0.8372285910963454, 'Fibrosis': 0.6929150004772864, 'Hernia': 0.859991895334028, 'Infiltration': 0.6344484738051623, 'Mass': 0.7654691675757352, 'Nodule': 0.6746540313162925, 'Pleural_Thickening': 0.7070067464077414, 'Pneumonia': 0.659298677603398, 'Pneumothorax': 0.8016437576287323, 'none': 0.7446646509979304}
AVG Loss in validation set: 0.21368990014244768
0.7611729019118784
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch8/10: 0.04188 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch8/10: 0.05615 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch8/10: 0.05338 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch8/10: 0.0528 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch8/10: 0.04684 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch8/10: 0.04615 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch8/10: 0.04792 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch8/10: 0.04489 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch8/10: 0.07428 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch8/10: 0.04502 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch8/10: 0.07283 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch8/10: 0.05185 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch8/10: 0.06609 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch8/10: 0.04336 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch8/10: 0.05054 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch8/10: 0.03584 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch8/10: 0.05606 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch8/10: 0.05477 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch8/10: 0.06248 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch8/10: 0.06208 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch8/10: 0.06295 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch8/10: 0.0565 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch8/10: 0.0549 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch8/10: 0.05735 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch8/10: 0.06749 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch8/10: 0.06333 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch8/10: 0.0722 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch8/10: 0.0449 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch8/10: 0.04539 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch8/10: 0.04297 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch8/10: 0.06946 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch8/10: 0.05587 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch8/10: 0.05018 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch8/10: 0.06377 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch8/10: 0.043 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch8/10: 0.06206 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch8/10: 0.0483 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch8/10: 0.0514 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch8/10: 0.05131 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch8/10: 0.06323 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch8/10: 0.04539 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch8/10: 0.05552 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch8/10: 0.04429 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch8/10: 0.05044 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch8/10: 0.06078 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch8/10: 0.04522 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch8/10: 0.04351 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch8/10: 0.0503 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch8/10: 0.04861 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch8/10: 0.05471 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch8/10: 0.05065 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch8/10: 0.05101 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch8/10: 0.06807 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch8/10: 0.04544 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch8/10: 0.21187 in 0.09 secs
Val Loss for batch 020/136 @epoch8/10: 0.18309 in 0.08 secs
Val Loss for batch 030/136 @epoch8/10: 0.23437 in 0.08 secs
Val Loss for batch 040/136 @epoch8/10: 0.25899 in 0.09 secs
Val Loss for batch 050/136 @epoch8/10: 0.20576 in 0.09 secs
Val Loss for batch 060/136 @epoch8/10: 0.23477 in 0.09 secs
Val Loss for batch 070/136 @epoch8/10: 0.27193 in 0.09 secs
Val Loss for batch 080/136 @epoch8/10: 0.24738 in 0.08 secs
Val Loss for batch 090/136 @epoch8/10: 0.26837 in 0.09 secs
Val Loss for batch 100/136 @epoch8/10: 0.14925 in 0.09 secs
Val Loss for batch 110/136 @epoch8/10: 0.20488 in 0.09 secs
Val Loss for batch 120/136 @epoch8/10: 0.14518 in 0.09 secs
Val Loss for batch 130/136 @epoch8/10: 0.16688 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.748499117732674, 'Cardiomegaly': 0.8302024382722458, 'Consolidation': 0.7306359376024121, 'Edema': 0.8602782593894268, 'Effusion': 0.8540760204653193, 'Emphysema': 0.849758929325594, 'Fibrosis': 0.681546729783473, 'Hernia': 0.8142854386168037, 'Infiltration': 0.6413178390842648, 'Mass': 0.773598616818844, 'Nodule': 0.6757321583172304, 'Pleural_Thickening': 0.7172676064430561, 'Pneumonia': 0.663277341078435, 'Pneumothorax': 0.7987069817453584, 'none': 0.7369325984916082}
AVG Loss in validation set: 0.21980909104844348
0.7599416724767956
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch9/10: 0.04857 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch9/10: 0.04244 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch9/10: 0.07035 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch9/10: 0.04211 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch9/10: 0.02923 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch9/10: 0.04851 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch9/10: 0.05746 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch9/10: 0.06485 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch9/10: 0.05886 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch9/10: 0.05461 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch9/10: 0.05407 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch9/10: 0.05902 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch9/10: 0.06424 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch9/10: 0.05903 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch9/10: 0.04218 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch9/10: 0.04121 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch9/10: 0.0459 in 0 mins 0.24 secs
Train Loss for batch 180/541 @epoch9/10: 0.05033 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch9/10: 0.05169 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch9/10: 0.04811 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch9/10: 0.04543 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch9/10: 0.04845 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch9/10: 0.03305 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch9/10: 0.05688 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch9/10: 0.05337 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch9/10: 0.04676 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch9/10: 0.05445 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch9/10: 0.03542 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch9/10: 0.05198 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch9/10: 0.03957 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch9/10: 0.05148 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch9/10: 0.04266 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch9/10: 0.04931 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch9/10: 0.06843 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch9/10: 0.04448 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch9/10: 0.04077 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch9/10: 0.05158 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch9/10: 0.05153 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch9/10: 0.04286 in 0 mins 0.24 secs
Train Loss for batch 400/541 @epoch9/10: 0.04238 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch9/10: 0.05794 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch9/10: 0.05263 in 0 mins 0.24 secs
Train Loss for batch 430/541 @epoch9/10: 0.05273 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch9/10: 0.03566 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch9/10: 0.04543 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch9/10: 0.04355 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch9/10: 0.05652 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch9/10: 0.06576 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch9/10: 0.03608 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch9/10: 0.04555 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch9/10: 0.05094 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch9/10: 0.05706 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch9/10: 0.04543 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch9/10: 0.04939 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch9/10: 0.21498 in 0.08 secs
Val Loss for batch 020/136 @epoch9/10: 0.19332 in 0.09 secs
Val Loss for batch 030/136 @epoch9/10: 0.23215 in 0.09 secs
Val Loss for batch 040/136 @epoch9/10: 0.26647 in 0.09 secs
Val Loss for batch 050/136 @epoch9/10: 0.20991 in 0.09 secs
Val Loss for batch 060/136 @epoch9/10: 0.22821 in 0.09 secs
Val Loss for batch 070/136 @epoch9/10: 0.27637 in 0.09 secs
Val Loss for batch 080/136 @epoch9/10: 0.24831 in 0.09 secs
Val Loss for batch 090/136 @epoch9/10: 0.25916 in 0.09 secs
Val Loss for batch 100/136 @epoch9/10: 0.15796 in 0.09 secs
Val Loss for batch 110/136 @epoch9/10: 0.20454 in 0.09 secs
Val Loss for batch 120/136 @epoch9/10: 0.14597 in 0.09 secs
Val Loss for batch 130/136 @epoch9/10: 0.16817 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7483244303112001, 'Cardiomegaly': 0.8253848780364009, 'Consolidation': 0.7480852538998494, 'Edema': 0.8686651034443629, 'Effusion': 0.8563683639536803, 'Emphysema': 0.8351246523279555, 'Fibrosis': 0.6792527650980623, 'Hernia': 0.8056983520512523, 'Infiltration': 0.6405670327116693, 'Mass': 0.7808766852506472, 'Nodule': 0.6773308249672274, 'Pleural_Thickening': 0.70436319305494, 'Pneumonia': 0.6667602183146755, 'Pneumothorax': 0.8004049546085715, 'none': 0.739754541592697}
AVG Loss in validation set: 0.218896873608762
0.7598004791450353
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch10/10: 0.05269 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch10/10: 0.05338 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch10/10: 0.04833 in 0 mins 0.24 secs
Train Loss for batch 040/541 @epoch10/10: 0.05519 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch10/10: 0.03901 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch10/10: 0.03605 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch10/10: 0.04494 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch10/10: 0.06629 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch10/10: 0.03801 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch10/10: 0.04204 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch10/10: 0.04658 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch10/10: 0.05213 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch10/10: 0.03355 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch10/10: 0.04423 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch10/10: 0.05134 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch10/10: 0.04473 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch10/10: 0.05683 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch10/10: 0.03726 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch10/10: 0.02983 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch10/10: 0.04365 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch10/10: 0.05101 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch10/10: 0.04452 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch10/10: 0.04501 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch10/10: 0.05337 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch10/10: 0.04498 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch10/10: 0.03774 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch10/10: 0.04262 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch10/10: 0.04693 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch10/10: 0.04032 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch10/10: 0.03924 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch10/10: 0.05391 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch10/10: 0.04499 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch10/10: 0.05607 in 0 mins 0.24 secs
Train Loss for batch 340/541 @epoch10/10: 0.07344 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch10/10: 0.06494 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch10/10: 0.04278 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch10/10: 0.06157 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch10/10: 0.05011 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch10/10: 0.04996 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch10/10: 0.04156 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch10/10: 0.0369 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch10/10: 0.03609 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch10/10: 0.0718 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch10/10: 0.03961 in 0 mins 0.24 secs
Train Loss for batch 450/541 @epoch10/10: 0.03788 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch10/10: 0.06319 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch10/10: 0.04619 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch10/10: 0.0383 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch10/10: 0.05179 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch10/10: 0.04131 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch10/10: 0.05341 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch10/10: 0.0381 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch10/10: 0.0562 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch10/10: 0.02746 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch10/10: 0.21889 in 0.09 secs
Val Loss for batch 020/136 @epoch10/10: 0.19379 in 0.09 secs
Val Loss for batch 030/136 @epoch10/10: 0.23371 in 0.09 secs
Val Loss for batch 040/136 @epoch10/10: 0.26164 in 0.08 secs
Val Loss for batch 050/136 @epoch10/10: 0.21162 in 0.09 secs
Val Loss for batch 060/136 @epoch10/10: 0.22889 in 0.09 secs
Val Loss for batch 070/136 @epoch10/10: 0.27295 in 0.09 secs
Val Loss for batch 080/136 @epoch10/10: 0.25075 in 0.09 secs
Val Loss for batch 090/136 @epoch10/10: 0.26675 in 0.09 secs
Val Loss for batch 100/136 @epoch10/10: 0.16163 in 0.09 secs
Val Loss for batch 110/136 @epoch10/10: 0.20492 in 0.09 secs
Val Loss for batch 120/136 @epoch10/10: 0.15098 in 0.08 secs
Val Loss for batch 130/136 @epoch10/10: 0.16247 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7425012579492871, 'Cardiomegaly': 0.8138546864798396, 'Consolidation': 0.7373742892606672, 'Edema': 0.857137993830764, 'Effusion': 0.8525378786762103, 'Emphysema': 0.8464803842043183, 'Fibrosis': 0.6755499431281693, 'Hernia': 0.8305295048435027, 'Infiltration': 0.6418725258338378, 'Mass': 0.7682690082436977, 'Nodule': 0.6764540411062098, 'Pleural_Thickening': 0.7051916642681921, 'Pneumonia': 0.6634351040279328, 'Pneumothorax': 0.8054943468799334, 'none': 0.7435242571077607}
AVG Loss in validation set: 0.22043854563780751
0.7583344734808973
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_2/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/10: 0.53405 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch1/10: 0.42271 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch1/10: 0.36101 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch1/10: 0.31904 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch1/10: 0.30087 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch1/10: 0.27703 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch1/10: 0.27374 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch1/10: 0.26753 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch1/10: 0.25625 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch1/10: 0.25386 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch1/10: 0.24477 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch1/10: 0.23535 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch1/10: 0.24308 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch1/10: 0.24068 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch1/10: 0.24254 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch1/10: 0.2393 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch1/10: 0.22715 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch1/10: 0.2307 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch1/10: 0.2252 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch1/10: 0.22975 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch1/10: 0.22324 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch1/10: 0.2152 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch1/10: 0.20959 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch1/10: 0.22429 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch1/10: 0.23234 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch1/10: 0.21957 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch1/10: 0.22841 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch1/10: 0.20355 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch1/10: 0.23077 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch1/10: 0.2203 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch1/10: 0.20513 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch1/10: 0.20797 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch1/10: 0.20426 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch1/10: 0.19361 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch1/10: 0.21735 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch1/10: 0.2069 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch1/10: 0.2033 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch1/10: 0.20711 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch1/10: 0.19376 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch1/10: 0.20233 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch1/10: 0.20408 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch1/10: 0.21175 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch1/10: 0.20548 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch1/10: 0.19369 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch1/10: 0.21565 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch1/10: 0.20483 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch1/10: 0.19413 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch1/10: 0.18611 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch1/10: 0.20868 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch1/10: 0.18429 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch1/10: 0.18311 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch1/10: 0.18691 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch1/10: 0.17288 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch1/10: 0.18577 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/10: 0.2272 in 0.08 secs
Val Loss for batch 020/136 @epoch1/10: 0.2006 in 0.09 secs
Val Loss for batch 030/136 @epoch1/10: 0.22061 in 0.09 secs
Val Loss for batch 040/136 @epoch1/10: 0.2402 in 0.09 secs
Val Loss for batch 050/136 @epoch1/10: 0.21367 in 0.09 secs
Val Loss for batch 060/136 @epoch1/10: 0.21305 in 0.08 secs
Val Loss for batch 070/136 @epoch1/10: 0.24396 in 0.09 secs
Val Loss for batch 080/136 @epoch1/10: 0.23847 in 0.09 secs
Val Loss for batch 090/136 @epoch1/10: 0.23228 in 0.09 secs
Val Loss for batch 100/136 @epoch1/10: 0.18594 in 0.09 secs
Val Loss for batch 110/136 @epoch1/10: 0.21054 in 0.09 secs
Val Loss for batch 120/136 @epoch1/10: 0.19761 in 0.09 secs
Val Loss for batch 130/136 @epoch1/10: 0.20476 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7478733550046887, 'Cardiomegaly': 0.8730106271633649, 'Consolidation': 0.7489955430294292, 'Edema': 0.8850682445828237, 'Effusion': 0.862747801496427, 'Emphysema': 0.8183500216583407, 'Fibrosis': 0.7226513198980102, 'Hernia': 0.8160491683068967, 'Infiltration': 0.6168980858146731, 'Mass': 0.7344386674187091, 'Nodule': 0.6385740187320813, 'Pleural_Thickening': 0.7091420315406931, 'Pneumonia': 0.6480962427108455, 'Pneumothorax': 0.7702187368453876, 'none': 0.7449248576311145}
AVG Loss in validation set: 0.22090763836010593
0.7565795617287407
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/10: 0.17841 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch2/10: 0.19082 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch2/10: 0.18104 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch2/10: 0.17191 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch2/10: 0.18566 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch2/10: 0.18649 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch2/10: 0.18902 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch2/10: 0.16852 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch2/10: 0.18446 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch2/10: 0.17279 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch2/10: 0.17709 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch2/10: 0.15981 in 0 mins 0.24 secs
Train Loss for batch 130/541 @epoch2/10: 0.1985 in 0 mins 0.24 secs
Train Loss for batch 140/541 @epoch2/10: 0.16662 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch2/10: 0.18774 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch2/10: 0.17324 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch2/10: 0.20542 in 0 mins 0.24 secs
Train Loss for batch 180/541 @epoch2/10: 0.16426 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch2/10: 0.16906 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch2/10: 0.14792 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch2/10: 0.19399 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch2/10: 0.1603 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch2/10: 0.15248 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch2/10: 0.15866 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch2/10: 0.1695 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch2/10: 0.14564 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch2/10: 0.17101 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch2/10: 0.15299 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch2/10: 0.15622 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch2/10: 0.15782 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch2/10: 0.15941 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch2/10: 0.15205 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch2/10: 0.15078 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch2/10: 0.15837 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch2/10: 0.17665 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch2/10: 0.14946 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch2/10: 0.15335 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch2/10: 0.14241 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch2/10: 0.14969 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch2/10: 0.14339 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch2/10: 0.12992 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch2/10: 0.14767 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch2/10: 0.16203 in 0 mins 0.24 secs
Train Loss for batch 440/541 @epoch2/10: 0.15358 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch2/10: 0.15389 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch2/10: 0.13683 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch2/10: 0.16079 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch2/10: 0.14068 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch2/10: 0.15493 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch2/10: 0.13781 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch2/10: 0.14483 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch2/10: 0.15134 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch2/10: 0.12968 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch2/10: 0.16315 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/10: 0.22455 in 0.09 secs
Val Loss for batch 020/136 @epoch2/10: 0.19201 in 0.09 secs
Val Loss for batch 030/136 @epoch2/10: 0.21936 in 0.09 secs
Val Loss for batch 040/136 @epoch2/10: 0.24005 in 0.08 secs
Val Loss for batch 050/136 @epoch2/10: 0.20568 in 0.09 secs
Val Loss for batch 060/136 @epoch2/10: 0.2123 in 0.09 secs
Val Loss for batch 070/136 @epoch2/10: 0.24005 in 0.08 secs
Val Loss for batch 080/136 @epoch2/10: 0.23136 in 0.09 secs
Val Loss for batch 090/136 @epoch2/10: 0.22785 in 0.09 secs
Val Loss for batch 100/136 @epoch2/10: 0.17796 in 0.09 secs
Val Loss for batch 110/136 @epoch2/10: 0.19795 in 0.09 secs
Val Loss for batch 120/136 @epoch2/10: 0.19074 in 0.09 secs
Val Loss for batch 130/136 @epoch2/10: 0.19619 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7508715507442488, 'Cardiomegaly': 0.8564802318150463, 'Consolidation': 0.7481408124139739, 'Edema': 0.8366095170341403, 'Effusion': 0.8662076992582722, 'Emphysema': 0.8213658377644821, 'Fibrosis': 0.6968134523443961, 'Hernia': 0.7530508278337386, 'Infiltration': 0.6225094192816673, 'Mass': 0.7259098740419102, 'Nodule': 0.6280510231275848, 'Pleural_Thickening': 0.652600434013046, 'Pneumonia': 0.6321201428134336, 'Pneumothorax': 0.767721114419794, 'none': 0.7332780738621878}
AVG Loss in validation set: 0.21688769021300988
0.7398894240646953
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/10: 0.15099 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch3/10: 0.14397 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch3/10: 0.13574 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch3/10: 0.13111 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch3/10: 0.14164 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch3/10: 0.12258 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch3/10: 0.12477 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch3/10: 0.11638 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch3/10: 0.14815 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch3/10: 0.12146 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch3/10: 0.12554 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch3/10: 0.13596 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch3/10: 0.1402 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch3/10: 0.12447 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch3/10: 0.14054 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch3/10: 0.12898 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch3/10: 0.13215 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch3/10: 0.12763 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch3/10: 0.14599 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch3/10: 0.12217 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch3/10: 0.11719 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch3/10: 0.12982 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch3/10: 0.1376 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch3/10: 0.12992 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch3/10: 0.13607 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch3/10: 0.1291 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch3/10: 0.11986 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch3/10: 0.12154 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch3/10: 0.14599 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch3/10: 0.12426 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch3/10: 0.1232 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch3/10: 0.11099 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch3/10: 0.13018 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch3/10: 0.11801 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch3/10: 0.12304 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch3/10: 0.11712 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch3/10: 0.14409 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch3/10: 0.11853 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch3/10: 0.12467 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch3/10: 0.14829 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch3/10: 0.09269 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch3/10: 0.13312 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch3/10: 0.12889 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch3/10: 0.12322 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch3/10: 0.10288 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch3/10: 0.11821 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch3/10: 0.12486 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch3/10: 0.13004 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch3/10: 0.10966 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch3/10: 0.13133 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch3/10: 0.12946 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch3/10: 0.10021 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch3/10: 0.11852 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch3/10: 0.1128 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/10: 0.2091 in 0.09 secs
Val Loss for batch 020/136 @epoch3/10: 0.16978 in 0.09 secs
Val Loss for batch 030/136 @epoch3/10: 0.21105 in 0.09 secs
Val Loss for batch 040/136 @epoch3/10: 0.22614 in 0.09 secs
Val Loss for batch 050/136 @epoch3/10: 0.19439 in 0.09 secs
Val Loss for batch 060/136 @epoch3/10: 0.20144 in 0.09 secs
Val Loss for batch 070/136 @epoch3/10: 0.23154 in 0.09 secs
Val Loss for batch 080/136 @epoch3/10: 0.23028 in 0.09 secs
Val Loss for batch 090/136 @epoch3/10: 0.21504 in 0.09 secs
Val Loss for batch 100/136 @epoch3/10: 0.15331 in 0.09 secs
Val Loss for batch 110/136 @epoch3/10: 0.18486 in 0.09 secs
Val Loss for batch 120/136 @epoch3/10: 0.16137 in 0.09 secs
Val Loss for batch 130/136 @epoch3/10: 0.18758 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7639374397969759, 'Cardiomegaly': 0.827833839736624, 'Consolidation': 0.7189309620174346, 'Edema': 0.865281952856736, 'Effusion': 0.8677691490177118, 'Emphysema': 0.8336593286456084, 'Fibrosis': 0.711017033947135, 'Hernia': 0.7762977113967041, 'Infiltration': 0.6382260255713493, 'Mass': 0.7176990011101114, 'Nodule': 0.6375722474351442, 'Pleural_Thickening': 0.681387381381915, 'Pneumonia': 0.6245289608905367, 'Pneumothorax': 0.7533292328242567, 'none': 0.7372331143772117}
AVG Loss in validation set: 0.20423392781327293
0.7441050190448745
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/10: 0.09971 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch4/10: 0.1012 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch4/10: 0.12469 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch4/10: 0.11261 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch4/10: 0.10076 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch4/10: 0.11753 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch4/10: 0.12822 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch4/10: 0.11366 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch4/10: 0.13427 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch4/10: 0.09932 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch4/10: 0.0966 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch4/10: 0.10423 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch4/10: 0.11894 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch4/10: 0.09573 in 0 mins 0.24 secs
Train Loss for batch 150/541 @epoch4/10: 0.11297 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch4/10: 0.10757 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch4/10: 0.12013 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch4/10: 0.10744 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch4/10: 0.10921 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch4/10: 0.094 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch4/10: 0.10554 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch4/10: 0.10326 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch4/10: 0.10464 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch4/10: 0.09603 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch4/10: 0.10832 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch4/10: 0.1165 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch4/10: 0.12358 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch4/10: 0.10168 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch4/10: 0.09348 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch4/10: 0.10425 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch4/10: 0.07964 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch4/10: 0.11418 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch4/10: 0.09938 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch4/10: 0.10143 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch4/10: 0.10156 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch4/10: 0.09375 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch4/10: 0.11062 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch4/10: 0.11019 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch4/10: 0.09078 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch4/10: 0.09975 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch4/10: 0.09105 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch4/10: 0.10505 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch4/10: 0.08819 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch4/10: 0.11519 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch4/10: 0.09719 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch4/10: 0.08558 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch4/10: 0.10772 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch4/10: 0.08653 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch4/10: 0.09242 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch4/10: 0.11247 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch4/10: 0.11551 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch4/10: 0.11197 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch4/10: 0.09911 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch4/10: 0.10666 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/10: 0.20769 in 0.09 secs
Val Loss for batch 020/136 @epoch4/10: 0.17951 in 0.09 secs
Val Loss for batch 030/136 @epoch4/10: 0.2275 in 0.09 secs
Val Loss for batch 040/136 @epoch4/10: 0.23159 in 0.09 secs
Val Loss for batch 050/136 @epoch4/10: 0.19438 in 0.09 secs
Val Loss for batch 060/136 @epoch4/10: 0.2093 in 0.09 secs
Val Loss for batch 070/136 @epoch4/10: 0.24443 in 0.09 secs
Val Loss for batch 080/136 @epoch4/10: 0.24106 in 0.09 secs
Val Loss for batch 090/136 @epoch4/10: 0.24231 in 0.09 secs
Val Loss for batch 100/136 @epoch4/10: 0.15188 in 0.09 secs
Val Loss for batch 110/136 @epoch4/10: 0.18293 in 0.08 secs
Val Loss for batch 120/136 @epoch4/10: 0.15895 in 0.09 secs
Val Loss for batch 130/136 @epoch4/10: 0.18371 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7444637077806951, 'Cardiomegaly': 0.8603791910928391, 'Consolidation': 0.6914819324736187, 'Edema': 0.8677677600130063, 'Effusion': 0.8585466550022404, 'Emphysema': 0.8205789548340834, 'Fibrosis': 0.6610307774937061, 'Hernia': 0.7170381305237158, 'Infiltration': 0.6383856791078806, 'Mass': 0.7439553239337046, 'Nodule': 0.6501375638772678, 'Pleural_Thickening': 0.6726886996473311, 'Pneumonia': 0.6555061800331161, 'Pneumothorax': 0.7461026136470508, 'none': 0.7376971826326552}
AVG Loss in validation set: 0.21056242970559425
0.7377187978185897
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/10: 0.10883 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch5/10: 0.0991 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch5/10: 0.10276 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch5/10: 0.13173 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch5/10: 0.09203 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch5/10: 0.10323 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch5/10: 0.10534 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch5/10: 0.09583 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch5/10: 0.0925 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch5/10: 0.10728 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch5/10: 0.09454 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch5/10: 0.0975 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch5/10: 0.0901 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch5/10: 0.09666 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch5/10: 0.09711 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch5/10: 0.09661 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch5/10: 0.09191 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch5/10: 0.08661 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch5/10: 0.10103 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch5/10: 0.09991 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch5/10: 0.09537 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch5/10: 0.09248 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch5/10: 0.10142 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch5/10: 0.06602 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch5/10: 0.08625 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch5/10: 0.09929 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch5/10: 0.10298 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch5/10: 0.11991 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch5/10: 0.07761 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch5/10: 0.09841 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch5/10: 0.06488 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch5/10: 0.08485 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch5/10: 0.07645 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch5/10: 0.09997 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch5/10: 0.10114 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch5/10: 0.10961 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch5/10: 0.09864 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch5/10: 0.07838 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch5/10: 0.08805 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch5/10: 0.08209 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch5/10: 0.09373 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch5/10: 0.08562 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch5/10: 0.0879 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch5/10: 0.08567 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch5/10: 0.09426 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch5/10: 0.07817 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch5/10: 0.08808 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch5/10: 0.0982 in 0 mins 0.24 secs
Train Loss for batch 490/541 @epoch5/10: 0.09998 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch5/10: 0.07555 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch5/10: 0.07141 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch5/10: 0.09323 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch5/10: 0.09231 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch5/10: 0.07946 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/10: 0.22416 in 0.09 secs
Val Loss for batch 020/136 @epoch5/10: 0.18915 in 0.09 secs
Val Loss for batch 030/136 @epoch5/10: 0.23054 in 0.09 secs
Val Loss for batch 040/136 @epoch5/10: 0.25176 in 0.09 secs
Val Loss for batch 050/136 @epoch5/10: 0.22029 in 0.09 secs
Val Loss for batch 060/136 @epoch5/10: 0.21333 in 0.08 secs
Val Loss for batch 070/136 @epoch5/10: 0.25191 in 0.09 secs
Val Loss for batch 080/136 @epoch5/10: 0.24874 in 0.08 secs
Val Loss for batch 090/136 @epoch5/10: 0.24573 in 0.09 secs
Val Loss for batch 100/136 @epoch5/10: 0.16776 in 0.09 secs
Val Loss for batch 110/136 @epoch5/10: 0.18693 in 0.09 secs
Val Loss for batch 120/136 @epoch5/10: 0.17923 in 0.09 secs
Val Loss for batch 130/136 @epoch5/10: 0.19455 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7449072172416118, 'Cardiomegaly': 0.8496497473366724, 'Consolidation': 0.6848223356492102, 'Edema': 0.8762220357606199, 'Effusion': 0.8559275577226952, 'Emphysema': 0.8378764353039582, 'Fibrosis': 0.6913332850296551, 'Hernia': 0.7701439543051214, 'Infiltration': 0.6287855242064966, 'Mass': 0.7327659889947321, 'Nodule': 0.6194318697689544, 'Pleural_Thickening': 0.6683390595249052, 'Pneumonia': 0.638898044076887, 'Pneumothorax': 0.7380196150517182, 'none': 0.7318908708234458}
AVG Loss in validation set: 0.22044486405394223
0.7383659049980884
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch6/10: 0.08849 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch6/10: 0.08777 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch6/10: 0.10037 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch6/10: 0.06566 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch6/10: 0.08982 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch6/10: 0.08472 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch6/10: 0.08355 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch6/10: 0.0823 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch6/10: 0.07811 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch6/10: 0.07893 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch6/10: 0.08631 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch6/10: 0.06938 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch6/10: 0.08314 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch6/10: 0.06536 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch6/10: 0.07774 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch6/10: 0.0641 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch6/10: 0.07875 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch6/10: 0.08548 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch6/10: 0.08131 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch6/10: 0.07215 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch6/10: 0.07444 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch6/10: 0.09218 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch6/10: 0.06352 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch6/10: 0.10273 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch6/10: 0.08463 in 0 mins 0.24 secs
Train Loss for batch 260/541 @epoch6/10: 0.06974 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch6/10: 0.07902 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch6/10: 0.08483 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch6/10: 0.08766 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch6/10: 0.07657 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch6/10: 0.07939 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch6/10: 0.05275 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch6/10: 0.08058 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch6/10: 0.07509 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch6/10: 0.0725 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch6/10: 0.0789 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch6/10: 0.07281 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch6/10: 0.09084 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch6/10: 0.07407 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch6/10: 0.07751 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch6/10: 0.07883 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch6/10: 0.07857 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch6/10: 0.08914 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch6/10: 0.07029 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch6/10: 0.06607 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch6/10: 0.07587 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch6/10: 0.06838 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch6/10: 0.06461 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch6/10: 0.07882 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch6/10: 0.07993 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch6/10: 0.07508 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch6/10: 0.07644 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch6/10: 0.08168 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch6/10: 0.08089 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch6/10: 0.21685 in 0.09 secs
Val Loss for batch 020/136 @epoch6/10: 0.18041 in 0.09 secs
Val Loss for batch 030/136 @epoch6/10: 0.21242 in 0.09 secs
Val Loss for batch 040/136 @epoch6/10: 0.24254 in 0.09 secs
Val Loss for batch 050/136 @epoch6/10: 0.2052 in 0.09 secs
Val Loss for batch 060/136 @epoch6/10: 0.20121 in 0.09 secs
Val Loss for batch 070/136 @epoch6/10: 0.24404 in 0.09 secs
Val Loss for batch 080/136 @epoch6/10: 0.24988 in 0.09 secs
Val Loss for batch 090/136 @epoch6/10: 0.24552 in 0.09 secs
Val Loss for batch 100/136 @epoch6/10: 0.15135 in 0.09 secs
Val Loss for batch 110/136 @epoch6/10: 0.1876 in 0.08 secs
Val Loss for batch 120/136 @epoch6/10: 0.15628 in 0.09 secs
Val Loss for batch 130/136 @epoch6/10: 0.16759 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7345438441567954, 'Cardiomegaly': 0.8386803676249494, 'Consolidation': 0.69072561979747, 'Edema': 0.8649325737629613, 'Effusion': 0.8558610609124785, 'Emphysema': 0.841544810495036, 'Fibrosis': 0.6816934809585751, 'Hernia': 0.8118115858129752, 'Infiltration': 0.6327821253938168, 'Mass': 0.7450173246925071, 'Nodule': 0.643170900523351, 'Pleural_Thickening': 0.6955118912020055, 'Pneumonia': 0.6384035233162954, 'Pneumothorax': 0.768051937993463, 'none': 0.7414410513081751}
AVG Loss in validation set: 0.20992375124233825
0.7459093604744771
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch7/10: 0.06804 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch7/10: 0.08034 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch7/10: 0.07332 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch7/10: 0.07976 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch7/10: 0.06633 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch7/10: 0.06778 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch7/10: 0.0898 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch7/10: 0.08269 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch7/10: 0.07705 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch7/10: 0.0668 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch7/10: 0.06645 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch7/10: 0.06762 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch7/10: 0.06437 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch7/10: 0.06668 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch7/10: 0.08551 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch7/10: 0.06916 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch7/10: 0.06555 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch7/10: 0.06757 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch7/10: 0.06464 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch7/10: 0.06219 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch7/10: 0.07028 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch7/10: 0.0746 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch7/10: 0.05918 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch7/10: 0.07141 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch7/10: 0.07558 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch7/10: 0.08225 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch7/10: 0.07302 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch7/10: 0.07902 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch7/10: 0.06798 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch7/10: 0.06449 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch7/10: 0.06141 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch7/10: 0.08294 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch7/10: 0.06467 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch7/10: 0.07155 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch7/10: 0.0773 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch7/10: 0.06946 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch7/10: 0.06809 in 0 mins 0.24 secs
Train Loss for batch 380/541 @epoch7/10: 0.05669 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch7/10: 0.08009 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch7/10: 0.089 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch7/10: 0.06215 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch7/10: 0.06033 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch7/10: 0.07075 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch7/10: 0.07094 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch7/10: 0.06106 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch7/10: 0.07813 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch7/10: 0.05515 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch7/10: 0.05366 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch7/10: 0.07144 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch7/10: 0.06509 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch7/10: 0.06868 in 0 mins 0.24 secs
Train Loss for batch 520/541 @epoch7/10: 0.06399 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch7/10: 0.06086 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch7/10: 0.06687 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch7/10: 0.21741 in 0.09 secs
Val Loss for batch 020/136 @epoch7/10: 0.17945 in 0.09 secs
Val Loss for batch 030/136 @epoch7/10: 0.22719 in 0.09 secs
Val Loss for batch 040/136 @epoch7/10: 0.24278 in 0.09 secs
Val Loss for batch 050/136 @epoch7/10: 0.20525 in 0.09 secs
Val Loss for batch 060/136 @epoch7/10: 0.2161 in 0.09 secs
Val Loss for batch 070/136 @epoch7/10: 0.25564 in 0.09 secs
Val Loss for batch 080/136 @epoch7/10: 0.24789 in 0.09 secs
Val Loss for batch 090/136 @epoch7/10: 0.248 in 0.09 secs
Val Loss for batch 100/136 @epoch7/10: 0.14842 in 0.09 secs
Val Loss for batch 110/136 @epoch7/10: 0.18689 in 0.08 secs
Val Loss for batch 120/136 @epoch7/10: 0.16858 in 0.09 secs
Val Loss for batch 130/136 @epoch7/10: 0.17842 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7413176211725234, 'Cardiomegaly': 0.8359726288444547, 'Consolidation': 0.7104291267942584, 'Edema': 0.8578275865455225, 'Effusion': 0.8574032746869178, 'Emphysema': 0.8261436135582216, 'Fibrosis': 0.6909408751476425, 'Hernia': 0.8341322218362857, 'Infiltration': 0.628032658487537, 'Mass': 0.7366743636088992, 'Nodule': 0.634129283274223, 'Pleural_Thickening': 0.6844096587321051, 'Pneumonia': 0.6481590947950038, 'Pneumothorax': 0.7671418462651084, 'none': 0.7352778579909229}
AVG Loss in validation set: 0.21519020133640168
0.7466224181249074
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch8/10: 0.05535 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch8/10: 0.07138 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch8/10: 0.06481 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch8/10: 0.06741 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch8/10: 0.055 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch8/10: 0.05884 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch8/10: 0.06052 in 0 mins 0.24 secs
Train Loss for batch 080/541 @epoch8/10: 0.05624 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch8/10: 0.08223 in 0 mins 0.24 secs
Train Loss for batch 100/541 @epoch8/10: 0.04812 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch8/10: 0.07488 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch8/10: 0.06552 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch8/10: 0.07478 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch8/10: 0.05644 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch8/10: 0.05821 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch8/10: 0.04957 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch8/10: 0.06243 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch8/10: 0.06267 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch8/10: 0.07203 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch8/10: 0.06464 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch8/10: 0.07216 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch8/10: 0.07593 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch8/10: 0.06208 in 0 mins 0.24 secs
Train Loss for batch 240/541 @epoch8/10: 0.07452 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch8/10: 0.07199 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch8/10: 0.07438 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch8/10: 0.07261 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch8/10: 0.05452 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch8/10: 0.0568 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch8/10: 0.04682 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch8/10: 0.0814 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch8/10: 0.0648 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch8/10: 0.05404 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch8/10: 0.08433 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch8/10: 0.0559 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch8/10: 0.0658 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch8/10: 0.05572 in 0 mins 0.24 secs
Train Loss for batch 380/541 @epoch8/10: 0.06445 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch8/10: 0.06064 in 0 mins 0.24 secs
Train Loss for batch 400/541 @epoch8/10: 0.06941 in 0 mins 0.24 secs
Train Loss for batch 410/541 @epoch8/10: 0.06382 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch8/10: 0.07079 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch8/10: 0.0517 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch8/10: 0.05696 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch8/10: 0.07308 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch8/10: 0.05307 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch8/10: 0.05873 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch8/10: 0.07305 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch8/10: 0.0609 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch8/10: 0.07246 in 0 mins 0.24 secs
Train Loss for batch 510/541 @epoch8/10: 0.05865 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch8/10: 0.06205 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch8/10: 0.07715 in 0 mins 0.24 secs
Train Loss for batch 540/541 @epoch8/10: 0.06233 in 0 mins 0.24 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch8/10: 0.22704 in 0.09 secs
Val Loss for batch 020/136 @epoch8/10: 0.19155 in 0.08 secs
Val Loss for batch 030/136 @epoch8/10: 0.22038 in 0.08 secs
Val Loss for batch 040/136 @epoch8/10: 0.25223 in 0.09 secs
Val Loss for batch 050/136 @epoch8/10: 0.20036 in 0.09 secs
Val Loss for batch 060/136 @epoch8/10: 0.20934 in 0.09 secs
Val Loss for batch 070/136 @epoch8/10: 0.26407 in 0.09 secs
Val Loss for batch 080/136 @epoch8/10: 0.25375 in 0.08 secs
Val Loss for batch 090/136 @epoch8/10: 0.26193 in 0.09 secs
Val Loss for batch 100/136 @epoch8/10: 0.14067 in 0.09 secs
Val Loss for batch 110/136 @epoch8/10: 0.18581 in 0.09 secs
Val Loss for batch 120/136 @epoch8/10: 0.16729 in 0.09 secs
Val Loss for batch 130/136 @epoch8/10: 0.18506 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7338801298421462, 'Cardiomegaly': 0.8409649501248513, 'Consolidation': 0.723997642475585, 'Edema': 0.8519915808585647, 'Effusion': 0.8520101972830829, 'Emphysema': 0.8317777916437527, 'Fibrosis': 0.6801047499767108, 'Hernia': 0.7668692833159663, 'Infiltration': 0.6301066611352543, 'Mass': 0.7402177963489888, 'Nodule': 0.6371906808181121, 'Pleural_Thickening': 0.6954894138163834, 'Pneumonia': 0.6711567708145856, 'Pneumothorax': 0.7792358669483713, 'none': 0.7345735968831542}
AVG Loss in validation set: 0.21782965932628703
0.7453566796715968
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch9/10: 0.05432 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch9/10: 0.05288 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch9/10: 0.08186 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch9/10: 0.05544 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch9/10: 0.04029 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch9/10: 0.05472 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch9/10: 0.0659 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch9/10: 0.07067 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch9/10: 0.0744 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch9/10: 0.06815 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch9/10: 0.05742 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch9/10: 0.06554 in 0 mins 0.24 secs
Train Loss for batch 130/541 @epoch9/10: 0.07705 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch9/10: 0.06735 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch9/10: 0.05324 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch9/10: 0.05704 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch9/10: 0.06075 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch9/10: 0.06354 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch9/10: 0.06031 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch9/10: 0.06529 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch9/10: 0.05853 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch9/10: 0.06341 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch9/10: 0.04255 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch9/10: 0.06727 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch9/10: 0.06506 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch9/10: 0.06372 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch9/10: 0.06598 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch9/10: 0.04728 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch9/10: 0.06215 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch9/10: 0.05122 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch9/10: 0.06366 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch9/10: 0.05506 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch9/10: 0.05554 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch9/10: 0.07534 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch9/10: 0.06013 in 0 mins 0.24 secs
Train Loss for batch 360/541 @epoch9/10: 0.04842 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch9/10: 0.05743 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch9/10: 0.06006 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch9/10: 0.05306 in 0 mins 0.24 secs
Train Loss for batch 400/541 @epoch9/10: 0.05377 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch9/10: 0.06472 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch9/10: 0.05856 in 0 mins 0.24 secs
Train Loss for batch 430/541 @epoch9/10: 0.0683 in 0 mins 0.24 secs
Train Loss for batch 440/541 @epoch9/10: 0.05447 in 0 mins 0.24 secs
Train Loss for batch 450/541 @epoch9/10: 0.05426 in 0 mins 0.24 secs
Train Loss for batch 460/541 @epoch9/10: 0.05079 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch9/10: 0.06904 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch9/10: 0.07679 in 0 mins 0.24 secs
Train Loss for batch 490/541 @epoch9/10: 0.0456 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch9/10: 0.06314 in 0 mins 0.24 secs
Train Loss for batch 510/541 @epoch9/10: 0.05531 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch9/10: 0.05983 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch9/10: 0.05338 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch9/10: 0.0588 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch9/10: 0.24017 in 0.09 secs
Val Loss for batch 020/136 @epoch9/10: 0.18906 in 0.09 secs
Val Loss for batch 030/136 @epoch9/10: 0.24694 in 0.09 secs
Val Loss for batch 040/136 @epoch9/10: 0.24456 in 0.09 secs
Val Loss for batch 050/136 @epoch9/10: 0.21851 in 0.09 secs
Val Loss for batch 060/136 @epoch9/10: 0.22458 in 0.09 secs
Val Loss for batch 070/136 @epoch9/10: 0.25579 in 0.09 secs
Val Loss for batch 080/136 @epoch9/10: 0.26623 in 0.09 secs
Val Loss for batch 090/136 @epoch9/10: 0.25986 in 0.09 secs
Val Loss for batch 100/136 @epoch9/10: 0.14451 in 0.09 secs
Val Loss for batch 110/136 @epoch9/10: 0.19472 in 0.09 secs
Val Loss for batch 120/136 @epoch9/10: 0.16086 in 0.09 secs
Val Loss for batch 130/136 @epoch9/10: 0.18967 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7402352769970274, 'Cardiomegaly': 0.8227863408767044, 'Consolidation': 0.7298227350560398, 'Edema': 0.8581742378200141, 'Effusion': 0.8498336197849108, 'Emphysema': 0.8318566404432547, 'Fibrosis': 0.6928677318777826, 'Hernia': 0.7422716220910038, 'Infiltration': 0.636421737082503, 'Mass': 0.7367943959470232, 'Nodule': 0.6398473790039331, 'Pleural_Thickening': 0.6919806806205567, 'Pneumonia': 0.6677250751412835, 'Pneumothorax': 0.7753060168348864, 'none': 0.7307504838037808}
AVG Loss in validation set: 0.2217449588090581
0.7439945349697803
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch10/10: 0.05784 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch10/10: 0.0708 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch10/10: 0.05866 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch10/10: 0.07036 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch10/10: 0.04925 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch10/10: 0.04811 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch10/10: 0.05373 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch10/10: 0.07844 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch10/10: 0.05287 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch10/10: 0.05062 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch10/10: 0.05113 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch10/10: 0.06081 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch10/10: 0.04606 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch10/10: 0.0536 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch10/10: 0.06712 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch10/10: 0.04844 in 0 mins 0.24 secs
Train Loss for batch 170/541 @epoch10/10: 0.05613 in 0 mins 0.24 secs
Train Loss for batch 180/541 @epoch10/10: 0.06431 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch10/10: 0.04308 in 0 mins 0.24 secs
Train Loss for batch 200/541 @epoch10/10: 0.05507 in 0 mins 0.24 secs
Train Loss for batch 210/541 @epoch10/10: 0.06492 in 0 mins 0.24 secs
Train Loss for batch 220/541 @epoch10/10: 0.04642 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch10/10: 0.05601 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch10/10: 0.06096 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch10/10: 0.05308 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch10/10: 0.04719 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch10/10: 0.0534 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch10/10: 0.0618 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch10/10: 0.04934 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch10/10: 0.04943 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch10/10: 0.06353 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch10/10: 0.05541 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch10/10: 0.05635 in 0 mins 0.24 secs
Train Loss for batch 340/541 @epoch10/10: 0.08659 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch10/10: 0.07604 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch10/10: 0.0517 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch10/10: 0.06495 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch10/10: 0.05169 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch10/10: 0.05457 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch10/10: 0.0417 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch10/10: 0.04353 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch10/10: 0.04454 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch10/10: 0.07154 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch10/10: 0.04773 in 0 mins 0.24 secs
Train Loss for batch 450/541 @epoch10/10: 0.04588 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch10/10: 0.07072 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch10/10: 0.0554 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch10/10: 0.04776 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch10/10: 0.06299 in 0 mins 0.24 secs
Train Loss for batch 500/541 @epoch10/10: 0.05038 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch10/10: 0.07104 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch10/10: 0.0475 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch10/10: 0.06375 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch10/10: 0.03615 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch10/10: 0.23846 in 0.09 secs
Val Loss for batch 020/136 @epoch10/10: 0.19584 in 0.09 secs
Val Loss for batch 030/136 @epoch10/10: 0.23289 in 0.09 secs
Val Loss for batch 040/136 @epoch10/10: 0.2694 in 0.08 secs
Val Loss for batch 050/136 @epoch10/10: 0.21496 in 0.09 secs
Val Loss for batch 060/136 @epoch10/10: 0.21883 in 0.09 secs
Val Loss for batch 070/136 @epoch10/10: 0.27433 in 0.09 secs
Val Loss for batch 080/136 @epoch10/10: 0.27089 in 0.09 secs
Val Loss for batch 090/136 @epoch10/10: 0.25368 in 0.09 secs
Val Loss for batch 100/136 @epoch10/10: 0.14302 in 0.09 secs
Val Loss for batch 110/136 @epoch10/10: 0.19302 in 0.09 secs
Val Loss for batch 120/136 @epoch10/10: 0.15071 in 0.08 secs
Val Loss for batch 130/136 @epoch10/10: 0.18145 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7308413925903412, 'Cardiomegaly': 0.8396266535009502, 'Consolidation': 0.7079125565314281, 'Edema': 0.8634667527930141, 'Effusion': 0.8445243036720831, 'Emphysema': 0.8378026023313965, 'Fibrosis': 0.6873457013751597, 'Hernia': 0.7684960055574853, 'Infiltration': 0.6417467611901029, 'Mass': 0.7385897357027627, 'Nodule': 0.6450693392434484, 'Pleural_Thickening': 0.6874264164876013, 'Pneumonia': 0.6712656019401749, 'Pneumothorax': 0.7756641994879225, 'none': 0.7389138803505688}
AVG Loss in validation set: 0.2211854153218448
0.7456984301717051
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/2/ft_googlenet_adam_steplr_1/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/5: 0.29039 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch1/5: 0.2692 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch1/5: 0.26496 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch1/5: 0.26132 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch1/5: 0.25394 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch1/5: 0.23525 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch1/5: 0.24386 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch1/5: 0.2387 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch1/5: 0.23476 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch1/5: 0.24888 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch1/5: 0.23468 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch1/5: 0.22621 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch1/5: 0.21746 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch1/5: 0.25218 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch1/5: 0.21644 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch1/5: 0.23022 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch1/5: 0.21191 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch1/5: 0.23354 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch1/5: 0.20833 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch1/5: 0.21628 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch1/5: 0.20814 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch1/5: 0.2269 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch1/5: 0.23165 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch1/5: 0.22858 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch1/5: 0.21731 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch1/5: 0.22742 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch1/5: 0.22812 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch1/5: 0.19988 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch1/5: 0.22903 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch1/5: 0.21752 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch1/5: 0.20816 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch1/5: 0.21219 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch1/5: 0.21651 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch1/5: 0.2173 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch1/5: 0.21409 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch1/5: 0.20862 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch1/5: 0.2115 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch1/5: 0.21221 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch1/5: 0.20068 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch1/5: 0.20452 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch1/5: 0.23171 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch1/5: 0.21038 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch1/5: 0.21033 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch1/5: 0.21043 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch1/5: 0.1981 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch1/5: 0.20543 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch1/5: 0.19449 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch1/5: 0.18705 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch1/5: 0.18707 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch1/5: 0.19668 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch1/5: 0.1971 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch1/5: 0.18575 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch1/5: 0.2031 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch1/5: 0.2061 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/5: 0.23527 in 0.1 secs
Val Loss for batch 020/136 @epoch1/5: 0.20223 in 0.11 secs
Val Loss for batch 030/136 @epoch1/5: 0.23775 in 0.11 secs
Val Loss for batch 040/136 @epoch1/5: 0.23944 in 0.11 secs
Val Loss for batch 050/136 @epoch1/5: 0.21997 in 0.11 secs
Val Loss for batch 060/136 @epoch1/5: 0.22733 in 0.1 secs
Val Loss for batch 070/136 @epoch1/5: 0.2542 in 0.11 secs
Val Loss for batch 080/136 @epoch1/5: 0.24049 in 0.11 secs
Val Loss for batch 090/136 @epoch1/5: 0.24868 in 0.11 secs
Val Loss for batch 100/136 @epoch1/5: 0.18646 in 0.11 secs
Val Loss for batch 110/136 @epoch1/5: 0.21611 in 0.14 secs
Val Loss for batch 120/136 @epoch1/5: 0.19715 in 0.12 secs
Val Loss for batch 130/136 @epoch1/5: 0.19946 in 0.13 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7161883889843081, 'Cardiomegaly': 0.8250763065550965, 'Consolidation': 0.7449249729632299, 'Edema': 0.863604016659338, 'Effusion': 0.862037470372161, 'Emphysema': 0.8476446579537071, 'Fibrosis': 0.6922480646901262, 'Hernia': 0.8093454517386438, 'Infiltration': 0.5325279659236223, 'Mass': 0.703802178293992, 'Nodule': 0.6158570666427075, 'Pleural_Thickening': 0.7013198348430867, 'Pneumonia': 0.5576906203880351, 'Pneumothorax': 0.7734387596680901, 'none': 0.7345233391395971}
AVG Loss in validation set: 0.22763885375089907
0.7318361254054389
Model saved to /scratch/group4/out/2/ft_resnet_34_adam_steplr/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/5: 0.21045 in 0 mins 0.27 secs
Train Loss for batch 020/541 @epoch2/5: 0.19742 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch2/5: 0.2 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch2/5: 0.20867 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch2/5: 0.19145 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch2/5: 0.19284 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch2/5: 0.21674 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch2/5: 0.18722 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch2/5: 0.1932 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch2/5: 0.21627 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch2/5: 0.18565 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch2/5: 0.21707 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch2/5: 0.19941 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch2/5: 0.21269 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch2/5: 0.17644 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch2/5: 0.19738 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch2/5: 0.18074 in 0 mins 0.27 secs
Train Loss for batch 180/541 @epoch2/5: 0.21441 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch2/5: 0.173 in 0 mins 0.39 secs
Train Loss for batch 200/541 @epoch2/5: 0.20995 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch2/5: 0.18654 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch2/5: 0.16903 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch2/5: 0.18043 in 0 mins 0.81 secs
Train Loss for batch 240/541 @epoch2/5: 0.195 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch2/5: 0.19932 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch2/5: 0.20706 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch2/5: 0.19724 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch2/5: 0.18377 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch2/5: 0.17454 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch2/5: 0.19314 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch2/5: 0.19179 in 0 mins 0.47 secs
Train Loss for batch 320/541 @epoch2/5: 0.17995 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch2/5: 0.18379 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch2/5: 0.20468 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch2/5: 0.18658 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch2/5: 0.16723 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch2/5: 0.18356 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch2/5: 0.18577 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch2/5: 0.16092 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch2/5: 0.16873 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch2/5: 0.1737 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch2/5: 0.16318 in 0 mins 0.77 secs
Train Loss for batch 430/541 @epoch2/5: 0.19657 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch2/5: 0.16163 in 0 mins 0.27 secs
Train Loss for batch 450/541 @epoch2/5: 0.16492 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch2/5: 0.14798 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch2/5: 0.17237 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch2/5: 0.17633 in 0 mins 0.35 secs
Train Loss for batch 490/541 @epoch2/5: 0.15731 in 0 mins 0.33 secs
Train Loss for batch 500/541 @epoch2/5: 0.18186 in 0 mins 0.35 secs
Train Loss for batch 510/541 @epoch2/5: 0.15724 in 0 mins 0.29 secs
Train Loss for batch 520/541 @epoch2/5: 0.18794 in 0 mins 0.36 secs
Train Loss for batch 530/541 @epoch2/5: 0.17807 in 0 mins 0.29 secs
Train Loss for batch 540/541 @epoch2/5: 0.17023 in 0 mins 0.31 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/5: 0.24099 in 0.14 secs
Val Loss for batch 020/136 @epoch2/5: 0.23686 in 0.28 secs
Val Loss for batch 030/136 @epoch2/5: 0.25705 in 0.42 secs
Val Loss for batch 040/136 @epoch2/5: 0.26612 in 0.31 secs
Val Loss for batch 050/136 @epoch2/5: 0.25719 in 0.24 secs
Val Loss for batch 060/136 @epoch2/5: 0.23935 in 0.19 secs
Val Loss for batch 070/136 @epoch2/5: 0.2739 in 0.26 secs
Val Loss for batch 080/136 @epoch2/5: 0.26872 in 0.28 secs
Val Loss for batch 090/136 @epoch2/5: 0.25943 in 0.26 secs
Val Loss for batch 100/136 @epoch2/5: 0.2167 in 0.18 secs
Val Loss for batch 110/136 @epoch2/5: 0.22894 in 0.4 secs
Val Loss for batch 120/136 @epoch2/5: 0.23114 in 0.16 secs
Val Loss for batch 130/136 @epoch2/5: 0.23371 in 0.19 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7116631568076766, 'Cardiomegaly': 0.8325454667100395, 'Consolidation': 0.7167449777151471, 'Edema': 0.8776254442253701, 'Effusion': 0.8551753091023795, 'Emphysema': 0.7913868420413774, 'Fibrosis': 0.6717941021208765, 'Hernia': 0.7991200648373278, 'Infiltration': 0.6573634952026142, 'Mass': 0.6948755806226343, 'Nodule': 0.6021145938777135, 'Pleural_Thickening': 0.6445432222835215, 'Pneumonia': 0.6293130309384112, 'Pneumothorax': 0.7252769226668464, 'none': 0.6984355448045894}
AVG Loss in validation set: 0.2514607528197892
0.729253014939424
Model saved to /scratch/group4/out/2/ft_resnet_34_adam_steplr/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/5: 0.15939 in 0 mins 0.25 secs
Train Loss for batch 020/541 @epoch3/5: 0.16044 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch3/5: 0.17089 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch3/5: 0.16719 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch3/5: 0.14946 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch3/5: 0.14693 in 0 mins 0.27 secs
Train Loss for batch 070/541 @epoch3/5: 0.1754 in 0 mins 0.27 secs
Train Loss for batch 080/541 @epoch3/5: 0.14638 in 0 mins 0.3 secs
Train Loss for batch 090/541 @epoch3/5: 0.14248 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch3/5: 0.15866 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch3/5: 0.14083 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch3/5: 0.13296 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch3/5: 0.15457 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch3/5: 0.14722 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch3/5: 0.16758 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch3/5: 0.13313 in 0 mins 0.27 secs
Train Loss for batch 170/541 @epoch3/5: 0.16064 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch3/5: 0.16141 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch3/5: 0.15935 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch3/5: 0.14376 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch3/5: 0.14301 in 0 mins 0.27 secs
Train Loss for batch 220/541 @epoch3/5: 0.15595 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch3/5: 0.12497 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch3/5: 0.16462 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch3/5: 0.15531 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch3/5: 0.16312 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch3/5: 0.13019 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch3/5: 0.13355 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch3/5: 0.13786 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch3/5: 0.15117 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch3/5: 0.14352 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch3/5: 0.13334 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch3/5: 0.13882 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch3/5: 0.13795 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch3/5: 0.13975 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch3/5: 0.14817 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch3/5: 0.1206 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch3/5: 0.14126 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch3/5: 0.15303 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch3/5: 0.13618 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch3/5: 0.13979 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch3/5: 0.14132 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch3/5: 0.15476 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch3/5: 0.12972 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch3/5: 0.12659 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch3/5: 0.12695 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch3/5: 0.16447 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch3/5: 0.13347 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch3/5: 0.14107 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch3/5: 0.14388 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch3/5: 0.11867 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch3/5: 0.13174 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch3/5: 0.13995 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch3/5: 0.12645 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/5: 0.21018 in 0.11 secs
Val Loss for batch 020/136 @epoch3/5: 0.19142 in 0.1 secs
Val Loss for batch 030/136 @epoch3/5: 0.23524 in 0.1 secs
Val Loss for batch 040/136 @epoch3/5: 0.23805 in 0.1 secs
Val Loss for batch 050/136 @epoch3/5: 0.20974 in 0.11 secs
Val Loss for batch 060/136 @epoch3/5: 0.19978 in 0.1 secs
Val Loss for batch 070/136 @epoch3/5: 0.23711 in 0.1 secs
Val Loss for batch 080/136 @epoch3/5: 0.23663 in 0.11 secs
Val Loss for batch 090/136 @epoch3/5: 0.22834 in 0.11 secs
Val Loss for batch 100/136 @epoch3/5: 0.17133 in 0.11 secs
Val Loss for batch 110/136 @epoch3/5: 0.19842 in 0.1 secs
Val Loss for batch 120/136 @epoch3/5: 0.1698 in 0.1 secs
Val Loss for batch 130/136 @epoch3/5: 0.19347 in 0.1 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7354230117294263, 'Cardiomegaly': 0.8581395004564166, 'Consolidation': 0.7285367986825719, 'Edema': 0.869702002110241, 'Effusion': 0.8694052395580293, 'Emphysema': 0.8438813833169181, 'Fibrosis': 0.7139902403568033, 'Hernia': 0.8256358303423257, 'Infiltration': 0.6154510156407236, 'Mass': 0.7538301244963693, 'Nodule': 0.6244735358970344, 'Pleural_Thickening': 0.6795244849220633, 'Pneumonia': 0.6377759867355386, 'Pneumothorax': 0.7774350460754055, 'none': 0.7431438441203352}
AVG Loss in validation set: 0.21347273337141098
0.7523717285942761
Model saved to /scratch/group4/out/2/ft_resnet_34_adam_steplr/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/5: 0.13006 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch4/5: 0.13751 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch4/5: 0.13476 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch4/5: 0.12603 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch4/5: 0.13791 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch4/5: 0.12365 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch4/5: 0.12753 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch4/5: 0.13989 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch4/5: 0.1282 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch4/5: 0.13172 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch4/5: 0.12564 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch4/5: 0.11506 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch4/5: 0.1306 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch4/5: 0.12357 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch4/5: 0.14498 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch4/5: 0.12256 in 0 mins 0.27 secs
Train Loss for batch 170/541 @epoch4/5: 0.1217 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch4/5: 0.12347 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch4/5: 0.11922 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch4/5: 0.13736 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch4/5: 0.10527 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch4/5: 0.14966 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch4/5: 0.10864 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch4/5: 0.1313 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch4/5: 0.13997 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch4/5: 0.09339 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch4/5: 0.11996 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch4/5: 0.1294 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch4/5: 0.13062 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch4/5: 0.1511 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch4/5: 0.11228 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch4/5: 0.12012 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch4/5: 0.11001 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch4/5: 0.10731 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch4/5: 0.12718 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch4/5: 0.13908 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch4/5: 0.12567 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch4/5: 0.1108 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch4/5: 0.12489 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch4/5: 0.11313 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch4/5: 0.1052 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch4/5: 0.11362 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch4/5: 0.11709 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch4/5: 0.1294 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch4/5: 0.12816 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch4/5: 0.11022 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch4/5: 0.12677 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch4/5: 0.12194 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch4/5: 0.10201 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch4/5: 0.12162 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch4/5: 0.09764 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch4/5: 0.10956 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch4/5: 0.1189 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch4/5: 0.10941 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/5: 0.21423 in 0.11 secs
Val Loss for batch 020/136 @epoch4/5: 0.1966 in 0.11 secs
Val Loss for batch 030/136 @epoch4/5: 0.2198 in 0.1 secs
Val Loss for batch 040/136 @epoch4/5: 0.2403 in 0.11 secs
Val Loss for batch 050/136 @epoch4/5: 0.21424 in 0.11 secs
Val Loss for batch 060/136 @epoch4/5: 0.20693 in 0.11 secs
Val Loss for batch 070/136 @epoch4/5: 0.24819 in 0.11 secs
Val Loss for batch 080/136 @epoch4/5: 0.23518 in 0.11 secs
Val Loss for batch 090/136 @epoch4/5: 0.2376 in 0.1 secs
Val Loss for batch 100/136 @epoch4/5: 0.16906 in 0.11 secs
Val Loss for batch 110/136 @epoch4/5: 0.20075 in 0.1 secs
Val Loss for batch 120/136 @epoch4/5: 0.16505 in 0.11 secs
Val Loss for batch 130/136 @epoch4/5: 0.18247 in 0.1 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7403499066953817, 'Cardiomegaly': 0.8480871836517483, 'Consolidation': 0.703759442387101, 'Edema': 0.8661668574321619, 'Effusion': 0.8650678197448173, 'Emphysema': 0.848230707173415, 'Fibrosis': 0.7151350375331083, 'Hernia': 0.8250762224537842, 'Infiltration': 0.6031155188777271, 'Mass': 0.7536464705121932, 'Nodule': 0.628670627415738, 'Pleural_Thickening': 0.698612041388182, 'Pneumonia': 0.6255582164968864, 'Pneumothorax': 0.7833520002051931, 'none': 0.7447639778876921}
AVG Loss in validation set: 0.21419201167821333
0.750344860854817
Model saved to /scratch/group4/out/2/ft_resnet_34_adam_steplr/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/5: 0.09369 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch5/5: 0.13284 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch5/5: 0.11755 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch5/5: 0.10559 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch5/5: 0.10373 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch5/5: 0.13637 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch5/5: 0.1088 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch5/5: 0.10037 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch5/5: 0.12355 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch5/5: 0.10312 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch5/5: 0.14118 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch5/5: 0.11948 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch5/5: 0.09964 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch5/5: 0.11888 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch5/5: 0.12507 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch5/5: 0.11319 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch5/5: 0.10067 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch5/5: 0.10041 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch5/5: 0.09715 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch5/5: 0.10286 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch5/5: 0.11936 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch5/5: 0.10187 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch5/5: 0.13846 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch5/5: 0.10454 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch5/5: 0.11986 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch5/5: 0.11193 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch5/5: 0.12862 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch5/5: 0.14455 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch5/5: 0.10642 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch5/5: 0.116 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch5/5: 0.10322 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch5/5: 0.13381 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch5/5: 0.10618 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch5/5: 0.10752 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch5/5: 0.10734 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch5/5: 0.10826 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch5/5: 0.10354 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch5/5: 0.11443 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch5/5: 0.13304 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch5/5: 0.10208 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch5/5: 0.12427 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch5/5: 0.12299 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch5/5: 0.09508 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch5/5: 0.10591 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch5/5: 0.09661 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch5/5: 0.11912 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch5/5: 0.10566 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch5/5: 0.10829 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch5/5: 0.09997 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch5/5: 0.08854 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch5/5: 0.09927 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch5/5: 0.11315 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch5/5: 0.08808 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch5/5: 0.1145 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/5: 0.21929 in 0.11 secs
Val Loss for batch 020/136 @epoch5/5: 0.19003 in 0.11 secs
Val Loss for batch 030/136 @epoch5/5: 0.22921 in 0.11 secs
Val Loss for batch 040/136 @epoch5/5: 0.23242 in 0.1 secs
Val Loss for batch 050/136 @epoch5/5: 0.20301 in 0.1 secs
Val Loss for batch 060/136 @epoch5/5: 0.20718 in 0.1 secs
Val Loss for batch 070/136 @epoch5/5: 0.24639 in 0.1 secs
Val Loss for batch 080/136 @epoch5/5: 0.2335 in 0.1 secs
Val Loss for batch 090/136 @epoch5/5: 0.23996 in 0.1 secs
Val Loss for batch 100/136 @epoch5/5: 0.16623 in 0.1 secs
Val Loss for batch 110/136 @epoch5/5: 0.19511 in 0.11 secs
Val Loss for batch 120/136 @epoch5/5: 0.15734 in 0.11 secs
Val Loss for batch 130/136 @epoch5/5: 0.19005 in 0.1 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7399211414564739, 'Cardiomegaly': 0.8487071143317899, 'Consolidation': 0.711587713836272, 'Edema': 0.8639457578591202, 'Effusion': 0.8635432021060825, 'Emphysema': 0.835370227214954, 'Fibrosis': 0.702344913565168, 'Hernia': 0.827167998147505, 'Infiltration': 0.6150492744982975, 'Mass': 0.7468627655555863, 'Nodule': 0.6242397362853395, 'Pleural_Thickening': 0.6836875893442829, 'Pneumonia': 0.6190664539163457, 'Pneumothorax': 0.7774598402410817, 'none': 0.7444277972110009}
AVG Loss in validation set: 0.21308905502132833
0.7470681234541642
Model saved to /scratch/group4/out/2/ft_resnet_34_adam_steplr/models/model_weights_epoch_5.pth
Model saved to /scratch/group4/out/2/ft_resnet_34_adam_steplr/models/model_weights_final_0.pth
