-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch1/10: 0.28429 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch1/10: 0.25652 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch1/10: 0.22277 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch1/10: 0.23722 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch1/10: 0.21751 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch1/10: 0.21176 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch1/10: 0.20406 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch1/10: 0.20643 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch1/10: 0.19585 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch1/10: 0.20481 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch1/10: 0.20681 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch1/10: 0.18846 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch1/10: 0.23156 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch1/10: 0.19406 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch1/10: 0.24699 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch1/10: 0.20694 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch1/10: 0.22107 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch1/10: 0.18849 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch1/10: 0.19759 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch1/10: 0.19644 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch1/10: 0.17163 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch1/10: 0.20505 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch1/10: 0.18361 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch1/10: 0.20719 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch1/10: 0.18432 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch1/10: 0.16122 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch1/10: 0.1946 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch1/10: 0.18462 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch1/10: 0.18378 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch1/10: 0.15905 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch1/10: 0.17291 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch1/10: 0.19244 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch1/10: 0.17155 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch1/10: 0.17445 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch1/10: 0.1688 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch1/10: 0.15497 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch1/10: 0.14033 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch1/10: 0.1801 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch1/10: 0.16418 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch1/10: 0.1754 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch1/10: 0.17847 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch1/10: 0.1539 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch1/10: 0.1413 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch1/10: 0.14227 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch1/10: 0.17179 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch1/10: 0.16735 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch1/10: 0.143 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch1/10: 0.15316 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch1/10: 0.15743 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch1/10: 0.1568 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch1/10: 0.12242 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch1/10: 0.16596 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch1/10: 0.15352 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch1/10: 0.1776 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch1/10: 0.20274 in 0.09 secs
Val Loss for batch 040/271 @epoch1/10: 0.27886 in 0.09 secs
Val Loss for batch 060/271 @epoch1/10: 0.21879 in 0.09 secs
Val Loss for batch 080/271 @epoch1/10: 0.20759 in 0.09 secs
Val Loss for batch 100/271 @epoch1/10: 0.18643 in 0.09 secs
Val Loss for batch 120/271 @epoch1/10: 0.20012 in 0.09 secs
Val Loss for batch 140/271 @epoch1/10: 0.22964 in 0.09 secs
Val Loss for batch 160/271 @epoch1/10: 0.23317 in 0.09 secs
Val Loss for batch 180/271 @epoch1/10: 0.19283 in 0.09 secs
Val Loss for batch 200/271 @epoch1/10: 0.22128 in 0.09 secs
Val Loss for batch 220/271 @epoch1/10: 0.26588 in 0.09 secs
Val Loss for batch 240/271 @epoch1/10: 0.2534 in 0.09 secs
Val Loss for batch 260/271 @epoch1/10: 0.23403 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7381935222136634, 'Cardiomegaly': 0.8562578160470589, 'Consolidation': 0.6469548356641663, 'Edema': 0.8683714028804078, 'Effusion': 0.8569023523887367, 'Emphysema': 0.8299619819649984, 'Fibrosis': 0.7005306889611057, 'Hernia': 0.6650122558348431, 'Infiltration': 0.5782991179096377, 'Mass': 0.7227748691099477, 'Nodule': 0.6661943351827032, 'Pleural_Thickening': 0.675522585870972, 'Pneumonia': 0.6130970643182365, 'Pneumothorax': 0.7934523584184688, 'none': 0.7081042888519096}
AVG Loss in validation set: 0.22811074797417133
0.7293946561974962
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch2/10: 0.19198 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch2/10: 0.14437 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch2/10: 0.17058 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch2/10: 0.13653 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch2/10: 0.1469 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch2/10: 0.13577 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch2/10: 0.14593 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch2/10: 0.13759 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch2/10: 0.14713 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch2/10: 0.14817 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch2/10: 0.14925 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch2/10: 0.15837 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch2/10: 0.12154 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch2/10: 0.1558 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch2/10: 0.1734 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch2/10: 0.1664 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch2/10: 0.14389 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch2/10: 0.18903 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch2/10: 0.12857 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch2/10: 0.16186 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch2/10: 0.12979 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch2/10: 0.14144 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch2/10: 0.11804 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch2/10: 0.12285 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch2/10: 0.15674 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch2/10: 0.12085 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch2/10: 0.14675 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch2/10: 0.11069 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch2/10: 0.13415 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch2/10: 0.1224 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch2/10: 0.12657 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch2/10: 0.10817 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch2/10: 0.13404 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch2/10: 0.1446 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch2/10: 0.11379 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch2/10: 0.10709 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch2/10: 0.10359 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch2/10: 0.12548 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch2/10: 0.09561 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch2/10: 0.12095 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch2/10: 0.15562 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch2/10: 0.13112 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch2/10: 0.08973 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch2/10: 0.13212 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch2/10: 0.10641 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch2/10: 0.13788 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch2/10: 0.13829 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch2/10: 0.11409 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch2/10: 0.11674 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch2/10: 0.12855 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch2/10: 0.09804 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch2/10: 0.1144 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch2/10: 0.14414 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch2/10: 0.12549 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch2/10: 0.19388 in 0.09 secs
Val Loss for batch 040/271 @epoch2/10: 0.27343 in 0.09 secs
Val Loss for batch 060/271 @epoch2/10: 0.214 in 0.09 secs
Val Loss for batch 080/271 @epoch2/10: 0.19625 in 0.09 secs
Val Loss for batch 100/271 @epoch2/10: 0.1714 in 0.09 secs
Val Loss for batch 120/271 @epoch2/10: 0.19872 in 0.09 secs
Val Loss for batch 140/271 @epoch2/10: 0.23677 in 0.09 secs
Val Loss for batch 160/271 @epoch2/10: 0.22246 in 0.09 secs
Val Loss for batch 180/271 @epoch2/10: 0.19962 in 0.09 secs
Val Loss for batch 200/271 @epoch2/10: 0.22982 in 0.09 secs
Val Loss for batch 220/271 @epoch2/10: 0.26206 in 0.09 secs
Val Loss for batch 240/271 @epoch2/10: 0.22786 in 0.09 secs
Val Loss for batch 260/271 @epoch2/10: 0.23148 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7674500720205396, 'Cardiomegaly': 0.8667234100715402, 'Consolidation': 0.7087193523398287, 'Edema': 0.8573129715712198, 'Effusion': 0.8705031027876446, 'Emphysema': 0.8510711793207788, 'Fibrosis': 0.6836978736060292, 'Hernia': 0.8408994717050075, 'Infiltration': 0.6274564675119063, 'Mass': 0.7380828326696506, 'Nodule': 0.6415708406650332, 'Pleural_Thickening': 0.7190165825503657, 'Pneumonia': 0.6174045842209805, 'Pneumothorax': 0.7421274680264048, 'none': 0.6935750440631513}
AVG Loss in validation set: 0.23019117685280296
0.7522883006476379
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch3/10: 0.11614 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch3/10: 0.12364 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch3/10: 0.13659 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch3/10: 0.08926 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch3/10: 0.08228 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch3/10: 0.10638 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch3/10: 0.08766 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch3/10: 0.11661 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch3/10: 0.10754 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch3/10: 0.10774 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch3/10: 0.08187 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch3/10: 0.10434 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch3/10: 0.10559 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch3/10: 0.12459 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch3/10: 0.08786 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch3/10: 0.09009 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch3/10: 0.10903 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch3/10: 0.08288 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch3/10: 0.06555 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch3/10: 0.08763 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch3/10: 0.07803 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch3/10: 0.10331 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch3/10: 0.0869 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch3/10: 0.09456 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch3/10: 0.09761 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch3/10: 0.09604 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch3/10: 0.10156 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch3/10: 0.0985 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch3/10: 0.08429 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch3/10: 0.07802 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch3/10: 0.07853 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch3/10: 0.12555 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch3/10: 0.11021 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch3/10: 0.09428 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch3/10: 0.12554 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch3/10: 0.08914 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch3/10: 0.08788 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch3/10: 0.0965 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch3/10: 0.08534 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch3/10: 0.08704 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch3/10: 0.0812 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch3/10: 0.09575 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch3/10: 0.09072 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch3/10: 0.07783 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch3/10: 0.08356 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch3/10: 0.0691 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch3/10: 0.13432 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch3/10: 0.08932 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch3/10: 0.05177 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch3/10: 0.0823 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch3/10: 0.07803 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch3/10: 0.07547 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch3/10: 0.11254 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch3/10: 0.06974 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch3/10: 0.13425 in 0.09 secs
Val Loss for batch 040/271 @epoch3/10: 0.24912 in 0.09 secs
Val Loss for batch 060/271 @epoch3/10: 0.17437 in 0.09 secs
Val Loss for batch 080/271 @epoch3/10: 0.17864 in 0.09 secs
Val Loss for batch 100/271 @epoch3/10: 0.12496 in 0.09 secs
Val Loss for batch 120/271 @epoch3/10: 0.17434 in 0.09 secs
Val Loss for batch 140/271 @epoch3/10: 0.25127 in 0.09 secs
Val Loss for batch 160/271 @epoch3/10: 0.2078 in 0.09 secs
Val Loss for batch 180/271 @epoch3/10: 0.15092 in 0.09 secs
Val Loss for batch 200/271 @epoch3/10: 0.2077 in 0.09 secs
Val Loss for batch 220/271 @epoch3/10: 0.26144 in 0.09 secs
Val Loss for batch 240/271 @epoch3/10: 0.21099 in 0.09 secs
Val Loss for batch 260/271 @epoch3/10: 0.20914 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7302927193587422, 'Cardiomegaly': 0.851189330757536, 'Consolidation': 0.7190080495777962, 'Edema': 0.859076803534989, 'Effusion': 0.8448409500558816, 'Emphysema': 0.8446542910488617, 'Fibrosis': 0.7150000864055037, 'Hernia': 0.8511304294870818, 'Infiltration': 0.6420635175109429, 'Mass': 0.7889238447805416, 'Nodule': 0.6832701509542173, 'Pleural_Thickening': 0.7218157757209899, 'Pneumonia': 0.6627214076753221, 'Pneumothorax': 0.7859708060556756, 'none': 0.7343909168386626}
AVG Loss in validation set: 0.19913697785599277
0.7642827259231487
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch4/10: 0.0833 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch4/10: 0.07695 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch4/10: 0.05803 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch4/10: 0.05438 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch4/10: 0.08291 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch4/10: 0.09971 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch4/10: 0.11153 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch4/10: 0.07453 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch4/10: 0.08847 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch4/10: 0.08142 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch4/10: 0.12028 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch4/10: 0.08259 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch4/10: 0.06631 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch4/10: 0.0614 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch4/10: 0.1066 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch4/10: 0.07856 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch4/10: 0.0722 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch4/10: 0.07666 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch4/10: 0.08401 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch4/10: 0.06591 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch4/10: 0.09673 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch4/10: 0.0573 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch4/10: 0.08217 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch4/10: 0.10062 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch4/10: 0.08168 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch4/10: 0.09928 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch4/10: 0.06365 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch4/10: 0.04963 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch4/10: 0.07477 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch4/10: 0.08656 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch4/10: 0.05806 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch4/10: 0.07161 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch4/10: 0.06093 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch4/10: 0.09763 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch4/10: 0.05133 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch4/10: 0.06622 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch4/10: 0.07179 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch4/10: 0.08291 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch4/10: 0.0616 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch4/10: 0.06979 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch4/10: 0.06629 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch4/10: 0.06409 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch4/10: 0.07894 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch4/10: 0.06454 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch4/10: 0.10134 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch4/10: 0.07341 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch4/10: 0.04522 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch4/10: 0.09274 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch4/10: 0.05915 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch4/10: 0.04934 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch4/10: 0.07171 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch4/10: 0.04547 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch4/10: 0.05443 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch4/10: 0.04028 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch4/10: 0.1277 in 0.09 secs
Val Loss for batch 040/271 @epoch4/10: 0.27734 in 0.09 secs
Val Loss for batch 060/271 @epoch4/10: 0.19661 in 0.09 secs
Val Loss for batch 080/271 @epoch4/10: 0.15622 in 0.09 secs
Val Loss for batch 100/271 @epoch4/10: 0.1381 in 0.09 secs
Val Loss for batch 120/271 @epoch4/10: 0.18163 in 0.09 secs
Val Loss for batch 140/271 @epoch4/10: 0.25556 in 0.09 secs
Val Loss for batch 160/271 @epoch4/10: 0.20802 in 0.09 secs
Val Loss for batch 180/271 @epoch4/10: 0.15985 in 0.09 secs
Val Loss for batch 200/271 @epoch4/10: 0.20586 in 0.09 secs
Val Loss for batch 220/271 @epoch4/10: 0.25575 in 0.09 secs
Val Loss for batch 240/271 @epoch4/10: 0.2196 in 0.09 secs
Val Loss for batch 260/271 @epoch4/10: 0.20466 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7482277388421614, 'Cardiomegaly': 0.8752339398370583, 'Consolidation': 0.7437768864684966, 'Edema': 0.8527293033709844, 'Effusion': 0.853015230891677, 'Emphysema': 0.8459814470465805, 'Fibrosis': 0.7223850283819342, 'Hernia': 0.8568457591766515, 'Infiltration': 0.6331510639959087, 'Mass': 0.7740861436973353, 'Nodule': 0.674863031685277, 'Pleural_Thickening': 0.7378448036078725, 'Pneumonia': 0.6397365650175513, 'Pneumothorax': 0.7931840866743566, 'none': 0.73235532259876}
AVG Loss in validation set: 0.20766801803518764
0.767932930620989
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch5/10: 0.04437 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch5/10: 0.05025 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch5/10: 0.06333 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch5/10: 0.06588 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch5/10: 0.04586 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch5/10: 0.08126 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch5/10: 0.05007 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch5/10: 0.05796 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch5/10: 0.04453 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch5/10: 0.04693 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch5/10: 0.05341 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch5/10: 0.04689 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch5/10: 0.04719 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch5/10: 0.0465 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch5/10: 0.04401 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch5/10: 0.07933 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch5/10: 0.06912 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch5/10: 0.09233 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch5/10: 0.06208 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch5/10: 0.08047 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch5/10: 0.0641 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch5/10: 0.05307 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch5/10: 0.03893 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch5/10: 0.05612 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch5/10: 0.0402 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch5/10: 0.06065 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch5/10: 0.04799 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch5/10: 0.05331 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch5/10: 0.07109 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch5/10: 0.05128 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch5/10: 0.05622 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch5/10: 0.05248 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch5/10: 0.05416 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch5/10: 0.03878 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch5/10: 0.09875 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch5/10: 0.03303 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch5/10: 0.05432 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch5/10: 0.05334 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch5/10: 0.05394 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch5/10: 0.03247 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch5/10: 0.05302 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch5/10: 0.04814 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch5/10: 0.03637 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch5/10: 0.07154 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch5/10: 0.04729 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch5/10: 0.06368 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch5/10: 0.06012 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch5/10: 0.0356 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch5/10: 0.04199 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch5/10: 0.05236 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch5/10: 0.05291 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch5/10: 0.05516 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch5/10: 0.04512 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch5/10: 0.06279 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch5/10: 0.12915 in 0.09 secs
Val Loss for batch 040/271 @epoch5/10: 0.26666 in 0.09 secs
Val Loss for batch 060/271 @epoch5/10: 0.17249 in 0.09 secs
Val Loss for batch 080/271 @epoch5/10: 0.18606 in 0.09 secs
Val Loss for batch 100/271 @epoch5/10: 0.12185 in 0.09 secs
Val Loss for batch 120/271 @epoch5/10: 0.16848 in 0.09 secs
Val Loss for batch 140/271 @epoch5/10: 0.25803 in 0.09 secs
Val Loss for batch 160/271 @epoch5/10: 0.19904 in 0.09 secs
Val Loss for batch 180/271 @epoch5/10: 0.15948 in 0.09 secs
Val Loss for batch 200/271 @epoch5/10: 0.19916 in 0.09 secs
Val Loss for batch 220/271 @epoch5/10: 0.25191 in 0.09 secs
Val Loss for batch 240/271 @epoch5/10: 0.2222 in 0.09 secs
Val Loss for batch 260/271 @epoch5/10: 0.21334 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7605679948113446, 'Cardiomegaly': 0.8542331032369737, 'Consolidation': 0.7420702849719097, 'Edema': 0.8498443289058656, 'Effusion': 0.8492755885184984, 'Emphysema': 0.8647239669767712, 'Fibrosis': 0.7038356994798389, 'Hernia': 0.8645281122969415, 'Infiltration': 0.6471773404457739, 'Mass': 0.7848444513380224, 'Nodule': 0.6956854017291848, 'Pleural_Thickening': 0.7503062608558919, 'Pneumonia': 0.6386737289539375, 'Pneumothorax': 0.7837120976155671, 'none': 0.721831603069057}
AVG Loss in validation set: 0.20534763959508995
0.7706770257240372
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch6/10: 0.07991 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch6/10: 0.05274 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch6/10: 0.04446 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch6/10: 0.04786 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch6/10: 0.04885 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch6/10: 0.04205 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch6/10: 0.05197 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch6/10: 0.03395 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch6/10: 0.05188 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch6/10: 0.03868 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch6/10: 0.04808 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch6/10: 0.04977 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch6/10: 0.07561 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch6/10: 0.04643 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch6/10: 0.06058 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch6/10: 0.0496 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch6/10: 0.08637 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch6/10: 0.04002 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch6/10: 0.04855 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch6/10: 0.05892 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch6/10: 0.04136 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch6/10: 0.02597 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch6/10: 0.03252 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch6/10: 0.04741 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch6/10: 0.04058 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch6/10: 0.06154 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch6/10: 0.0491 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch6/10: 0.04834 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch6/10: 0.0845 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch6/10: 0.03013 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch6/10: 0.02989 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch6/10: 0.05128 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch6/10: 0.05321 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch6/10: 0.04457 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch6/10: 0.04422 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch6/10: 0.03706 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch6/10: 0.04365 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch6/10: 0.05826 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch6/10: 0.04873 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch6/10: 0.05629 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch6/10: 0.03023 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch6/10: 0.03028 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch6/10: 0.04746 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch6/10: 0.05948 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch6/10: 0.05724 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch6/10: 0.05573 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch6/10: 0.03206 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch6/10: 0.03263 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch6/10: 0.02741 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch6/10: 0.0641 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch6/10: 0.02646 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch6/10: 0.03452 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch6/10: 0.04474 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch6/10: 0.03668 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch6/10: 0.12943 in 0.09 secs
Val Loss for batch 040/271 @epoch6/10: 0.28476 in 0.09 secs
Val Loss for batch 060/271 @epoch6/10: 0.18471 in 0.09 secs
Val Loss for batch 080/271 @epoch6/10: 0.16311 in 0.09 secs
Val Loss for batch 100/271 @epoch6/10: 0.1121 in 0.09 secs
Val Loss for batch 120/271 @epoch6/10: 0.18362 in 0.09 secs
Val Loss for batch 140/271 @epoch6/10: 0.27289 in 0.09 secs
Val Loss for batch 160/271 @epoch6/10: 0.19527 in 0.09 secs
Val Loss for batch 180/271 @epoch6/10: 0.17733 in 0.09 secs
Val Loss for batch 200/271 @epoch6/10: 0.20286 in 0.09 secs
Val Loss for batch 220/271 @epoch6/10: 0.25448 in 0.08 secs
Val Loss for batch 240/271 @epoch6/10: 0.23609 in 0.09 secs
Val Loss for batch 260/271 @epoch6/10: 0.2246 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7416973268101497, 'Cardiomegaly': 0.8301435332382996, 'Consolidation': 0.7285083086920736, 'Edema': 0.8425318093614994, 'Effusion': 0.8506516773284696, 'Emphysema': 0.8600170809804141, 'Fibrosis': 0.6971521200727261, 'Hernia': 0.877459921136367, 'Infiltration': 0.649082263135415, 'Mass': 0.7835535145640902, 'Nodule': 0.6878991108429673, 'Pleural_Thickening': 0.7452922510156391, 'Pneumonia': 0.6578885014209559, 'Pneumothorax': 0.7820507547447497, 'none': 0.7085879540233351}
AVG Loss in validation set: 0.21025406302978086
0.766709155238844
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch7/10: 0.04655 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch7/10: 0.05093 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch7/10: 0.03431 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch7/10: 0.04472 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch7/10: 0.03966 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch7/10: 0.02243 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch7/10: 0.04772 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch7/10: 0.03741 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch7/10: 0.04533 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch7/10: 0.0485 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch7/10: 0.05272 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch7/10: 0.04027 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch7/10: 0.04589 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch7/10: 0.05651 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch7/10: 0.04243 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch7/10: 0.0479 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch7/10: 0.04832 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch7/10: 0.04447 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch7/10: 0.07116 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch7/10: 0.03661 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch7/10: 0.02426 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch7/10: 0.04625 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch7/10: 0.04749 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch7/10: 0.0617 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch7/10: 0.08009 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch7/10: 0.04164 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch7/10: 0.03349 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch7/10: 0.03941 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch7/10: 0.047 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch7/10: 0.05152 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch7/10: 0.04944 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch7/10: 0.04672 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch7/10: 0.05556 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch7/10: 0.02744 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch7/10: 0.02465 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch7/10: 0.03427 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch7/10: 0.02956 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch7/10: 0.04123 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch7/10: 0.06222 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch7/10: 0.03757 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch7/10: 0.05251 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch7/10: 0.04409 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch7/10: 0.02788 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch7/10: 0.05106 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch7/10: 0.02063 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch7/10: 0.05282 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch7/10: 0.02917 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch7/10: 0.02126 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch7/10: 0.05069 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch7/10: 0.0639 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch7/10: 0.03925 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch7/10: 0.03 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch7/10: 0.0342 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch7/10: 0.05143 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch7/10: 0.13584 in 0.09 secs
Val Loss for batch 040/271 @epoch7/10: 0.30108 in 0.09 secs
Val Loss for batch 060/271 @epoch7/10: 0.18842 in 0.09 secs
Val Loss for batch 080/271 @epoch7/10: 0.16831 in 0.09 secs
Val Loss for batch 100/271 @epoch7/10: 0.12083 in 0.09 secs
Val Loss for batch 120/271 @epoch7/10: 0.18509 in 0.09 secs
Val Loss for batch 140/271 @epoch7/10: 0.28434 in 0.09 secs
Val Loss for batch 160/271 @epoch7/10: 0.20209 in 0.09 secs
Val Loss for batch 180/271 @epoch7/10: 0.18209 in 0.09 secs
Val Loss for batch 200/271 @epoch7/10: 0.19859 in 0.09 secs
Val Loss for batch 220/271 @epoch7/10: 0.27202 in 0.09 secs
Val Loss for batch 240/271 @epoch7/10: 0.22862 in 0.09 secs
Val Loss for batch 260/271 @epoch7/10: 0.21604 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7442048549112938, 'Cardiomegaly': 0.8484232532642036, 'Consolidation': 0.7287349776480313, 'Edema': 0.8464749902814226, 'Effusion': 0.8558830784127024, 'Emphysema': 0.8596642263905908, 'Fibrosis': 0.6855762837811413, 'Hernia': 0.8436018452263143, 'Infiltration': 0.6518606480678633, 'Mass': 0.7938749944605177, 'Nodule': 0.691174639804552, 'Pleural_Thickening': 0.7330073289864619, 'Pneumonia': 0.6511486839774088, 'Pneumothorax': 0.7843297008459124, 'none': 0.7234510802951601}
AVG Loss in validation set: 0.21209892555485707
0.7655685361470297
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch8/10: 0.03223 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch8/10: 0.02972 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch8/10: 0.03849 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch8/10: 0.0581 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch8/10: 0.03132 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch8/10: 0.05833 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch8/10: 0.05277 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch8/10: 0.04 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch8/10: 0.0467 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch8/10: 0.03781 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch8/10: 0.01825 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch8/10: 0.04332 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch8/10: 0.02498 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch8/10: 0.06834 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch8/10: 0.0406 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch8/10: 0.0394 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch8/10: 0.0481 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch8/10: 0.04118 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch8/10: 0.02428 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch8/10: 0.02467 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch8/10: 0.05755 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch8/10: 0.01876 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch8/10: 0.03979 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch8/10: 0.02089 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch8/10: 0.03696 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch8/10: 0.03582 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch8/10: 0.03056 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch8/10: 0.04825 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch8/10: 0.03214 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch8/10: 0.03741 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch8/10: 0.06276 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch8/10: 0.03262 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch8/10: 0.0247 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch8/10: 0.0203 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch8/10: 0.01898 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch8/10: 0.02507 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch8/10: 0.01622 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch8/10: 0.04502 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch8/10: 0.02147 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch8/10: 0.01718 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch8/10: 0.03541 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch8/10: 0.02293 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch8/10: 0.03256 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch8/10: 0.03933 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch8/10: 0.01393 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch8/10: 0.03391 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch8/10: 0.02171 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch8/10: 0.03578 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch8/10: 0.04335 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch8/10: 0.03559 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch8/10: 0.02678 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch8/10: 0.02598 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch8/10: 0.03304 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch8/10: 0.03922 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch8/10: 0.14209 in 0.09 secs
Val Loss for batch 040/271 @epoch8/10: 0.30152 in 0.08 secs
Val Loss for batch 060/271 @epoch8/10: 0.18799 in 0.09 secs
Val Loss for batch 080/271 @epoch8/10: 0.18331 in 0.09 secs
Val Loss for batch 100/271 @epoch8/10: 0.1232 in 0.09 secs
Val Loss for batch 120/271 @epoch8/10: 0.18603 in 0.09 secs
Val Loss for batch 140/271 @epoch8/10: 0.26942 in 0.09 secs
Val Loss for batch 160/271 @epoch8/10: 0.2272 in 0.09 secs
Val Loss for batch 180/271 @epoch8/10: 0.16567 in 0.09 secs
Val Loss for batch 200/271 @epoch8/10: 0.21696 in 0.09 secs
Val Loss for batch 220/271 @epoch8/10: 0.27565 in 0.09 secs
Val Loss for batch 240/271 @epoch8/10: 0.24711 in 0.09 secs
Val Loss for batch 260/271 @epoch8/10: 0.23064 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7428244230568352, 'Cardiomegaly': 0.8378390441602879, 'Consolidation': 0.7417533967281668, 'Edema': 0.833977259108515, 'Effusion': 0.8573059714011915, 'Emphysema': 0.8625201967835581, 'Fibrosis': 0.7068388591926815, 'Hernia': 0.8980101396099447, 'Infiltration': 0.6329923005762852, 'Mass': 0.7865690504377774, 'Nodule': 0.6905093908282491, 'Pleural_Thickening': 0.7396810473718254, 'Pneumonia': 0.6269630868374695, 'Pneumothorax': 0.7710887610722098, 'none': 0.714981474166204}
AVG Loss in validation set: 0.22131427458409517
0.7663480662260712
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch9/10: 0.02946 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch9/10: 0.03015 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch9/10: 0.04616 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch9/10: 0.0425 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch9/10: 0.04336 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch9/10: 0.01535 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch9/10: 0.01872 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch9/10: 0.03015 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch9/10: 0.02824 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch9/10: 0.03548 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch9/10: 0.0222 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch9/10: 0.03073 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch9/10: 0.03546 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch9/10: 0.03443 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch9/10: 0.03413 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch9/10: 0.03131 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch9/10: 0.02463 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch9/10: 0.02761 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch9/10: 0.02349 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch9/10: 0.02302 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch9/10: 0.03916 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch9/10: 0.01969 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch9/10: 0.04215 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch9/10: 0.01699 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch9/10: 0.02267 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch9/10: 0.02285 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch9/10: 0.01762 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch9/10: 0.0469 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch9/10: 0.0172 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch9/10: 0.0301 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch9/10: 0.02009 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch9/10: 0.0176 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch9/10: 0.02985 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch9/10: 0.03563 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch9/10: 0.01805 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch9/10: 0.00941 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch9/10: 0.03844 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch9/10: 0.03523 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch9/10: 0.02737 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch9/10: 0.03052 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch9/10: 0.03113 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch9/10: 0.02224 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch9/10: 0.02571 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch9/10: 0.02513 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch9/10: 0.0187 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch9/10: 0.01805 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch9/10: 0.01943 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch9/10: 0.04427 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch9/10: 0.02429 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch9/10: 0.01349 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch9/10: 0.03057 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch9/10: 0.01449 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch9/10: 0.04677 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch9/10: 0.01832 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch9/10: 0.15456 in 0.09 secs
Val Loss for batch 040/271 @epoch9/10: 0.29491 in 0.09 secs
Val Loss for batch 060/271 @epoch9/10: 0.2058 in 0.09 secs
Val Loss for batch 080/271 @epoch9/10: 0.1798 in 0.09 secs
Val Loss for batch 100/271 @epoch9/10: 0.11782 in 0.09 secs
Val Loss for batch 120/271 @epoch9/10: 0.19365 in 0.09 secs
Val Loss for batch 140/271 @epoch9/10: 0.28233 in 0.09 secs
Val Loss for batch 160/271 @epoch9/10: 0.20505 in 0.09 secs
Val Loss for batch 180/271 @epoch9/10: 0.16333 in 0.09 secs
Val Loss for batch 200/271 @epoch9/10: 0.21656 in 0.09 secs
Val Loss for batch 220/271 @epoch9/10: 0.28187 in 0.09 secs
Val Loss for batch 240/271 @epoch9/10: 0.24773 in 0.09 secs
Val Loss for batch 260/271 @epoch9/10: 0.24402 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7461510206269513, 'Cardiomegaly': 0.8387027025436273, 'Consolidation': 0.7272406436434516, 'Edema': 0.8221351986820289, 'Effusion': 0.8539161538762057, 'Emphysema': 0.8503032016841047, 'Fibrosis': 0.6863780359028511, 'Hernia': 0.8676430735502337, 'Infiltration': 0.6514917388829478, 'Mass': 0.7982711671530861, 'Nodule': 0.6899457664058775, 'Pleural_Thickening': 0.7340954122645729, 'Pneumonia': 0.6369313836062174, 'Pneumothorax': 0.7713789069459253, 'none': 0.7216012280102335}
AVG Loss in validation set: 0.22419862525638362
0.7624703146977201
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch10/10: 0.01372 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch10/10: 0.02434 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch10/10: 0.01903 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch10/10: 0.03744 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch10/10: 0.0205 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch10/10: 0.03852 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch10/10: 0.02505 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch10/10: 0.01483 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch10/10: 0.01942 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch10/10: 0.01389 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch10/10: 0.015 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch10/10: 0.03052 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch10/10: 0.0199 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch10/10: 0.0341 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch10/10: 0.0225 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch10/10: 0.03901 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch10/10: 0.02491 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch10/10: 0.02322 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch10/10: 0.03049 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch10/10: 0.01784 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch10/10: 0.01614 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch10/10: 0.02733 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch10/10: 0.0205 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch10/10: 0.02452 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch10/10: 0.02906 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch10/10: 0.02141 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch10/10: 0.01683 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch10/10: 0.04296 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch10/10: 0.01421 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch10/10: 0.03748 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch10/10: 0.0138 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch10/10: 0.02454 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch10/10: 0.0288 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch10/10: 0.02699 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch10/10: 0.01948 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch10/10: 0.0245 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch10/10: 0.02669 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch10/10: 0.02124 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch10/10: 0.01486 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch10/10: 0.03135 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch10/10: 0.03006 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch10/10: 0.01595 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch10/10: 0.02862 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch10/10: 0.01315 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch10/10: 0.04587 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch10/10: 0.01393 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch10/10: 0.01421 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch10/10: 0.01653 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch10/10: 0.02072 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch10/10: 0.01848 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch10/10: 0.03182 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch10/10: 0.01856 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch10/10: 0.01802 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch10/10: 0.02345 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch10/10: 0.14891 in 0.09 secs
Val Loss for batch 040/271 @epoch10/10: 0.29958 in 0.09 secs
Val Loss for batch 060/271 @epoch10/10: 0.18775 in 0.09 secs
Val Loss for batch 080/271 @epoch10/10: 0.16746 in 0.09 secs
Val Loss for batch 100/271 @epoch10/10: 0.12869 in 0.09 secs
Val Loss for batch 120/271 @epoch10/10: 0.21598 in 0.09 secs
Val Loss for batch 140/271 @epoch10/10: 0.28894 in 0.09 secs
Val Loss for batch 160/271 @epoch10/10: 0.2293 in 0.09 secs
Val Loss for batch 180/271 @epoch10/10: 0.18493 in 0.09 secs
Val Loss for batch 200/271 @epoch10/10: 0.22491 in 0.09 secs
Val Loss for batch 220/271 @epoch10/10: 0.27432 in 0.09 secs
Val Loss for batch 240/271 @epoch10/10: 0.24342 in 0.09 secs
Val Loss for batch 260/271 @epoch10/10: 0.23395 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7450549255879386, 'Cardiomegaly': 0.8292116160049754, 'Consolidation': 0.7365438772820436, 'Edema': 0.8265771158971355, 'Effusion': 0.8551417569108936, 'Emphysema': 0.8545332674468314, 'Fibrosis': 0.684901638703117, 'Hernia': 0.889411263188344, 'Infiltration': 0.6470605133497758, 'Mass': 0.7883597276473976, 'Nodule': 0.6985630403702577, 'Pleural_Thickening': 0.7348752856639792, 'Pneumonia': 0.6227531541186113, 'Pneumothorax': 0.767112797085864, 'none': 0.7139304980296286}
AVG Loss in validation set: 0.2308447704483831
0.7628642842326546
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_steplr_0/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch1/10: 0.27327 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch1/10: 0.26905 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch1/10: 0.25617 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch1/10: 0.26268 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch1/10: 0.25841 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch1/10: 0.26201 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch1/10: 0.25855 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch1/10: 0.25389 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch1/10: 0.23721 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch1/10: 0.2647 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch1/10: 0.24749 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch1/10: 0.25423 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch1/10: 0.26734 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch1/10: 0.24504 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch1/10: 0.28888 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch1/10: 0.26312 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch1/10: 0.27788 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch1/10: 0.24238 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch1/10: 0.24272 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch1/10: 0.24499 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch1/10: 0.23009 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch1/10: 0.24541 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch1/10: 0.24418 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch1/10: 0.24766 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch1/10: 0.24582 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch1/10: 0.22124 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch1/10: 0.2514 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch1/10: 0.2456 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch1/10: 0.23111 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch1/10: 0.24007 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch1/10: 0.24671 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch1/10: 0.23883 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch1/10: 0.22337 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch1/10: 0.23683 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch1/10: 0.237 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch1/10: 0.24036 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch1/10: 0.2072 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch1/10: 0.24971 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch1/10: 0.2215 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch1/10: 0.2489 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch1/10: 0.23365 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch1/10: 0.25058 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch1/10: 0.21921 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch1/10: 0.23564 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch1/10: 0.22916 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch1/10: 0.23077 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch1/10: 0.24173 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch1/10: 0.22675 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch1/10: 0.23472 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch1/10: 0.21518 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch1/10: 0.20377 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch1/10: 0.25332 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch1/10: 0.23052 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch1/10: 0.23819 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch1/10: 0.19989 in 0.09 secs
Val Loss for batch 040/271 @epoch1/10: 0.27056 in 0.09 secs
Val Loss for batch 060/271 @epoch1/10: 0.23429 in 0.09 secs
Val Loss for batch 080/271 @epoch1/10: 0.20782 in 0.09 secs
Val Loss for batch 100/271 @epoch1/10: 0.19086 in 0.09 secs
Val Loss for batch 120/271 @epoch1/10: 0.22102 in 0.09 secs
Val Loss for batch 140/271 @epoch1/10: 0.23179 in 0.09 secs
Val Loss for batch 160/271 @epoch1/10: 0.23757 in 0.09 secs
Val Loss for batch 180/271 @epoch1/10: 0.20859 in 0.09 secs
Val Loss for batch 200/271 @epoch1/10: 0.23934 in 0.09 secs
Val Loss for batch 220/271 @epoch1/10: 0.25618 in 0.09 secs
Val Loss for batch 240/271 @epoch1/10: 0.23019 in 0.09 secs
Val Loss for batch 260/271 @epoch1/10: 0.24155 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.706528480183356, 'Cardiomegaly': 0.8293275334292608, 'Consolidation': 0.7487156920144387, 'Edema': 0.8489417819547634, 'Effusion': 0.8397056469126478, 'Emphysema': 0.7552265038927306, 'Fibrosis': 0.646512128149367, 'Hernia': 0.8445929692614528, 'Infiltration': 0.5217634967974347, 'Mass': 0.6771450062358744, 'Nodule': 0.5845710929919913, 'Pleural_Thickening': 0.6720372706016666, 'Pneumonia': 0.6270394281030924, 'Pneumothorax': 0.7156539890175505, 'none': 0.6744180866214898}
AVG Loss in validation set: 0.22874386418460974
0.7155543585389733
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch2/10: 0.23918 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch2/10: 0.23137 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch2/10: 0.22063 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch2/10: 0.21638 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch2/10: 0.22786 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch2/10: 0.20568 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch2/10: 0.24146 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch2/10: 0.21257 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch2/10: 0.20946 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch2/10: 0.21763 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch2/10: 0.23385 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch2/10: 0.22636 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch2/10: 0.20192 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch2/10: 0.20227 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch2/10: 0.23497 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch2/10: 0.23066 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch2/10: 0.22793 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch2/10: 0.2403 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch2/10: 0.19787 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch2/10: 0.21493 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch2/10: 0.20205 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch2/10: 0.2083 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch2/10: 0.21012 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch2/10: 0.21726 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch2/10: 0.22874 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch2/10: 0.21042 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch2/10: 0.21969 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch2/10: 0.1959 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch2/10: 0.21827 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch2/10: 0.21404 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch2/10: 0.21849 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch2/10: 0.21315 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch2/10: 0.20277 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch2/10: 0.22128 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch2/10: 0.21197 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch2/10: 0.20274 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch2/10: 0.19579 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch2/10: 0.22379 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch2/10: 0.18862 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch2/10: 0.20481 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch2/10: 0.24404 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch2/10: 0.21505 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch2/10: 0.19433 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch2/10: 0.19392 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch2/10: 0.20382 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch2/10: 0.20692 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch2/10: 0.19879 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch2/10: 0.20206 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch2/10: 0.20165 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch2/10: 0.21724 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch2/10: 0.20804 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch2/10: 0.2094 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch2/10: 0.20685 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch2/10: 0.22208 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch2/10: 0.19654 in 0.09 secs
Val Loss for batch 040/271 @epoch2/10: 0.26456 in 0.09 secs
Val Loss for batch 060/271 @epoch2/10: 0.23176 in 0.09 secs
Val Loss for batch 080/271 @epoch2/10: 0.192 in 0.09 secs
Val Loss for batch 100/271 @epoch2/10: 0.18133 in 0.09 secs
Val Loss for batch 120/271 @epoch2/10: 0.20187 in 0.09 secs
Val Loss for batch 140/271 @epoch2/10: 0.24974 in 0.09 secs
Val Loss for batch 160/271 @epoch2/10: 0.23403 in 0.09 secs
Val Loss for batch 180/271 @epoch2/10: 0.20476 in 0.09 secs
Val Loss for batch 200/271 @epoch2/10: 0.22593 in 0.09 secs
Val Loss for batch 220/271 @epoch2/10: 0.2591 in 0.09 secs
Val Loss for batch 240/271 @epoch2/10: 0.23588 in 0.09 secs
Val Loss for batch 260/271 @epoch2/10: 0.25865 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7261214725054412, 'Cardiomegaly': 0.8649597975810372, 'Consolidation': 0.7493860605484616, 'Edema': 0.8583180938468018, 'Effusion': 0.8611295127539471, 'Emphysema': 0.7653073291116462, 'Fibrosis': 0.6700094227475677, 'Hernia': 0.8238235159782592, 'Infiltration': 0.5629622027651731, 'Mass': 0.6674348873427578, 'Nodule': 0.5920520605502475, 'Pleural_Thickening': 0.6909018293726328, 'Pneumonia': 0.5618241817440666, 'Pneumothorax': 0.7407438884172829, 'none': 0.7129859520332545}
AVG Loss in validation set: 0.227309044848368
0.7239267325189516
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch3/10: 0.19024 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch3/10: 0.20215 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch3/10: 0.20626 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch3/10: 0.18191 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch3/10: 0.19532 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch3/10: 0.20623 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch3/10: 0.17375 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch3/10: 0.20462 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch3/10: 0.19501 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch3/10: 0.19258 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch3/10: 0.18411 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch3/10: 0.1802 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch3/10: 0.17778 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch3/10: 0.25034 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch3/10: 0.19806 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch3/10: 0.20204 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch3/10: 0.21328 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch3/10: 0.19115 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch3/10: 0.18117 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch3/10: 0.19932 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch3/10: 0.16406 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch3/10: 0.18597 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch3/10: 0.20287 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch3/10: 0.19087 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch3/10: 0.20646 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch3/10: 0.19326 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch3/10: 0.22815 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch3/10: 0.21018 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch3/10: 0.18272 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch3/10: 0.19145 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch3/10: 0.19365 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch3/10: 0.21371 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch3/10: 0.20376 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch3/10: 0.20568 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch3/10: 0.20988 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch3/10: 0.18994 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch3/10: 0.17849 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch3/10: 0.17004 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch3/10: 0.19989 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch3/10: 0.18839 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch3/10: 0.18032 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch3/10: 0.19144 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch3/10: 0.18225 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch3/10: 0.17272 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch3/10: 0.20808 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch3/10: 0.21114 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch3/10: 0.21729 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch3/10: 0.17678 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch3/10: 0.1789 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch3/10: 0.18635 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch3/10: 0.18167 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch3/10: 0.20594 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch3/10: 0.21949 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch3/10: 0.19545 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch3/10: 0.18264 in 0.09 secs
Val Loss for batch 040/271 @epoch3/10: 0.2581 in 0.09 secs
Val Loss for batch 060/271 @epoch3/10: 0.2298 in 0.09 secs
Val Loss for batch 080/271 @epoch3/10: 0.18566 in 0.09 secs
Val Loss for batch 100/271 @epoch3/10: 0.16746 in 0.09 secs
Val Loss for batch 120/271 @epoch3/10: 0.19501 in 0.09 secs
Val Loss for batch 140/271 @epoch3/10: 0.24164 in 0.09 secs
Val Loss for batch 160/271 @epoch3/10: 0.22671 in 0.09 secs
Val Loss for batch 180/271 @epoch3/10: 0.1983 in 0.09 secs
Val Loss for batch 200/271 @epoch3/10: 0.21884 in 0.09 secs
Val Loss for batch 220/271 @epoch3/10: 0.26046 in 0.09 secs
Val Loss for batch 240/271 @epoch3/10: 0.23635 in 0.09 secs
Val Loss for batch 260/271 @epoch3/10: 0.24716 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7289918712695468, 'Cardiomegaly': 0.8714101362839032, 'Consolidation': 0.7380346809666666, 'Edema': 0.8599113146494022, 'Effusion': 0.8624024561852374, 'Emphysema': 0.7840171914259952, 'Fibrosis': 0.6708068545940896, 'Hernia': 0.8280833701262122, 'Infiltration': 0.5735627469764701, 'Mass': 0.6759480428217807, 'Nodule': 0.5950255744421056, 'Pleural_Thickening': 0.7053703837064336, 'Pneumonia': 0.5904406331427683, 'Pneumothorax': 0.7345737474006061, 'none': 0.7113927400954513}
AVG Loss in validation set: 0.22185572687669095
0.729898500285087
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch4/10: 0.16896 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch4/10: 0.20317 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch4/10: 0.18175 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch4/10: 0.17727 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch4/10: 0.17968 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch4/10: 0.18372 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch4/10: 0.19872 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch4/10: 0.20799 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch4/10: 0.18915 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch4/10: 0.19579 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch4/10: 0.20298 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch4/10: 0.19081 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch4/10: 0.18238 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch4/10: 0.19654 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch4/10: 0.20976 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch4/10: 0.18916 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch4/10: 0.18046 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch4/10: 0.18745 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch4/10: 0.20243 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch4/10: 0.19004 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch4/10: 0.19168 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch4/10: 0.17046 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch4/10: 0.19716 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch4/10: 0.18771 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch4/10: 0.18112 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch4/10: 0.21937 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch4/10: 0.18344 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch4/10: 0.182 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch4/10: 0.19514 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch4/10: 0.20645 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch4/10: 0.19237 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch4/10: 0.19864 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch4/10: 0.19802 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch4/10: 0.20181 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch4/10: 0.17241 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch4/10: 0.19324 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch4/10: 0.18975 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch4/10: 0.2141 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch4/10: 0.17951 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch4/10: 0.20427 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch4/10: 0.21907 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch4/10: 0.18872 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch4/10: 0.20499 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch4/10: 0.19245 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch4/10: 0.20509 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch4/10: 0.19751 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch4/10: 0.16856 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch4/10: 0.2024 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch4/10: 0.18859 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch4/10: 0.18112 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch4/10: 0.18624 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch4/10: 0.16315 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch4/10: 0.18778 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch4/10: 0.18904 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch4/10: 0.19215 in 0.09 secs
Val Loss for batch 040/271 @epoch4/10: 0.25698 in 0.09 secs
Val Loss for batch 060/271 @epoch4/10: 0.22456 in 0.09 secs
Val Loss for batch 080/271 @epoch4/10: 0.1859 in 0.09 secs
Val Loss for batch 100/271 @epoch4/10: 0.17138 in 0.09 secs
Val Loss for batch 120/271 @epoch4/10: 0.19902 in 0.09 secs
Val Loss for batch 140/271 @epoch4/10: 0.23982 in 0.09 secs
Val Loss for batch 160/271 @epoch4/10: 0.22779 in 0.09 secs
Val Loss for batch 180/271 @epoch4/10: 0.19857 in 0.09 secs
Val Loss for batch 200/271 @epoch4/10: 0.21784 in 0.09 secs
Val Loss for batch 220/271 @epoch4/10: 0.25939 in 0.09 secs
Val Loss for batch 240/271 @epoch4/10: 0.22998 in 0.09 secs
Val Loss for batch 260/271 @epoch4/10: 0.2494 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7294833664012882, 'Cardiomegaly': 0.867469107352451, 'Consolidation': 0.7411122233798186, 'Edema': 0.8557491904662667, 'Effusion': 0.8597513748248673, 'Emphysema': 0.7822253070815612, 'Fibrosis': 0.6711705535500384, 'Hernia': 0.8339631259229938, 'Infiltration': 0.5789628985343186, 'Mass': 0.6757803152123678, 'Nodule': 0.5929836082549459, 'Pleural_Thickening': 0.7061517106143782, 'Pneumonia': 0.5754125669246426, 'Pneumothorax': 0.7356646173352858, 'none': 0.7134741850809063}
AVG Loss in validation set: 0.22242688164769417
0.728991426132516
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch5/10: 0.18106 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch5/10: 0.17488 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch5/10: 0.19118 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch5/10: 0.20103 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch5/10: 0.17244 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch5/10: 0.21729 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch5/10: 0.17387 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch5/10: 0.18545 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch5/10: 0.17391 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch5/10: 0.17731 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch5/10: 0.19694 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch5/10: 0.19829 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch5/10: 0.18422 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch5/10: 0.18851 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch5/10: 0.17241 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch5/10: 0.18371 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch5/10: 0.20394 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch5/10: 0.18384 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch5/10: 0.18928 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch5/10: 0.19889 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch5/10: 0.2075 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch5/10: 0.16702 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch5/10: 0.1784 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch5/10: 0.17643 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch5/10: 0.18285 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch5/10: 0.17759 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch5/10: 0.20491 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch5/10: 0.20793 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch5/10: 0.21403 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch5/10: 0.18743 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch5/10: 0.16442 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch5/10: 0.20754 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch5/10: 0.17647 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch5/10: 0.1894 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch5/10: 0.19724 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch5/10: 0.18535 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch5/10: 0.19706 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch5/10: 0.172 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch5/10: 0.20441 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch5/10: 0.17636 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch5/10: 0.18671 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch5/10: 0.20095 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch5/10: 0.17385 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch5/10: 0.20009 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch5/10: 0.21292 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch5/10: 0.17595 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch5/10: 0.18094 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch5/10: 0.19724 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch5/10: 0.20653 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch5/10: 0.18758 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch5/10: 0.18486 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch5/10: 0.16932 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch5/10: 0.21906 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch5/10: 0.22921 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch5/10: 0.18095 in 0.09 secs
Val Loss for batch 040/271 @epoch5/10: 0.25162 in 0.09 secs
Val Loss for batch 060/271 @epoch5/10: 0.22766 in 0.09 secs
Val Loss for batch 080/271 @epoch5/10: 0.17993 in 0.09 secs
Val Loss for batch 100/271 @epoch5/10: 0.17369 in 0.09 secs
Val Loss for batch 120/271 @epoch5/10: 0.19928 in 0.09 secs
Val Loss for batch 140/271 @epoch5/10: 0.2374 in 0.09 secs
Val Loss for batch 160/271 @epoch5/10: 0.22764 in 0.09 secs
Val Loss for batch 180/271 @epoch5/10: 0.18874 in 0.09 secs
Val Loss for batch 200/271 @epoch5/10: 0.21856 in 0.09 secs
Val Loss for batch 220/271 @epoch5/10: 0.25672 in 0.09 secs
Val Loss for batch 240/271 @epoch5/10: 0.22724 in 0.09 secs
Val Loss for batch 260/271 @epoch5/10: 0.25032 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7320799084380094, 'Cardiomegaly': 0.8681561101970874, 'Consolidation': 0.7411727431505069, 'Edema': 0.8613288245006899, 'Effusion': 0.860503133428678, 'Emphysema': 0.788306383659386, 'Fibrosis': 0.6666380164206839, 'Hernia': 0.8193626965881583, 'Infiltration': 0.5735429893606431, 'Mass': 0.6781681881777952, 'Nodule': 0.5970791998306172, 'Pleural_Thickening': 0.7031130188777726, 'Pneumonia': 0.5931890987553493, 'Pneumothorax': 0.7381230840362601, 'none': 0.7130502944223245}
AVG Loss in validation set: 0.22190613959241234
0.7300545282444026
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch6/10: 0.21684 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch6/10: 0.2088 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch6/10: 0.19207 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch6/10: 0.20637 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch6/10: 0.18449 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch6/10: 0.20901 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch6/10: 0.20569 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch6/10: 0.20296 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch6/10: 0.21136 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch6/10: 0.18797 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch6/10: 0.17841 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch6/10: 0.17816 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch6/10: 0.20069 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch6/10: 0.19641 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch6/10: 0.21712 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch6/10: 0.18899 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch6/10: 0.19699 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch6/10: 0.199 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch6/10: 0.19757 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch6/10: 0.20844 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch6/10: 0.18707 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch6/10: 0.16439 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch6/10: 0.18855 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch6/10: 0.19297 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch6/10: 0.19166 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch6/10: 0.19237 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch6/10: 0.18465 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch6/10: 0.21947 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch6/10: 0.21856 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch6/10: 0.18267 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch6/10: 0.19869 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch6/10: 0.20158 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch6/10: 0.19468 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch6/10: 0.18757 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch6/10: 0.20933 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch6/10: 0.18315 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch6/10: 0.21386 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch6/10: 0.19681 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch6/10: 0.20271 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch6/10: 0.19396 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch6/10: 0.1873 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch6/10: 0.17594 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch6/10: 0.19905 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch6/10: 0.2089 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch6/10: 0.18823 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch6/10: 0.19214 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch6/10: 0.19047 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch6/10: 0.17547 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch6/10: 0.19091 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch6/10: 0.21448 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch6/10: 0.16919 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch6/10: 0.2029 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch6/10: 0.18571 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch6/10: 0.19472 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch6/10: 0.18477 in 0.09 secs
Val Loss for batch 040/271 @epoch6/10: 0.25728 in 0.09 secs
Val Loss for batch 060/271 @epoch6/10: 0.22313 in 0.09 secs
Val Loss for batch 080/271 @epoch6/10: 0.17996 in 0.09 secs
Val Loss for batch 100/271 @epoch6/10: 0.16809 in 0.09 secs
Val Loss for batch 120/271 @epoch6/10: 0.19725 in 0.09 secs
Val Loss for batch 140/271 @epoch6/10: 0.24093 in 0.09 secs
Val Loss for batch 160/271 @epoch6/10: 0.2256 in 0.08 secs
Val Loss for batch 180/271 @epoch6/10: 0.19108 in 0.09 secs
Val Loss for batch 200/271 @epoch6/10: 0.21749 in 0.09 secs
Val Loss for batch 220/271 @epoch6/10: 0.25559 in 0.08 secs
Val Loss for batch 240/271 @epoch6/10: 0.22504 in 0.09 secs
Val Loss for batch 260/271 @epoch6/10: 0.24651 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7310466557485402, 'Cardiomegaly': 0.8750172282067477, 'Consolidation': 0.7395532789163465, 'Edema': 0.8632120379155489, 'Effusion': 0.8608709024320553, 'Emphysema': 0.7857957461313102, 'Fibrosis': 0.6817935417797896, 'Hernia': 0.7993605651386203, 'Infiltration': 0.5725476194920535, 'Mass': 0.6842808090176441, 'Nodule': 0.590323768634166, 'Pleural_Thickening': 0.7158138425546338, 'Pneumonia': 0.5694075341627164, 'Pneumothorax': 0.743229302300362, 'none': 0.7128901367018137}
AVG Loss in validation set: 0.2205808378663043
0.7294466308878953
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch7/10: 0.18001 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch7/10: 0.23393 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch7/10: 0.17005 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch7/10: 0.20404 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch7/10: 0.1738 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch7/10: 0.16238 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch7/10: 0.19128 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch7/10: 0.2116 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch7/10: 0.18832 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch7/10: 0.2017 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch7/10: 0.19456 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch7/10: 0.19082 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch7/10: 0.19882 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch7/10: 0.18901 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch7/10: 0.19792 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch7/10: 0.20113 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch7/10: 0.20676 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch7/10: 0.16233 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch7/10: 0.21232 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch7/10: 0.22062 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch7/10: 0.19479 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch7/10: 0.19523 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch7/10: 0.20101 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch7/10: 0.2042 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch7/10: 0.24462 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch7/10: 0.21425 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch7/10: 0.19684 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch7/10: 0.20159 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch7/10: 0.1912 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch7/10: 0.17558 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch7/10: 0.19779 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch7/10: 0.19934 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch7/10: 0.20348 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch7/10: 0.17823 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch7/10: 0.15526 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch7/10: 0.19586 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch7/10: 0.18428 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch7/10: 0.19757 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch7/10: 0.19659 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch7/10: 0.17785 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch7/10: 0.21371 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch7/10: 0.19038 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch7/10: 0.17304 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch7/10: 0.24726 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch7/10: 0.17439 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch7/10: 0.17222 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch7/10: 0.18213 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch7/10: 0.16902 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch7/10: 0.19506 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch7/10: 0.21917 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch7/10: 0.18653 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch7/10: 0.19095 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch7/10: 0.19472 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch7/10: 0.17643 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch7/10: 0.17786 in 0.09 secs
Val Loss for batch 040/271 @epoch7/10: 0.25641 in 0.09 secs
Val Loss for batch 060/271 @epoch7/10: 0.23519 in 0.09 secs
Val Loss for batch 080/271 @epoch7/10: 0.18331 in 0.09 secs
Val Loss for batch 100/271 @epoch7/10: 0.16901 in 0.09 secs
Val Loss for batch 120/271 @epoch7/10: 0.19711 in 0.09 secs
Val Loss for batch 140/271 @epoch7/10: 0.24195 in 0.09 secs
Val Loss for batch 160/271 @epoch7/10: 0.22716 in 0.09 secs
Val Loss for batch 180/271 @epoch7/10: 0.1915 in 0.09 secs
Val Loss for batch 200/271 @epoch7/10: 0.21864 in 0.09 secs
Val Loss for batch 220/271 @epoch7/10: 0.25536 in 0.09 secs
Val Loss for batch 240/271 @epoch7/10: 0.23125 in 0.09 secs
Val Loss for batch 260/271 @epoch7/10: 0.24631 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7326146410915356, 'Cardiomegaly': 0.8650851976719073, 'Consolidation': 0.7396816592817602, 'Edema': 0.856369974011933, 'Effusion': 0.8588062713003058, 'Emphysema': 0.7935892052773945, 'Fibrosis': 0.6640663157693683, 'Hernia': 0.8608102553172053, 'Infiltration': 0.5767481262504376, 'Mass': 0.6725246427825293, 'Nodule': 0.5907039292600602, 'Pleural_Thickening': 0.7072423044981464, 'Pneumonia': 0.596349159021737, 'Pneumothorax': 0.7370777624761907, 'none': 0.7139956934558253}
AVG Loss in validation set: 0.22219063808699752
0.732262103143608
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch8/10: 0.19726 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch8/10: 0.18307 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch8/10: 0.18078 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch8/10: 0.21888 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch8/10: 0.1851 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch8/10: 0.20048 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch8/10: 0.22679 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch8/10: 0.1872 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch8/10: 0.16335 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch8/10: 0.20909 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch8/10: 0.19778 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch8/10: 0.18041 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch8/10: 0.17358 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch8/10: 0.23072 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch8/10: 0.19571 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch8/10: 0.19599 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch8/10: 0.19159 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch8/10: 0.19033 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch8/10: 0.20695 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch8/10: 0.17482 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch8/10: 0.2118 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch8/10: 0.18322 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch8/10: 0.20924 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch8/10: 0.1941 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch8/10: 0.19119 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch8/10: 0.19035 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch8/10: 0.1926 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch8/10: 0.19235 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch8/10: 0.19001 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch8/10: 0.20862 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch8/10: 0.24257 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch8/10: 0.18627 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch8/10: 0.19383 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch8/10: 0.2306 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch8/10: 0.1891 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch8/10: 0.21777 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch8/10: 0.19746 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch8/10: 0.22176 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch8/10: 0.17448 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch8/10: 0.17216 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch8/10: 0.17935 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch8/10: 0.17954 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch8/10: 0.19146 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch8/10: 0.21723 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch8/10: 0.17213 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch8/10: 0.19282 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch8/10: 0.18942 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch8/10: 0.17676 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch8/10: 0.1732 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch8/10: 0.19234 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch8/10: 0.18727 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch8/10: 0.19722 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch8/10: 0.18026 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch8/10: 0.18261 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch8/10: 0.18149 in 0.09 secs
Val Loss for batch 040/271 @epoch8/10: 0.25411 in 0.08 secs
Val Loss for batch 060/271 @epoch8/10: 0.22986 in 0.09 secs
Val Loss for batch 080/271 @epoch8/10: 0.17985 in 0.09 secs
Val Loss for batch 100/271 @epoch8/10: 0.16799 in 0.09 secs
Val Loss for batch 120/271 @epoch8/10: 0.19764 in 0.09 secs
Val Loss for batch 140/271 @epoch8/10: 0.23618 in 0.09 secs
Val Loss for batch 160/271 @epoch8/10: 0.22054 in 0.09 secs
Val Loss for batch 180/271 @epoch8/10: 0.19235 in 0.09 secs
Val Loss for batch 200/271 @epoch8/10: 0.21324 in 0.09 secs
Val Loss for batch 220/271 @epoch8/10: 0.25305 in 0.09 secs
Val Loss for batch 240/271 @epoch8/10: 0.22981 in 0.09 secs
Val Loss for batch 260/271 @epoch8/10: 0.24542 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.726883216465398, 'Cardiomegaly': 0.8685507853201129, 'Consolidation': 0.7394213682309757, 'Edema': 0.8583384930073764, 'Effusion': 0.862124369656491, 'Emphysema': 0.7799348942340741, 'Fibrosis': 0.6634107708553326, 'Hernia': 0.8497602119269826, 'Infiltration': 0.5744316681037667, 'Mass': 0.6749110121741992, 'Nodule': 0.59715985066972, 'Pleural_Thickening': 0.7101610817803365, 'Pneumonia': 0.5966829720086828, 'Pneumothorax': 0.7339394521910623, 'none': 0.7136819959318661}
AVG Loss in validation set: 0.22049906856750262
0.7311221533303222
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch9/10: 0.20664 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch9/10: 0.19388 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch9/10: 0.20067 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch9/10: 0.18376 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch9/10: 0.21855 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch9/10: 0.1744 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch9/10: 0.17711 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch9/10: 0.17205 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch9/10: 0.20168 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch9/10: 0.1986 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch9/10: 0.1986 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch9/10: 0.18751 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch9/10: 0.16226 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch9/10: 0.18692 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch9/10: 0.1777 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch9/10: 0.16923 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch9/10: 0.18854 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch9/10: 0.18364 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch9/10: 0.1965 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch9/10: 0.17815 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch9/10: 0.21434 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch9/10: 0.17487 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch9/10: 0.20216 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch9/10: 0.18548 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch9/10: 0.17159 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch9/10: 0.20066 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch9/10: 0.17528 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch9/10: 0.19616 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch9/10: 0.19203 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch9/10: 0.19357 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch9/10: 0.19378 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch9/10: 0.20895 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch9/10: 0.17629 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch9/10: 0.22605 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch9/10: 0.18167 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch9/10: 0.17861 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch9/10: 0.19399 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch9/10: 0.17213 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch9/10: 0.18133 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch9/10: 0.18553 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch9/10: 0.17736 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch9/10: 0.18639 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch9/10: 0.18982 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch9/10: 0.20519 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch9/10: 0.18797 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch9/10: 0.17794 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch9/10: 0.1837 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch9/10: 0.20385 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch9/10: 0.16897 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch9/10: 0.18123 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch9/10: 0.18141 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch9/10: 0.18526 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch9/10: 0.20637 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch9/10: 0.19725 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch9/10: 0.19086 in 0.09 secs
Val Loss for batch 040/271 @epoch9/10: 0.2562 in 0.09 secs
Val Loss for batch 060/271 @epoch9/10: 0.22999 in 0.09 secs
Val Loss for batch 080/271 @epoch9/10: 0.1835 in 0.09 secs
Val Loss for batch 100/271 @epoch9/10: 0.16968 in 0.09 secs
Val Loss for batch 120/271 @epoch9/10: 0.20175 in 0.09 secs
Val Loss for batch 140/271 @epoch9/10: 0.24214 in 0.09 secs
Val Loss for batch 160/271 @epoch9/10: 0.22618 in 0.09 secs
Val Loss for batch 180/271 @epoch9/10: 0.19634 in 0.09 secs
Val Loss for batch 200/271 @epoch9/10: 0.21393 in 0.09 secs
Val Loss for batch 220/271 @epoch9/10: 0.25642 in 0.09 secs
Val Loss for batch 240/271 @epoch9/10: 0.23146 in 0.09 secs
Val Loss for batch 260/271 @epoch9/10: 0.24707 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7332553581693222, 'Cardiomegaly': 0.869626332253345, 'Consolidation': 0.7440588637704445, 'Edema': 0.8559137746027206, 'Effusion': 0.8591831560111196, 'Emphysema': 0.7863104606247221, 'Fibrosis': 0.6664831686626338, 'Hernia': 0.8144360032276236, 'Infiltration': 0.5744890718180679, 'Mass': 0.6747037168343284, 'Nodule': 0.5955412451795787, 'Pleural_Thickening': 0.7106511123634776, 'Pneumonia': 0.6024903097006702, 'Pneumothorax': 0.7389900305245024, 'none': 0.7116857927450817}
AVG Loss in validation set: 0.22259049090008684
0.7304380431244684
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 020/1082 @epoch10/10: 0.20149 in 0 mins 0.27 secs
Train Loss for batch 040/1082 @epoch10/10: 0.17383 in 0 mins 0.27 secs
Train Loss for batch 060/1082 @epoch10/10: 0.18945 in 0 mins 0.27 secs
Train Loss for batch 080/1082 @epoch10/10: 0.2124 in 0 mins 0.27 secs
Train Loss for batch 100/1082 @epoch10/10: 0.18881 in 0 mins 0.27 secs
Train Loss for batch 120/1082 @epoch10/10: 0.23265 in 0 mins 0.27 secs
Train Loss for batch 140/1082 @epoch10/10: 0.19199 in 0 mins 0.27 secs
Train Loss for batch 160/1082 @epoch10/10: 0.16275 in 0 mins 0.27 secs
Train Loss for batch 180/1082 @epoch10/10: 0.18974 in 0 mins 0.27 secs
Train Loss for batch 200/1082 @epoch10/10: 0.19817 in 0 mins 0.27 secs
Train Loss for batch 220/1082 @epoch10/10: 0.20444 in 0 mins 0.27 secs
Train Loss for batch 240/1082 @epoch10/10: 0.20157 in 0 mins 0.27 secs
Train Loss for batch 260/1082 @epoch10/10: 0.19705 in 0 mins 0.27 secs
Train Loss for batch 280/1082 @epoch10/10: 0.21134 in 0 mins 0.27 secs
Train Loss for batch 300/1082 @epoch10/10: 0.19373 in 0 mins 0.27 secs
Train Loss for batch 320/1082 @epoch10/10: 0.22231 in 0 mins 0.27 secs
Train Loss for batch 340/1082 @epoch10/10: 0.17916 in 0 mins 0.27 secs
Train Loss for batch 360/1082 @epoch10/10: 0.18754 in 0 mins 0.27 secs
Train Loss for batch 380/1082 @epoch10/10: 0.21172 in 0 mins 0.27 secs
Train Loss for batch 400/1082 @epoch10/10: 0.19542 in 0 mins 0.27 secs
Train Loss for batch 420/1082 @epoch10/10: 0.20669 in 0 mins 0.27 secs
Train Loss for batch 440/1082 @epoch10/10: 0.20452 in 0 mins 0.27 secs
Train Loss for batch 460/1082 @epoch10/10: 0.19747 in 0 mins 0.27 secs
Train Loss for batch 480/1082 @epoch10/10: 0.16484 in 0 mins 0.27 secs
Train Loss for batch 500/1082 @epoch10/10: 0.20233 in 0 mins 0.27 secs
Train Loss for batch 520/1082 @epoch10/10: 0.18762 in 0 mins 0.27 secs
Train Loss for batch 540/1082 @epoch10/10: 0.18458 in 0 mins 0.27 secs
Train Loss for batch 560/1082 @epoch10/10: 0.21661 in 0 mins 0.27 secs
Train Loss for batch 580/1082 @epoch10/10: 0.19928 in 0 mins 0.27 secs
Train Loss for batch 600/1082 @epoch10/10: 0.20536 in 0 mins 0.27 secs
Train Loss for batch 620/1082 @epoch10/10: 0.18512 in 0 mins 0.27 secs
Train Loss for batch 640/1082 @epoch10/10: 0.2095 in 0 mins 0.27 secs
Train Loss for batch 660/1082 @epoch10/10: 0.20758 in 0 mins 0.27 secs
Train Loss for batch 680/1082 @epoch10/10: 0.19358 in 0 mins 0.27 secs
Train Loss for batch 700/1082 @epoch10/10: 0.21819 in 0 mins 0.27 secs
Train Loss for batch 720/1082 @epoch10/10: 0.20025 in 0 mins 0.27 secs
Train Loss for batch 740/1082 @epoch10/10: 0.19881 in 0 mins 0.27 secs
Train Loss for batch 760/1082 @epoch10/10: 0.17174 in 0 mins 0.27 secs
Train Loss for batch 780/1082 @epoch10/10: 0.1679 in 0 mins 0.27 secs
Train Loss for batch 800/1082 @epoch10/10: 0.19552 in 0 mins 0.27 secs
Train Loss for batch 820/1082 @epoch10/10: 0.20608 in 0 mins 0.27 secs
Train Loss for batch 840/1082 @epoch10/10: 0.17534 in 0 mins 0.27 secs
Train Loss for batch 860/1082 @epoch10/10: 0.21986 in 0 mins 0.27 secs
Train Loss for batch 880/1082 @epoch10/10: 0.16157 in 0 mins 0.27 secs
Train Loss for batch 900/1082 @epoch10/10: 0.18858 in 0 mins 0.27 secs
Train Loss for batch 920/1082 @epoch10/10: 0.18561 in 0 mins 0.27 secs
Train Loss for batch 940/1082 @epoch10/10: 0.2166 in 0 mins 0.27 secs
Train Loss for batch 960/1082 @epoch10/10: 0.20138 in 0 mins 0.27 secs
Train Loss for batch 980/1082 @epoch10/10: 0.16537 in 0 mins 0.27 secs
Train Loss for batch 1000/1082 @epoch10/10: 0.17816 in 0 mins 0.27 secs
Train Loss for batch 1020/1082 @epoch10/10: 0.2088 in 0 mins 0.27 secs
Train Loss for batch 1040/1082 @epoch10/10: 0.17899 in 0 mins 0.27 secs
Train Loss for batch 1060/1082 @epoch10/10: 0.18407 in 0 mins 0.27 secs
Train Loss for batch 1080/1082 @epoch10/10: 0.1916 in 0 mins 0.27 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 020/271 @epoch10/10: 0.19098 in 0.09 secs
Val Loss for batch 040/271 @epoch10/10: 0.25576 in 0.09 secs
Val Loss for batch 060/271 @epoch10/10: 0.22704 in 0.09 secs
Val Loss for batch 080/271 @epoch10/10: 0.1841 in 0.09 secs
Val Loss for batch 100/271 @epoch10/10: 0.16993 in 0.09 secs
Val Loss for batch 120/271 @epoch10/10: 0.19771 in 0.09 secs
Val Loss for batch 140/271 @epoch10/10: 0.23862 in 0.09 secs
Val Loss for batch 160/271 @epoch10/10: 0.2299 in 0.09 secs
Val Loss for batch 180/271 @epoch10/10: 0.1958 in 0.09 secs
Val Loss for batch 200/271 @epoch10/10: 0.22338 in 0.09 secs
Val Loss for batch 220/271 @epoch10/10: 0.2562 in 0.09 secs
Val Loss for batch 240/271 @epoch10/10: 0.22577 in 0.09 secs
Val Loss for batch 260/271 @epoch10/10: 0.24623 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7292311761583303, 'Cardiomegaly': 0.8717601774762799, 'Consolidation': 0.7358304164298177, 'Edema': 0.8569807897859548, 'Effusion': 0.8587697510186229, 'Emphysema': 0.7793693366885939, 'Fibrosis': 0.656521864685343, 'Hernia': 0.8002618638003746, 'Infiltration': 0.5744834518740105, 'Mass': 0.6800137062618307, 'Nodule': 0.5939083146100905, 'Pleural_Thickening': 0.7117126360764783, 'Pneumonia': 0.589909125085884, 'Pneumothorax': 0.7365152536869909, 'none': 0.710240802887349}
AVG Loss in validation set: 0.2227262808694588
0.7268048474027573
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/1/ft_resnet_50_adam_exponential/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch1/10: 0.27565 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch1/10: 0.23933 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch1/10: 0.25903 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch1/10: 0.24423 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch1/10: 0.25501 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch1/10: 0.24597 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch1/10: 0.27158 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch1/10: 0.23484 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch1/10: 0.21147 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch1/10: 0.21471 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch1/10: 0.22564 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch1/10: 0.20338 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch1/10: 0.26025 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch1/10: 0.25222 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch1/10: 0.22244 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch1/10: 0.22158 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch1/10: 0.20081 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch1/10: 0.1901 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch1/10: 0.20636 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch1/10: 0.26611 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch1/10: 0.21718 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch1/10: 0.2027 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch1/10: 0.28763 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch1/10: 0.2358 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch1/10: 0.20893 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch1/10: 0.2516 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch1/10: 0.21019 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch1/10: 0.26613 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch1/10: 0.27491 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch1/10: 0.18618 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch1/10: 0.24525 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch1/10: 0.2419 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch1/10: 0.20621 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch1/10: 0.20292 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch1/10: 0.19938 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch1/10: 0.2271 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch1/10: 0.18597 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch1/10: 0.24022 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch1/10: 0.20043 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch1/10: 0.23925 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch1/10: 0.21543 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch1/10: 0.1987 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch1/10: 0.20757 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch1/10: 0.19695 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch1/10: 0.22742 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch1/10: 0.25202 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch1/10: 0.26005 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch1/10: 0.2577 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch1/10: 0.21828 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch1/10: 0.22217 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch1/10: 0.19326 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch1/10: 0.22503 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch1/10: 0.25206 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch1/10: 0.21984 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch1/10: 0.15416 in 0.05 secs
Val Loss for batch 160/1082 @epoch1/10: 0.22289 in 0.05 secs
Val Loss for batch 240/1082 @epoch1/10: 0.20533 in 0.05 secs
Val Loss for batch 320/1082 @epoch1/10: 0.20283 in 0.05 secs
Val Loss for batch 400/1082 @epoch1/10: 0.15948 in 0.05 secs
Val Loss for batch 480/1082 @epoch1/10: 0.16952 in 0.05 secs
Val Loss for batch 560/1082 @epoch1/10: 0.20651 in 0.05 secs
Val Loss for batch 640/1082 @epoch1/10: 0.25082 in 0.05 secs
Val Loss for batch 720/1082 @epoch1/10: 0.21163 in 0.05 secs
Val Loss for batch 800/1082 @epoch1/10: 0.23758 in 0.05 secs
Val Loss for batch 880/1082 @epoch1/10: 0.19186 in 0.05 secs
Val Loss for batch 960/1082 @epoch1/10: 0.23394 in 0.05 secs
Val Loss for batch 1040/1082 @epoch1/10: 0.20427 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7384505229888463, 'Cardiomegaly': 0.8683266347013605, 'Consolidation': 0.7419404476490534, 'Edema': 0.8612634544633944, 'Effusion': 0.8486867253084979, 'Emphysema': 0.8504943867937552, 'Fibrosis': 0.7272871764227575, 'Hernia': 0.7880212535968211, 'Infiltration': 0.5710713304374564, 'Mass': 0.7679765695727317, 'Nodule': 0.6832317044968673, 'Pleural_Thickening': 0.741595119911151, 'Pneumonia': 0.587999873244691, 'Pneumothorax': 0.7988517227486257, 'none': 0.7412651646783357}
AVG Loss in validation set: 0.2251406701017297
0.7553712087382864
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch2/10: 0.20399 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch2/10: 0.17152 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch2/10: 0.21564 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch2/10: 0.21977 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch2/10: 0.26159 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch2/10: 0.25355 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch2/10: 0.18473 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch2/10: 0.16528 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch2/10: 0.23052 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch2/10: 0.22758 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch2/10: 0.19845 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch2/10: 0.22347 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch2/10: 0.19894 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch2/10: 0.18541 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch2/10: 0.1946 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch2/10: 0.16543 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch2/10: 0.19402 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch2/10: 0.23806 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch2/10: 0.19379 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch2/10: 0.12592 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch2/10: 0.17401 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch2/10: 0.20877 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch2/10: 0.19594 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch2/10: 0.23238 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch2/10: 0.17726 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch2/10: 0.15894 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch2/10: 0.22193 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch2/10: 0.28865 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch2/10: 0.1935 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch2/10: 0.22008 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch2/10: 0.15734 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch2/10: 0.17662 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch2/10: 0.1613 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch2/10: 0.2032 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch2/10: 0.1888 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch2/10: 0.15258 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch2/10: 0.21113 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch2/10: 0.15148 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch2/10: 0.19675 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch2/10: 0.16893 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch2/10: 0.16133 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch2/10: 0.24933 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch2/10: 0.1975 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch2/10: 0.18288 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch2/10: 0.15908 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch2/10: 0.20779 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch2/10: 0.18331 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch2/10: 0.17285 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch2/10: 0.2024 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch2/10: 0.17316 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch2/10: 0.23222 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch2/10: 0.20611 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch2/10: 0.15218 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch2/10: 0.17197 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch2/10: 0.21422 in 0.05 secs
Val Loss for batch 160/1082 @epoch2/10: 0.29726 in 0.05 secs
Val Loss for batch 240/1082 @epoch2/10: 0.21148 in 0.05 secs
Val Loss for batch 320/1082 @epoch2/10: 0.24647 in 0.05 secs
Val Loss for batch 400/1082 @epoch2/10: 0.20006 in 0.05 secs
Val Loss for batch 480/1082 @epoch2/10: 0.22459 in 0.05 secs
Val Loss for batch 560/1082 @epoch2/10: 0.25423 in 0.05 secs
Val Loss for batch 640/1082 @epoch2/10: 0.28434 in 0.05 secs
Val Loss for batch 720/1082 @epoch2/10: 0.25198 in 0.05 secs
Val Loss for batch 800/1082 @epoch2/10: 0.33215 in 0.05 secs
Val Loss for batch 880/1082 @epoch2/10: 0.31459 in 0.05 secs
Val Loss for batch 960/1082 @epoch2/10: 0.24782 in 0.05 secs
Val Loss for batch 1040/1082 @epoch2/10: 0.26518 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7421969731214948, 'Cardiomegaly': 0.8793289803533864, 'Consolidation': 0.7330044793596201, 'Edema': 0.8636835366951924, 'Effusion': 0.860869753393303, 'Emphysema': 0.7593371741736338, 'Fibrosis': 0.712441801345561, 'Hernia': 0.7783322929829636, 'Infiltration': 0.620234613596732, 'Mass': 0.7530104316364581, 'Nodule': 0.6805358273446365, 'Pleural_Thickening': 0.7222376896085372, 'Pneumonia': 0.6372893233139023, 'Pneumothorax': 0.7455353592304845, 'none': 0.7046427742616519}
AVG Loss in validation set: 0.27838480091596496
0.7491455882968504
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch3/10: 0.17353 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch3/10: 0.13277 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch3/10: 0.18931 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch3/10: 0.19782 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch3/10: 0.18392 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch3/10: 0.1205 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch3/10: 0.15684 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch3/10: 0.16894 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch3/10: 0.19506 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch3/10: 0.14492 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch3/10: 0.12792 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch3/10: 0.15897 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch3/10: 0.1503 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch3/10: 0.11542 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch3/10: 0.11572 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch3/10: 0.17342 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch3/10: 0.16049 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch3/10: 0.12833 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch3/10: 0.15783 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch3/10: 0.12109 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch3/10: 0.12201 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch3/10: 0.16407 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch3/10: 0.18812 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch3/10: 0.20752 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch3/10: 0.14583 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch3/10: 0.10094 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch3/10: 0.13605 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch3/10: 0.16124 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch3/10: 0.1072 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch3/10: 0.1445 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch3/10: 0.16625 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch3/10: 0.18374 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch3/10: 0.15313 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch3/10: 0.11457 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch3/10: 0.09978 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch3/10: 0.13858 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch3/10: 0.07262 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch3/10: 0.16645 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch3/10: 0.17777 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch3/10: 0.15704 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch3/10: 0.18095 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch3/10: 0.12677 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch3/10: 0.14405 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch3/10: 0.12323 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch3/10: 0.13225 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch3/10: 0.11278 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch3/10: 0.16189 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch3/10: 0.09703 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch3/10: 0.13613 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch3/10: 0.15215 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch3/10: 0.16509 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch3/10: 0.0976 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch3/10: 0.08158 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch3/10: 0.14073 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch3/10: 0.13259 in 0.05 secs
Val Loss for batch 160/1082 @epoch3/10: 0.23565 in 0.05 secs
Val Loss for batch 240/1082 @epoch3/10: 0.14612 in 0.05 secs
Val Loss for batch 320/1082 @epoch3/10: 0.18193 in 0.05 secs
Val Loss for batch 400/1082 @epoch3/10: 0.11723 in 0.05 secs
Val Loss for batch 480/1082 @epoch3/10: 0.13514 in 0.05 secs
Val Loss for batch 560/1082 @epoch3/10: 0.19958 in 0.05 secs
Val Loss for batch 640/1082 @epoch3/10: 0.20921 in 0.05 secs
Val Loss for batch 720/1082 @epoch3/10: 0.25206 in 0.05 secs
Val Loss for batch 800/1082 @epoch3/10: 0.26516 in 0.05 secs
Val Loss for batch 880/1082 @epoch3/10: 0.18306 in 0.05 secs
Val Loss for batch 960/1082 @epoch3/10: 0.24105 in 0.05 secs
Val Loss for batch 1040/1082 @epoch3/10: 0.20322 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7386952874499169, 'Cardiomegaly': 0.8819850262154857, 'Consolidation': 0.7140792185866526, 'Edema': 0.8476532736132454, 'Effusion': 0.863225589246223, 'Emphysema': 0.8164181165029502, 'Fibrosis': 0.6726923136392453, 'Hernia': 0.8199564575308679, 'Infiltration': 0.6117869595620938, 'Mass': 0.7902631728888242, 'Nodule': 0.6949474031907282, 'Pleural_Thickening': 0.7079242642769223, 'Pneumonia': 0.5754456961531205, 'Pneumothorax': 0.7355084982357233, 'none': 0.7282799652439654}
AVG Loss in validation set: 0.2194115671084206
0.7478986626494285
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch4/10: 0.20736 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch4/10: 0.09703 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch4/10: 0.10359 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch4/10: 0.11933 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch4/10: 0.12454 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch4/10: 0.11872 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch4/10: 0.09783 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch4/10: 0.15357 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch4/10: 0.14972 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch4/10: 0.14865 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch4/10: 0.11322 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch4/10: 0.16373 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch4/10: 0.07947 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch4/10: 0.10151 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch4/10: 0.13838 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch4/10: 0.08261 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch4/10: 0.10186 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch4/10: 0.1581 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch4/10: 0.12961 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch4/10: 0.15335 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch4/10: 0.16716 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch4/10: 0.12511 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch4/10: 0.13321 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch4/10: 0.11866 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch4/10: 0.14067 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch4/10: 0.08666 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch4/10: 0.1318 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch4/10: 0.12155 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch4/10: 0.13375 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch4/10: 0.11713 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch4/10: 0.1177 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch4/10: 0.08716 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch4/10: 0.11448 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch4/10: 0.1384 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch4/10: 0.0648 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch4/10: 0.1159 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch4/10: 0.09502 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch4/10: 0.10832 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch4/10: 0.10697 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch4/10: 0.13454 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch4/10: 0.14787 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch4/10: 0.13454 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch4/10: 0.11013 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch4/10: 0.12574 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch4/10: 0.08171 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch4/10: 0.12298 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch4/10: 0.13203 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch4/10: 0.05003 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch4/10: 0.10008 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch4/10: 0.13732 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch4/10: 0.09446 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch4/10: 0.15134 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch4/10: 0.06234 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch4/10: 0.10831 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch4/10: 0.13452 in 0.05 secs
Val Loss for batch 160/1082 @epoch4/10: 0.20561 in 0.05 secs
Val Loss for batch 240/1082 @epoch4/10: 0.14919 in 0.05 secs
Val Loss for batch 320/1082 @epoch4/10: 0.14579 in 0.05 secs
Val Loss for batch 400/1082 @epoch4/10: 0.11868 in 0.05 secs
Val Loss for batch 480/1082 @epoch4/10: 0.13143 in 0.05 secs
Val Loss for batch 560/1082 @epoch4/10: 0.22389 in 0.05 secs
Val Loss for batch 640/1082 @epoch4/10: 0.224 in 0.05 secs
Val Loss for batch 720/1082 @epoch4/10: 0.23982 in 0.05 secs
Val Loss for batch 800/1082 @epoch4/10: 0.28407 in 0.05 secs
Val Loss for batch 880/1082 @epoch4/10: 0.17238 in 0.05 secs
Val Loss for batch 960/1082 @epoch4/10: 0.2372 in 0.05 secs
Val Loss for batch 1040/1082 @epoch4/10: 0.16802 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.76583545124014, 'Cardiomegaly': 0.8729085610985374, 'Consolidation': 0.7169767707188314, 'Edema': 0.84653247882486, 'Effusion': 0.8631205862548921, 'Emphysema': 0.8298138325473607, 'Fibrosis': 0.6779308746874623, 'Hernia': 0.771313734147344, 'Infiltration': 0.596254964618438, 'Mass': 0.7886788809612741, 'Nodule': 0.6804812892622802, 'Pleural_Thickening': 0.7239890352601351, 'Pneumonia': 0.6247792585102506, 'Pneumothorax': 0.7553459881809876, 'none': 0.7374974991909562}
AVG Loss in validation set: 0.21006387791463307
0.7509972647366281
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch5/10: 0.06135 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch5/10: 0.07723 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch5/10: 0.0708 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch5/10: 0.08759 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch5/10: 0.10128 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch5/10: 0.173 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch5/10: 0.10104 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch5/10: 0.07575 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch5/10: 0.08363 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch5/10: 0.06504 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch5/10: 0.11614 in 0 mins 0.19 secs
Train Loss for batch 960/4327 @epoch5/10: 0.06749 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch5/10: 0.18587 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch5/10: 0.09088 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch5/10: 0.06669 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch5/10: 0.05439 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch5/10: 0.07738 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch5/10: 0.14304 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch5/10: 0.11501 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch5/10: 0.03988 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch5/10: 0.08764 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch5/10: 0.12626 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch5/10: 0.09213 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch5/10: 0.08808 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch5/10: 0.18353 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch5/10: 0.14313 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch5/10: 0.09582 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch5/10: 0.11863 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch5/10: 0.04924 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch5/10: 0.05951 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch5/10: 0.05978 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch5/10: 0.06311 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch5/10: 0.09942 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch5/10: 0.20547 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch5/10: 0.07731 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch5/10: 0.0849 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch5/10: 0.09843 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch5/10: 0.09603 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch5/10: 0.09442 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch5/10: 0.09409 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch5/10: 0.07757 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch5/10: 0.09107 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch5/10: 0.15036 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch5/10: 0.04419 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch5/10: 0.08496 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch5/10: 0.06314 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch5/10: 0.06796 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch5/10: 0.05809 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch5/10: 0.07155 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch5/10: 0.08063 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch5/10: 0.10019 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch5/10: 0.04966 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch5/10: 0.08479 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch5/10: 0.07013 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch5/10: 0.1311 in 0.05 secs
Val Loss for batch 160/1082 @epoch5/10: 0.23408 in 0.05 secs
Val Loss for batch 240/1082 @epoch5/10: 0.1434 in 0.05 secs
Val Loss for batch 320/1082 @epoch5/10: 0.17154 in 0.05 secs
Val Loss for batch 400/1082 @epoch5/10: 0.09514 in 0.05 secs
Val Loss for batch 480/1082 @epoch5/10: 0.16712 in 0.05 secs
Val Loss for batch 560/1082 @epoch5/10: 0.19101 in 0.05 secs
Val Loss for batch 640/1082 @epoch5/10: 0.24447 in 0.05 secs
Val Loss for batch 720/1082 @epoch5/10: 0.27646 in 0.05 secs
Val Loss for batch 800/1082 @epoch5/10: 0.3072 in 0.05 secs
Val Loss for batch 880/1082 @epoch5/10: 0.20005 in 0.05 secs
Val Loss for batch 960/1082 @epoch5/10: 0.23104 in 0.05 secs
Val Loss for batch 1040/1082 @epoch5/10: 0.18422 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7391839955272741, 'Cardiomegaly': 0.8726564529627856, 'Consolidation': 0.697495736718376, 'Edema': 0.8476270792365984, 'Effusion': 0.8609317631846453, 'Emphysema': 0.8337199880794941, 'Fibrosis': 0.6847290550785063, 'Hernia': 0.8401747788621103, 'Infiltration': 0.6072220345562331, 'Mass': 0.7744779829320637, 'Nodule': 0.6608579219358977, 'Pleural_Thickening': 0.7320934024586757, 'Pneumonia': 0.6027204137984676, 'Pneumothorax': 0.74589581870285, 'none': 0.7397512783139704}
AVG Loss in validation set: 0.2199168457471823
0.7499847445738556
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch6/10: 0.08527 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch6/10: 0.14943 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch6/10: 0.07414 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch6/10: 0.09846 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch6/10: 0.08927 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch6/10: 0.14594 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch6/10: 0.14204 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch6/10: 0.05853 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch6/10: 0.08692 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch6/10: 0.06105 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch6/10: 0.05777 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch6/10: 0.12225 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch6/10: 0.03543 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch6/10: 0.04215 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch6/10: 0.15265 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch6/10: 0.09832 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch6/10: 0.13907 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch6/10: 0.06659 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch6/10: 0.10238 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch6/10: 0.08007 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch6/10: 0.08877 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch6/10: 0.07482 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch6/10: 0.06365 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch6/10: 0.0819 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch6/10: 0.12549 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch6/10: 0.05146 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch6/10: 0.08824 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch6/10: 0.07421 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch6/10: 0.09505 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch6/10: 0.08491 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch6/10: 0.09438 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch6/10: 0.05352 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch6/10: 0.11726 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch6/10: 0.04968 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch6/10: 0.09902 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch6/10: 0.08168 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch6/10: 0.09344 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch6/10: 0.07568 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch6/10: 0.04818 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch6/10: 0.06581 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch6/10: 0.06277 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch6/10: 0.04016 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch6/10: 0.16692 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch6/10: 0.07787 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch6/10: 0.11581 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch6/10: 0.05047 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch6/10: 0.1007 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch6/10: 0.06875 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch6/10: 0.15415 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch6/10: 0.06621 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch6/10: 0.08667 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch6/10: 0.1468 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch6/10: 0.0656 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch6/10: 0.057 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch6/10: 0.12856 in 0.05 secs
Val Loss for batch 160/1082 @epoch6/10: 0.26459 in 0.05 secs
Val Loss for batch 240/1082 @epoch6/10: 0.14032 in 0.05 secs
Val Loss for batch 320/1082 @epoch6/10: 0.17 in 0.05 secs
Val Loss for batch 400/1082 @epoch6/10: 0.10266 in 0.05 secs
Val Loss for batch 480/1082 @epoch6/10: 0.16656 in 0.05 secs
Val Loss for batch 560/1082 @epoch6/10: 0.20743 in 0.05 secs
Val Loss for batch 640/1082 @epoch6/10: 0.24473 in 0.05 secs
Val Loss for batch 720/1082 @epoch6/10: 0.26941 in 0.05 secs
Val Loss for batch 800/1082 @epoch6/10: 0.33663 in 0.05 secs
Val Loss for batch 880/1082 @epoch6/10: 0.23061 in 0.05 secs
Val Loss for batch 960/1082 @epoch6/10: 0.23848 in 0.05 secs
Val Loss for batch 1040/1082 @epoch6/10: 0.17757 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7401034371329107, 'Cardiomegaly': 0.8691614363493173, 'Consolidation': 0.7212541175858798, 'Edema': 0.8482455446958357, 'Effusion': 0.854570608048327, 'Emphysema': 0.83164437284524, 'Fibrosis': 0.6642200266128951, 'Hernia': 0.8204862749874396, 'Infiltration': 0.6181387006207629, 'Mass': 0.7962648062447375, 'Nodule': 0.6619756635530926, 'Pleural_Thickening': 0.7189937228251714, 'Pneumonia': 0.6033992028819547, 'Pneumothorax': 0.7602205915964723, 'none': 0.7247197184856407}
AVG Loss in validation set: 0.2297971841159707
0.7506198932842884
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch7/10: 0.09386 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch7/10: 0.05894 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch7/10: 0.0951 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch7/10: 0.06558 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch7/10: 0.08427 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch7/10: 0.11126 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch7/10: 0.09438 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch7/10: 0.07365 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch7/10: 0.05313 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch7/10: 0.07255 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch7/10: 0.04152 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch7/10: 0.05494 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch7/10: 0.11524 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch7/10: 0.06817 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch7/10: 0.04921 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch7/10: 0.04583 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch7/10: 0.06043 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch7/10: 0.05676 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch7/10: 0.09063 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch7/10: 0.0721 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch7/10: 0.04604 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch7/10: 0.07366 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch7/10: 0.03416 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch7/10: 0.07374 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch7/10: 0.0507 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch7/10: 0.10372 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch7/10: 0.06223 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch7/10: 0.09295 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch7/10: 0.04913 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch7/10: 0.07142 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch7/10: 0.05474 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch7/10: 0.08349 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch7/10: 0.04974 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch7/10: 0.03721 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch7/10: 0.09324 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch7/10: 0.03995 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch7/10: 0.10877 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch7/10: 0.10889 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch7/10: 0.06106 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch7/10: 0.09592 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch7/10: 0.0511 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch7/10: 0.06739 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch7/10: 0.08908 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch7/10: 0.0137 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch7/10: 0.06204 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch7/10: 0.04531 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch7/10: 0.02702 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch7/10: 0.03489 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch7/10: 0.03856 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch7/10: 0.01913 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch7/10: 0.05108 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch7/10: 0.10911 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch7/10: 0.0635 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch7/10: 0.03218 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch7/10: 0.11473 in 0.05 secs
Val Loss for batch 160/1082 @epoch7/10: 0.23315 in 0.05 secs
Val Loss for batch 240/1082 @epoch7/10: 0.14192 in 0.05 secs
Val Loss for batch 320/1082 @epoch7/10: 0.16316 in 0.05 secs
Val Loss for batch 400/1082 @epoch7/10: 0.08866 in 0.05 secs
Val Loss for batch 480/1082 @epoch7/10: 0.15713 in 0.05 secs
Val Loss for batch 560/1082 @epoch7/10: 0.20309 in 0.05 secs
Val Loss for batch 640/1082 @epoch7/10: 0.27908 in 0.05 secs
Val Loss for batch 720/1082 @epoch7/10: 0.29616 in 0.05 secs
Val Loss for batch 800/1082 @epoch7/10: 0.34855 in 0.05 secs
Val Loss for batch 880/1082 @epoch7/10: 0.2213 in 0.05 secs
Val Loss for batch 960/1082 @epoch7/10: 0.24083 in 0.05 secs
Val Loss for batch 1040/1082 @epoch7/10: 0.19916 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7377646594479159, 'Cardiomegaly': 0.8629957411382436, 'Consolidation': 0.7109339836892493, 'Edema': 0.8481407671892484, 'Effusion': 0.8614403277364933, 'Emphysema': 0.8256302300981346, 'Fibrosis': 0.6554492995242239, 'Hernia': 0.7702967282249592, 'Infiltration': 0.6200997474838706, 'Mass': 0.7884497838019207, 'Nodule': 0.6697581001578713, 'Pleural_Thickening': 0.724092762914919, 'Pneumonia': 0.6177830496463095, 'Pneumothorax': 0.7624755907078697, 'none': 0.7357062244151635}
AVG Loss in validation set: 0.22458344529513347
0.7468079122686592
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch8/10: 0.05804 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch8/10: 0.06136 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch8/10: 0.06838 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch8/10: 0.08594 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch8/10: 0.0471 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch8/10: 0.0777 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch8/10: 0.04082 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch8/10: 0.0773 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch8/10: 0.05852 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch8/10: 0.08934 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch8/10: 0.05267 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch8/10: 0.06411 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch8/10: 0.04973 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch8/10: 0.07851 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch8/10: 0.05435 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch8/10: 0.08351 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch8/10: 0.06842 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch8/10: 0.05066 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch8/10: 0.04359 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch8/10: 0.07518 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch8/10: 0.14316 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch8/10: 0.06888 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch8/10: 0.08049 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch8/10: 0.06095 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch8/10: 0.05225 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch8/10: 0.05261 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch8/10: 0.03316 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch8/10: 0.07212 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch8/10: 0.09727 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch8/10: 0.02411 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch8/10: 0.07742 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch8/10: 0.04411 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch8/10: 0.08972 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch8/10: 0.09912 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch8/10: 0.05053 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch8/10: 0.02708 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch8/10: 0.05327 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch8/10: 0.06051 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch8/10: 0.05614 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch8/10: 0.03468 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch8/10: 0.07232 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch8/10: 0.08217 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch8/10: 0.06186 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch8/10: 0.05192 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch8/10: 0.06048 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch8/10: 0.03312 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch8/10: 0.06673 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch8/10: 0.04379 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch8/10: 0.053 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch8/10: 0.02508 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch8/10: 0.05715 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch8/10: 0.05947 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch8/10: 0.03853 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch8/10: 0.04089 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch8/10: 0.13438 in 0.05 secs
Val Loss for batch 160/1082 @epoch8/10: 0.24419 in 0.05 secs
Val Loss for batch 240/1082 @epoch8/10: 0.13821 in 0.05 secs
Val Loss for batch 320/1082 @epoch8/10: 0.14623 in 0.05 secs
Val Loss for batch 400/1082 @epoch8/10: 0.09583 in 0.05 secs
Val Loss for batch 480/1082 @epoch8/10: 0.19615 in 0.05 secs
Val Loss for batch 560/1082 @epoch8/10: 0.21156 in 0.05 secs
Val Loss for batch 640/1082 @epoch8/10: 0.308 in 0.05 secs
Val Loss for batch 720/1082 @epoch8/10: 0.3284 in 0.05 secs
Val Loss for batch 800/1082 @epoch8/10: 0.33569 in 0.05 secs
Val Loss for batch 880/1082 @epoch8/10: 0.20746 in 0.05 secs
Val Loss for batch 960/1082 @epoch8/10: 0.23381 in 0.05 secs
Val Loss for batch 1040/1082 @epoch8/10: 0.21881 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7350477204796727, 'Cardiomegaly': 0.8523068139662676, 'Consolidation': 0.7337683733540862, 'Edema': 0.8449571072877623, 'Effusion': 0.852883972364852, 'Emphysema': 0.8244713131884401, 'Fibrosis': 0.6804307223409161, 'Hernia': 0.7565214743540947, 'Infiltration': 0.6287789984095559, 'Mass': 0.7827769582861159, 'Nodule': 0.6661026032844645, 'Pleural_Thickening': 0.7227468140083867, 'Pneumonia': 0.6143754204171115, 'Pneumothorax': 0.7686468772525308, 'none': 0.730995203055788}
AVG Loss in validation set: 0.22954915347498323
0.7474153692138755
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch9/10: 0.05011 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch9/10: 0.06933 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch9/10: 0.02819 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch9/10: 0.03185 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch9/10: 0.09701 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch9/10: 0.05982 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch9/10: 0.03809 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch9/10: 0.07153 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch9/10: 0.03442 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch9/10: 0.07949 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch9/10: 0.13098 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch9/10: 0.05481 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch9/10: 0.08165 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch9/10: 0.06171 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch9/10: 0.05215 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch9/10: 0.03856 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch9/10: 0.05073 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch9/10: 0.06924 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch9/10: 0.03657 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch9/10: 0.02571 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch9/10: 0.04628 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch9/10: 0.03864 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch9/10: 0.01615 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch9/10: 0.04714 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch9/10: 0.06872 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch9/10: 0.07892 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch9/10: 0.05703 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch9/10: 0.03228 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch9/10: 0.0612 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch9/10: 0.04077 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch9/10: 0.05193 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch9/10: 0.04407 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch9/10: 0.06123 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch9/10: 0.06757 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch9/10: 0.03143 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch9/10: 0.09226 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch9/10: 0.03871 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch9/10: 0.08038 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch9/10: 0.04394 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch9/10: 0.059 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch9/10: 0.06738 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch9/10: 0.02645 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch9/10: 0.05427 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch9/10: 0.04114 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch9/10: 0.04647 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch9/10: 0.05117 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch9/10: 0.08499 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch9/10: 0.00951 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch9/10: 0.03372 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch9/10: 0.05533 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch9/10: 0.02728 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch9/10: 0.05206 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch9/10: 0.05634 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch9/10: 0.07257 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch9/10: 0.14594 in 0.05 secs
Val Loss for batch 160/1082 @epoch9/10: 0.2616 in 0.05 secs
Val Loss for batch 240/1082 @epoch9/10: 0.12132 in 0.05 secs
Val Loss for batch 320/1082 @epoch9/10: 0.14107 in 0.05 secs
Val Loss for batch 400/1082 @epoch9/10: 0.08755 in 0.05 secs
Val Loss for batch 480/1082 @epoch9/10: 0.18087 in 0.05 secs
Val Loss for batch 560/1082 @epoch9/10: 0.23425 in 0.05 secs
Val Loss for batch 640/1082 @epoch9/10: 0.30699 in 0.05 secs
Val Loss for batch 720/1082 @epoch9/10: 0.32939 in 0.05 secs
Val Loss for batch 800/1082 @epoch9/10: 0.32785 in 0.05 secs
Val Loss for batch 880/1082 @epoch9/10: 0.2167 in 0.05 secs
Val Loss for batch 960/1082 @epoch9/10: 0.22308 in 0.05 secs
Val Loss for batch 1040/1082 @epoch9/10: 0.18374 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.745129546105668, 'Cardiomegaly': 0.8585409315215773, 'Consolidation': 0.7342034432611461, 'Edema': 0.841177003748114, 'Effusion': 0.8537486048754481, 'Emphysema': 0.8208917338147237, 'Fibrosis': 0.6805411167411118, 'Hernia': 0.8420321848880227, 'Infiltration': 0.6279784950833518, 'Mass': 0.7914277303316726, 'Nodule': 0.6653379138470457, 'Pleural_Thickening': 0.7210269169960736, 'Pneumonia': 0.6149368167996877, 'Pneumothorax': 0.7681276803309244, 'none': 0.7255067897008535}
AVG Loss in validation set: 0.22688570017898407
0.7546500084531834
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 080/4327 @epoch10/10: 0.05319 in 0 mins 0.18 secs
Train Loss for batch 160/4327 @epoch10/10: 0.02191 in 0 mins 0.18 secs
Train Loss for batch 240/4327 @epoch10/10: 0.02658 in 0 mins 0.18 secs
Train Loss for batch 320/4327 @epoch10/10: 0.02998 in 0 mins 0.18 secs
Train Loss for batch 400/4327 @epoch10/10: 0.03859 in 0 mins 0.18 secs
Train Loss for batch 480/4327 @epoch10/10: 0.08889 in 0 mins 0.18 secs
Train Loss for batch 560/4327 @epoch10/10: 0.06451 in 0 mins 0.18 secs
Train Loss for batch 640/4327 @epoch10/10: 0.03592 in 0 mins 0.18 secs
Train Loss for batch 720/4327 @epoch10/10: 0.04557 in 0 mins 0.18 secs
Train Loss for batch 800/4327 @epoch10/10: 0.03422 in 0 mins 0.18 secs
Train Loss for batch 880/4327 @epoch10/10: 0.05965 in 0 mins 0.18 secs
Train Loss for batch 960/4327 @epoch10/10: 0.05707 in 0 mins 0.18 secs
Train Loss for batch 1040/4327 @epoch10/10: 0.03647 in 0 mins 0.18 secs
Train Loss for batch 1120/4327 @epoch10/10: 0.06251 in 0 mins 0.18 secs
Train Loss for batch 1200/4327 @epoch10/10: 0.03786 in 0 mins 0.18 secs
Train Loss for batch 1280/4327 @epoch10/10: 0.0432 in 0 mins 0.18 secs
Train Loss for batch 1360/4327 @epoch10/10: 0.09051 in 0 mins 0.18 secs
Train Loss for batch 1440/4327 @epoch10/10: 0.029 in 0 mins 0.18 secs
Train Loss for batch 1520/4327 @epoch10/10: 0.02338 in 0 mins 0.18 secs
Train Loss for batch 1600/4327 @epoch10/10: 0.01693 in 0 mins 0.18 secs
Train Loss for batch 1680/4327 @epoch10/10: 0.01718 in 0 mins 0.18 secs
Train Loss for batch 1760/4327 @epoch10/10: 0.02881 in 0 mins 0.18 secs
Train Loss for batch 1840/4327 @epoch10/10: 0.06982 in 0 mins 0.18 secs
Train Loss for batch 1920/4327 @epoch10/10: 0.06139 in 0 mins 0.18 secs
Train Loss for batch 2000/4327 @epoch10/10: 0.04875 in 0 mins 0.18 secs
Train Loss for batch 2080/4327 @epoch10/10: 0.029 in 0 mins 0.18 secs
Train Loss for batch 2160/4327 @epoch10/10: 0.04432 in 0 mins 0.18 secs
Train Loss for batch 2240/4327 @epoch10/10: 0.02171 in 0 mins 0.18 secs
Train Loss for batch 2320/4327 @epoch10/10: 0.10956 in 0 mins 0.18 secs
Train Loss for batch 2400/4327 @epoch10/10: 0.01016 in 0 mins 0.18 secs
Train Loss for batch 2480/4327 @epoch10/10: 0.03533 in 0 mins 0.18 secs
Train Loss for batch 2560/4327 @epoch10/10: 0.02313 in 0 mins 0.18 secs
Train Loss for batch 2640/4327 @epoch10/10: 0.01832 in 0 mins 0.18 secs
Train Loss for batch 2720/4327 @epoch10/10: 0.04583 in 0 mins 0.18 secs
Train Loss for batch 2800/4327 @epoch10/10: 0.02321 in 0 mins 0.18 secs
Train Loss for batch 2880/4327 @epoch10/10: 0.03052 in 0 mins 0.18 secs
Train Loss for batch 2960/4327 @epoch10/10: 0.0635 in 0 mins 0.18 secs
Train Loss for batch 3040/4327 @epoch10/10: 0.04422 in 0 mins 0.18 secs
Train Loss for batch 3120/4327 @epoch10/10: 0.03392 in 0 mins 0.18 secs
Train Loss for batch 3200/4327 @epoch10/10: 0.00871 in 0 mins 0.18 secs
Train Loss for batch 3280/4327 @epoch10/10: 0.06406 in 0 mins 0.18 secs
Train Loss for batch 3360/4327 @epoch10/10: 0.04734 in 0 mins 0.18 secs
Train Loss for batch 3440/4327 @epoch10/10: 0.02656 in 0 mins 0.18 secs
Train Loss for batch 3520/4327 @epoch10/10: 0.03707 in 0 mins 0.18 secs
Train Loss for batch 3600/4327 @epoch10/10: 0.07125 in 0 mins 0.18 secs
Train Loss for batch 3680/4327 @epoch10/10: 0.03528 in 0 mins 0.18 secs
Train Loss for batch 3760/4327 @epoch10/10: 0.09782 in 0 mins 0.18 secs
Train Loss for batch 3840/4327 @epoch10/10: 0.02257 in 0 mins 0.18 secs
Train Loss for batch 3920/4327 @epoch10/10: 0.07523 in 0 mins 0.18 secs
Train Loss for batch 4000/4327 @epoch10/10: 0.03776 in 0 mins 0.18 secs
Train Loss for batch 4080/4327 @epoch10/10: 0.0314 in 0 mins 0.18 secs
Train Loss for batch 4160/4327 @epoch10/10: 0.04199 in 0 mins 0.18 secs
Train Loss for batch 4240/4327 @epoch10/10: 0.0286 in 0 mins 0.18 secs
Train Loss for batch 4320/4327 @epoch10/10: 0.02345 in 0 mins 0.18 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 080/1082 @epoch10/10: 0.13641 in 0.05 secs
Val Loss for batch 160/1082 @epoch10/10: 0.24287 in 0.05 secs
Val Loss for batch 240/1082 @epoch10/10: 0.13765 in 0.05 secs
Val Loss for batch 320/1082 @epoch10/10: 0.15774 in 0.05 secs
Val Loss for batch 400/1082 @epoch10/10: 0.07534 in 0.05 secs
Val Loss for batch 480/1082 @epoch10/10: 0.20839 in 0.05 secs
Val Loss for batch 560/1082 @epoch10/10: 0.20363 in 0.05 secs
Val Loss for batch 640/1082 @epoch10/10: 0.28411 in 0.05 secs
Val Loss for batch 720/1082 @epoch10/10: 0.32197 in 0.05 secs
Val Loss for batch 800/1082 @epoch10/10: 0.36327 in 0.05 secs
Val Loss for batch 880/1082 @epoch10/10: 0.22494 in 0.05 secs
Val Loss for batch 960/1082 @epoch10/10: 0.24951 in 0.05 secs
Val Loss for batch 1040/1082 @epoch10/10: 0.20557 in 0.05 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7436752954888509, 'Cardiomegaly': 0.8482441453117288, 'Consolidation': 0.7276584542085001, 'Edema': 0.840021205854652, 'Effusion': 0.8564215179721151, 'Emphysema': 0.8091496547147411, 'Fibrosis': 0.6676682883615424, 'Hernia': 0.8038914178706819, 'Infiltration': 0.6347877472574672, 'Mass': 0.782514940775021, 'Nodule': 0.6798516602702724, 'Pleural_Thickening': 0.7173482190225948, 'Pneumonia': 0.6201280228620484, 'Pneumothorax': 0.7583487443213177, 'none': 0.7267429849631981}
AVG Loss in validation set: 0.23747027162126627
0.7492649510208238
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/1/ft_dense161_adam_steplr_0/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/10: 0.2883 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch1/10: 0.27225 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch1/10: 0.25819 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch1/10: 0.24361 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch1/10: 0.2165 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch1/10: 0.21773 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch1/10: 0.21913 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch1/10: 0.22602 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch1/10: 0.21971 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch1/10: 0.22723 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch1/10: 0.20954 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch1/10: 0.22403 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch1/10: 0.20516 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch1/10: 0.20326 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch1/10: 0.19373 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch1/10: 0.2106 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch1/10: 0.19327 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch1/10: 0.21788 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch1/10: 0.21682 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch1/10: 0.20984 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch1/10: 0.20433 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch1/10: 0.19702 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch1/10: 0.20588 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch1/10: 0.2099 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch1/10: 0.18933 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch1/10: 0.18802 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch1/10: 0.19867 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch1/10: 0.19458 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch1/10: 0.20394 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch1/10: 0.18382 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch1/10: 0.19314 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch1/10: 0.17992 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch1/10: 0.18229 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch1/10: 0.18537 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch1/10: 0.19837 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch1/10: 0.18351 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch1/10: 0.1835 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch1/10: 0.19818 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch1/10: 0.17947 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch1/10: 0.19669 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch1/10: 0.16461 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch1/10: 0.19443 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch1/10: 0.19005 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch1/10: 0.17338 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch1/10: 0.18903 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch1/10: 0.18378 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch1/10: 0.15969 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch1/10: 0.17724 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch1/10: 0.17848 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch1/10: 0.16929 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch1/10: 0.1855 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch1/10: 0.17196 in 0 mins 0.24 secs
Train Loss for batch 530/541 @epoch1/10: 0.16843 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch1/10: 0.18014 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/10: 0.20587 in 0.08 secs
Val Loss for batch 020/136 @epoch1/10: 0.23739 in 0.09 secs
Val Loss for batch 030/136 @epoch1/10: 0.22982 in 0.09 secs
Val Loss for batch 040/136 @epoch1/10: 0.19064 in 0.09 secs
Val Loss for batch 050/136 @epoch1/10: 0.21024 in 0.09 secs
Val Loss for batch 060/136 @epoch1/10: 0.18995 in 0.09 secs
Val Loss for batch 070/136 @epoch1/10: 0.2324 in 0.09 secs
Val Loss for batch 080/136 @epoch1/10: 0.2144 in 0.09 secs
Val Loss for batch 090/136 @epoch1/10: 0.20248 in 0.09 secs
Val Loss for batch 100/136 @epoch1/10: 0.24164 in 0.09 secs
Val Loss for batch 110/136 @epoch1/10: 0.24442 in 0.09 secs
Val Loss for batch 120/136 @epoch1/10: 0.22712 in 0.09 secs
Val Loss for batch 130/136 @epoch1/10: 0.21381 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7411704971738504, 'Cardiomegaly': 0.8930008601432569, 'Consolidation': 0.7557517317620309, 'Edema': 0.8573574788306553, 'Effusion': 0.8679910359656791, 'Emphysema': 0.8104603390869768, 'Fibrosis': 0.7104049052859248, 'Hernia': 0.7825403833564241, 'Infiltration': 0.61053189308217, 'Mass': 0.6704376032717765, 'Nodule': 0.6603699056677466, 'Pleural_Thickening': 0.6925553274721703, 'Pneumonia': 0.6284081693796624, 'Pneumothorax': 0.7583000866564646, 'none': 0.7345125915778351}
AVG Loss in validation set: 0.22614836820258732
0.7456628726524849
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/10: 0.18496 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch2/10: 0.19204 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch2/10: 0.15964 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch2/10: 0.18783 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch2/10: 0.16767 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch2/10: 0.16367 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch2/10: 0.18145 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch2/10: 0.17226 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch2/10: 0.15259 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch2/10: 0.15688 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch2/10: 0.14859 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch2/10: 0.17108 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch2/10: 0.13956 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch2/10: 0.16708 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch2/10: 0.15422 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch2/10: 0.17582 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch2/10: 0.165 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch2/10: 0.17207 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch2/10: 0.14353 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch2/10: 0.15852 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch2/10: 0.15636 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch2/10: 0.14571 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch2/10: 0.13485 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch2/10: 0.1759 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch2/10: 0.14606 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch2/10: 0.14921 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch2/10: 0.1597 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch2/10: 0.135 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch2/10: 0.16366 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch2/10: 0.15379 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch2/10: 0.15019 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch2/10: 0.13651 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch2/10: 0.14882 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch2/10: 0.13946 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch2/10: 0.14855 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch2/10: 0.14866 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch2/10: 0.14668 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch2/10: 0.15332 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch2/10: 0.14118 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch2/10: 0.14117 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch2/10: 0.15571 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch2/10: 0.14023 in 0 mins 0.24 secs
Train Loss for batch 430/541 @epoch2/10: 0.15274 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch2/10: 0.13962 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch2/10: 0.15378 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch2/10: 0.12034 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch2/10: 0.14307 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch2/10: 0.16022 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch2/10: 0.13424 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch2/10: 0.12895 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch2/10: 0.1409 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch2/10: 0.14528 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch2/10: 0.12498 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch2/10: 0.12623 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/10: 0.22074 in 0.09 secs
Val Loss for batch 020/136 @epoch2/10: 0.25093 in 0.09 secs
Val Loss for batch 030/136 @epoch2/10: 0.24956 in 0.09 secs
Val Loss for batch 040/136 @epoch2/10: 0.22116 in 0.09 secs
Val Loss for batch 050/136 @epoch2/10: 0.24348 in 0.09 secs
Val Loss for batch 060/136 @epoch2/10: 0.21493 in 0.09 secs
Val Loss for batch 070/136 @epoch2/10: 0.26336 in 0.09 secs
Val Loss for batch 080/136 @epoch2/10: 0.23016 in 0.09 secs
Val Loss for batch 090/136 @epoch2/10: 0.20417 in 0.09 secs
Val Loss for batch 100/136 @epoch2/10: 0.24715 in 0.09 secs
Val Loss for batch 110/136 @epoch2/10: 0.26199 in 0.09 secs
Val Loss for batch 120/136 @epoch2/10: 0.25954 in 0.09 secs
Val Loss for batch 130/136 @epoch2/10: 0.26011 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7102975894499378, 'Cardiomegaly': 0.8565086979759248, 'Consolidation': 0.7315414699400541, 'Edema': 0.842014644279206, 'Effusion': 0.8487425877425143, 'Emphysema': 0.8169778661342428, 'Fibrosis': 0.7069642608645825, 'Hernia': 0.7600079168125695, 'Infiltration': 0.6224595469401812, 'Mass': 0.7333836107295024, 'Nodule': 0.6284128377378347, 'Pleural_Thickening': 0.7273573430921015, 'Pneumonia': 0.6151597188912944, 'Pneumothorax': 0.7599086806910568, 'none': 0.7000848868251566}
AVG Loss in validation set: 0.24521478185954604
0.739981197948643
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/10: 0.12732 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch3/10: 0.12962 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch3/10: 0.13429 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch3/10: 0.14978 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch3/10: 0.11888 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch3/10: 0.11945 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch3/10: 0.11563 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch3/10: 0.10561 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch3/10: 0.12283 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch3/10: 0.12852 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch3/10: 0.13198 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch3/10: 0.13702 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch3/10: 0.12998 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch3/10: 0.13076 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch3/10: 0.13504 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch3/10: 0.12582 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch3/10: 0.11399 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch3/10: 0.11094 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch3/10: 0.12623 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch3/10: 0.13336 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch3/10: 0.12393 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch3/10: 0.13319 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch3/10: 0.1185 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch3/10: 0.1433 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch3/10: 0.1275 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch3/10: 0.12575 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch3/10: 0.11512 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch3/10: 0.13973 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch3/10: 0.12567 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch3/10: 0.10302 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch3/10: 0.13508 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch3/10: 0.11669 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch3/10: 0.12538 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch3/10: 0.09271 in 0 mins 0.24 secs
Train Loss for batch 350/541 @epoch3/10: 0.10962 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch3/10: 0.10898 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch3/10: 0.09679 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch3/10: 0.11287 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch3/10: 0.10216 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch3/10: 0.09512 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch3/10: 0.12412 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch3/10: 0.09312 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch3/10: 0.12162 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch3/10: 0.11051 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch3/10: 0.10534 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch3/10: 0.09159 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch3/10: 0.11795 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch3/10: 0.09583 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch3/10: 0.10854 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch3/10: 0.10837 in 0 mins 0.24 secs
Train Loss for batch 510/541 @epoch3/10: 0.10147 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch3/10: 0.11273 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch3/10: 0.11672 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch3/10: 0.11003 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/10: 0.17108 in 0.09 secs
Val Loss for batch 020/136 @epoch3/10: 0.20328 in 0.09 secs
Val Loss for batch 030/136 @epoch3/10: 0.1836 in 0.09 secs
Val Loss for batch 040/136 @epoch3/10: 0.17135 in 0.09 secs
Val Loss for batch 050/136 @epoch3/10: 0.19703 in 0.09 secs
Val Loss for batch 060/136 @epoch3/10: 0.15387 in 0.09 secs
Val Loss for batch 070/136 @epoch3/10: 0.21937 in 0.09 secs
Val Loss for batch 080/136 @epoch3/10: 0.18333 in 0.09 secs
Val Loss for batch 090/136 @epoch3/10: 0.1618 in 0.09 secs
Val Loss for batch 100/136 @epoch3/10: 0.20426 in 0.09 secs
Val Loss for batch 110/136 @epoch3/10: 0.20749 in 0.09 secs
Val Loss for batch 120/136 @epoch3/10: 0.18941 in 0.09 secs
Val Loss for batch 130/136 @epoch3/10: 0.20473 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7503268871183415, 'Cardiomegaly': 0.8596887429139548, 'Consolidation': 0.7314374655933896, 'Edema': 0.8731893137142861, 'Effusion': 0.8689128714555027, 'Emphysema': 0.8500345142441477, 'Fibrosis': 0.7474522882451224, 'Hernia': 0.9194159828266065, 'Infiltration': 0.602764979860529, 'Mass': 0.78867678387156, 'Nodule': 0.7038758140242398, 'Pleural_Thickening': 0.7362058405937185, 'Pneumonia': 0.6460482231930528, 'Pneumothorax': 0.7832371944426837, 'none': 0.7381534847412777}
AVG Loss in validation set: 0.20195438888852266
0.7758047787212239
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/10: 0.11263 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch4/10: 0.11731 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch4/10: 0.09701 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch4/10: 0.09119 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch4/10: 0.09038 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch4/10: 0.11486 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch4/10: 0.09859 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch4/10: 0.10326 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch4/10: 0.12778 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch4/10: 0.10253 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch4/10: 0.11558 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch4/10: 0.10391 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch4/10: 0.12011 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch4/10: 0.09074 in 0 mins 0.24 secs
Train Loss for batch 150/541 @epoch4/10: 0.07736 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch4/10: 0.10191 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch4/10: 0.08494 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch4/10: 0.09128 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch4/10: 0.09923 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch4/10: 0.08495 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch4/10: 0.08489 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch4/10: 0.09295 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch4/10: 0.09335 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch4/10: 0.10503 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch4/10: 0.10358 in 0 mins 0.24 secs
Train Loss for batch 260/541 @epoch4/10: 0.08868 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch4/10: 0.10653 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch4/10: 0.10783 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch4/10: 0.0898 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch4/10: 0.09442 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch4/10: 0.11702 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch4/10: 0.08998 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch4/10: 0.07942 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch4/10: 0.09301 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch4/10: 0.10603 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch4/10: 0.09148 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch4/10: 0.09838 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch4/10: 0.11192 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch4/10: 0.09927 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch4/10: 0.09289 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch4/10: 0.07278 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch4/10: 0.08816 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch4/10: 0.1157 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch4/10: 0.08374 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch4/10: 0.10457 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch4/10: 0.10759 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch4/10: 0.10981 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch4/10: 0.07939 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch4/10: 0.08635 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch4/10: 0.08993 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch4/10: 0.09088 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch4/10: 0.11493 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch4/10: 0.10063 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch4/10: 0.08068 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/10: 0.18907 in 0.09 secs
Val Loss for batch 020/136 @epoch4/10: 0.20941 in 0.09 secs
Val Loss for batch 030/136 @epoch4/10: 0.19845 in 0.09 secs
Val Loss for batch 040/136 @epoch4/10: 0.17676 in 0.09 secs
Val Loss for batch 050/136 @epoch4/10: 0.20099 in 0.09 secs
Val Loss for batch 060/136 @epoch4/10: 0.1627 in 0.09 secs
Val Loss for batch 070/136 @epoch4/10: 0.22443 in 0.09 secs
Val Loss for batch 080/136 @epoch4/10: 0.19635 in 0.09 secs
Val Loss for batch 090/136 @epoch4/10: 0.16863 in 0.09 secs
Val Loss for batch 100/136 @epoch4/10: 0.20233 in 0.09 secs
Val Loss for batch 110/136 @epoch4/10: 0.23227 in 0.08 secs
Val Loss for batch 120/136 @epoch4/10: 0.20264 in 0.09 secs
Val Loss for batch 130/136 @epoch4/10: 0.19734 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.736708346746828, 'Cardiomegaly': 0.8810427270971939, 'Consolidation': 0.7320639572936635, 'Edema': 0.8684319049362027, 'Effusion': 0.8631422647860222, 'Emphysema': 0.84846390190909, 'Fibrosis': 0.7150523844735677, 'Hernia': 0.8306989632020462, 'Infiltration': 0.6046520893346308, 'Mass': 0.7911699861354674, 'Nodule': 0.6879107058062951, 'Pleural_Thickening': 0.7529249546934781, 'Pneumonia': 0.6729824659957276, 'Pneumothorax': 0.7918362911775035, 'none': 0.7327676215834849}
AVG Loss in validation set: 0.21036817110003667
0.7697914959705512
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/10: 0.0945 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch5/10: 0.08966 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch5/10: 0.08926 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch5/10: 0.1053 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch5/10: 0.07689 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch5/10: 0.07671 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch5/10: 0.07248 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch5/10: 0.07602 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch5/10: 0.0664 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch5/10: 0.07066 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch5/10: 0.08185 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch5/10: 0.0598 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch5/10: 0.08138 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch5/10: 0.08191 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch5/10: 0.08713 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch5/10: 0.07479 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch5/10: 0.07207 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch5/10: 0.06129 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch5/10: 0.08597 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch5/10: 0.08895 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch5/10: 0.0775 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch5/10: 0.07868 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch5/10: 0.08658 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch5/10: 0.05984 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch5/10: 0.09295 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch5/10: 0.08661 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch5/10: 0.08151 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch5/10: 0.07304 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch5/10: 0.07542 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch5/10: 0.09147 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch5/10: 0.06286 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch5/10: 0.07665 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch5/10: 0.08422 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch5/10: 0.08302 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch5/10: 0.0729 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch5/10: 0.06114 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch5/10: 0.07915 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch5/10: 0.06301 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch5/10: 0.06482 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch5/10: 0.08316 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch5/10: 0.07361 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch5/10: 0.07237 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch5/10: 0.09659 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch5/10: 0.08719 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch5/10: 0.08744 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch5/10: 0.06507 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch5/10: 0.06327 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch5/10: 0.07875 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch5/10: 0.06983 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch5/10: 0.0686 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch5/10: 0.06078 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch5/10: 0.06786 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch5/10: 0.05456 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch5/10: 0.06262 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/10: 0.17212 in 0.09 secs
Val Loss for batch 020/136 @epoch5/10: 0.20357 in 0.09 secs
Val Loss for batch 030/136 @epoch5/10: 0.18611 in 0.09 secs
Val Loss for batch 040/136 @epoch5/10: 0.16377 in 0.09 secs
Val Loss for batch 050/136 @epoch5/10: 0.1979 in 0.09 secs
Val Loss for batch 060/136 @epoch5/10: 0.16457 in 0.08 secs
Val Loss for batch 070/136 @epoch5/10: 0.22758 in 0.09 secs
Val Loss for batch 080/136 @epoch5/10: 0.19063 in 0.08 secs
Val Loss for batch 090/136 @epoch5/10: 0.16624 in 0.09 secs
Val Loss for batch 100/136 @epoch5/10: 0.19372 in 0.09 secs
Val Loss for batch 110/136 @epoch5/10: 0.22238 in 0.09 secs
Val Loss for batch 120/136 @epoch5/10: 0.19661 in 0.09 secs
Val Loss for batch 130/136 @epoch5/10: 0.1979 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7378754734938147, 'Cardiomegaly': 0.8584562414993205, 'Consolidation': 0.7168855427682013, 'Edema': 0.8664163287862522, 'Effusion': 0.857076967977822, 'Emphysema': 0.8588101773698908, 'Fibrosis': 0.7100573505162047, 'Hernia': 0.8619521032839548, 'Infiltration': 0.6254608730462666, 'Mass': 0.8030206005431858, 'Nodule': 0.6616386708793105, 'Pleural_Thickening': 0.74356858809484, 'Pneumonia': 0.644014556694913, 'Pneumothorax': 0.7862012208273571, 'none': 0.7400205215967055}
AVG Loss in validation set: 0.20638684668008564
0.7665310496986667
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch6/10: 0.07147 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch6/10: 0.07247 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch6/10: 0.05997 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch6/10: 0.06425 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch6/10: 0.07178 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch6/10: 0.08741 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch6/10: 0.08444 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch6/10: 0.0719 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch6/10: 0.08204 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch6/10: 0.08249 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch6/10: 0.08244 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch6/10: 0.05273 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch6/10: 0.07218 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch6/10: 0.0766 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch6/10: 0.07474 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch6/10: 0.08262 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch6/10: 0.07592 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch6/10: 0.07236 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch6/10: 0.06349 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch6/10: 0.06655 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch6/10: 0.07137 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch6/10: 0.05449 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch6/10: 0.05485 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch6/10: 0.06741 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch6/10: 0.08545 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch6/10: 0.05953 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch6/10: 0.06769 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch6/10: 0.05706 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch6/10: 0.06373 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch6/10: 0.07754 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch6/10: 0.06995 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch6/10: 0.06791 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch6/10: 0.07917 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch6/10: 0.0709 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch6/10: 0.0711 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch6/10: 0.07055 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch6/10: 0.06231 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch6/10: 0.0565 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch6/10: 0.06973 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch6/10: 0.08152 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch6/10: 0.06251 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch6/10: 0.07446 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch6/10: 0.06593 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch6/10: 0.04658 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch6/10: 0.07435 in 0 mins 0.24 secs
Train Loss for batch 460/541 @epoch6/10: 0.0643 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch6/10: 0.06549 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch6/10: 0.07765 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch6/10: 0.06551 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch6/10: 0.07772 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch6/10: 0.0682 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch6/10: 0.07689 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch6/10: 0.08638 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch6/10: 0.05596 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch6/10: 0.17889 in 0.09 secs
Val Loss for batch 020/136 @epoch6/10: 0.21241 in 0.09 secs
Val Loss for batch 030/136 @epoch6/10: 0.19225 in 0.09 secs
Val Loss for batch 040/136 @epoch6/10: 0.17001 in 0.09 secs
Val Loss for batch 050/136 @epoch6/10: 0.17279 in 0.09 secs
Val Loss for batch 060/136 @epoch6/10: 0.16906 in 0.09 secs
Val Loss for batch 070/136 @epoch6/10: 0.22932 in 0.09 secs
Val Loss for batch 080/136 @epoch6/10: 0.19168 in 0.09 secs
Val Loss for batch 090/136 @epoch6/10: 0.16052 in 0.09 secs
Val Loss for batch 100/136 @epoch6/10: 0.21368 in 0.09 secs
Val Loss for batch 110/136 @epoch6/10: 0.22288 in 0.08 secs
Val Loss for batch 120/136 @epoch6/10: 0.19823 in 0.09 secs
Val Loss for batch 130/136 @epoch6/10: 0.19333 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7365975708797563, 'Cardiomegaly': 0.8661704725131012, 'Consolidation': 0.7158605732074045, 'Edema': 0.8704853817992662, 'Effusion': 0.8548315164477237, 'Emphysema': 0.8576562114690119, 'Fibrosis': 0.7017236533702238, 'Hernia': 0.9126531979355389, 'Infiltration': 0.6319067356233802, 'Mass': 0.7835232056825592, 'Nodule': 0.6676867129557301, 'Pleural_Thickening': 0.7411282133274839, 'Pneumonia': 0.6364495693920499, 'Pneumothorax': 0.7728589291015275, 'none': 0.7333446048889567}
AVG Loss in validation set: 0.2075491487442538
0.7678237102646255
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch7/10: 0.08461 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch7/10: 0.05409 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch7/10: 0.06708 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch7/10: 0.0552 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch7/10: 0.05281 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch7/10: 0.05571 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch7/10: 0.06667 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch7/10: 0.06303 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch7/10: 0.06282 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch7/10: 0.05966 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch7/10: 0.05364 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch7/10: 0.06943 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch7/10: 0.05943 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch7/10: 0.06419 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch7/10: 0.0776 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch7/10: 0.06272 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch7/10: 0.05458 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch7/10: 0.05119 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch7/10: 0.049 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch7/10: 0.08886 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch7/10: 0.05807 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch7/10: 0.05953 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch7/10: 0.04636 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch7/10: 0.05583 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch7/10: 0.05986 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch7/10: 0.05705 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch7/10: 0.07076 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch7/10: 0.05791 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch7/10: 0.06232 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch7/10: 0.0648 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch7/10: 0.07685 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch7/10: 0.06358 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch7/10: 0.05587 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch7/10: 0.07047 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch7/10: 0.0593 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch7/10: 0.06239 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch7/10: 0.05517 in 0 mins 0.24 secs
Train Loss for batch 380/541 @epoch7/10: 0.06681 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch7/10: 0.05736 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch7/10: 0.05738 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch7/10: 0.06497 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch7/10: 0.06106 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch7/10: 0.04302 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch7/10: 0.05045 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch7/10: 0.05718 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch7/10: 0.05285 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch7/10: 0.0547 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch7/10: 0.03629 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch7/10: 0.0675 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch7/10: 0.06425 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch7/10: 0.05533 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch7/10: 0.05945 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch7/10: 0.06352 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch7/10: 0.05857 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch7/10: 0.16498 in 0.09 secs
Val Loss for batch 020/136 @epoch7/10: 0.20583 in 0.09 secs
Val Loss for batch 030/136 @epoch7/10: 0.1924 in 0.09 secs
Val Loss for batch 040/136 @epoch7/10: 0.17264 in 0.09 secs
Val Loss for batch 050/136 @epoch7/10: 0.18251 in 0.09 secs
Val Loss for batch 060/136 @epoch7/10: 0.16445 in 0.09 secs
Val Loss for batch 070/136 @epoch7/10: 0.23655 in 0.09 secs
Val Loss for batch 080/136 @epoch7/10: 0.19387 in 0.09 secs
Val Loss for batch 090/136 @epoch7/10: 0.15735 in 0.09 secs
Val Loss for batch 100/136 @epoch7/10: 0.21342 in 0.08 secs
Val Loss for batch 110/136 @epoch7/10: 0.22126 in 0.08 secs
Val Loss for batch 120/136 @epoch7/10: 0.19621 in 0.09 secs
Val Loss for batch 130/136 @epoch7/10: 0.1986 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7325994268289032, 'Cardiomegaly': 0.8640492980946545, 'Consolidation': 0.736382042932277, 'Edema': 0.8683192459357572, 'Effusion': 0.8652252613871657, 'Emphysema': 0.8503643276006364, 'Fibrosis': 0.7107978229451178, 'Hernia': 0.8563829301341291, 'Infiltration': 0.6376140773376557, 'Mass': 0.7862756952841596, 'Nodule': 0.6658607471241921, 'Pleural_Thickening': 0.7425289991470548, 'Pneumonia': 0.6551724448362336, 'Pneumothorax': 0.7876179116501179, 'none': 0.7295700738285746}
AVG Loss in validation set: 0.20832723831750152
0.7685135879455753
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch8/10: 0.05603 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch8/10: 0.05267 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch8/10: 0.05852 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch8/10: 0.05795 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch8/10: 0.04693 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch8/10: 0.06331 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch8/10: 0.04894 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch8/10: 0.05525 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch8/10: 0.04839 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch8/10: 0.06185 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch8/10: 0.05147 in 0 mins 0.24 secs
Train Loss for batch 120/541 @epoch8/10: 0.05868 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch8/10: 0.0683 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch8/10: 0.07056 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch8/10: 0.04172 in 0 mins 0.24 secs
Train Loss for batch 160/541 @epoch8/10: 0.05072 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch8/10: 0.04007 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch8/10: 0.04645 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch8/10: 0.05597 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch8/10: 0.05696 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch8/10: 0.04215 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch8/10: 0.03995 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch8/10: 0.05307 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch8/10: 0.05922 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch8/10: 0.05309 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch8/10: 0.05675 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch8/10: 0.05427 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch8/10: 0.05758 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch8/10: 0.04194 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch8/10: 0.06146 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch8/10: 0.04872 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch8/10: 0.04626 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch8/10: 0.08051 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch8/10: 0.0484 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch8/10: 0.04412 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch8/10: 0.04584 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch8/10: 0.04823 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch8/10: 0.06258 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch8/10: 0.05247 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch8/10: 0.03991 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch8/10: 0.03908 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch8/10: 0.05667 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch8/10: 0.05161 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch8/10: 0.05257 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch8/10: 0.04672 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch8/10: 0.04752 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch8/10: 0.04621 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch8/10: 0.04746 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch8/10: 0.04316 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch8/10: 0.04298 in 0 mins 0.24 secs
Train Loss for batch 510/541 @epoch8/10: 0.05492 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch8/10: 0.04335 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch8/10: 0.05864 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch8/10: 0.05931 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch8/10: 0.17983 in 0.09 secs
Val Loss for batch 020/136 @epoch8/10: 0.2044 in 0.09 secs
Val Loss for batch 030/136 @epoch8/10: 0.209 in 0.09 secs
Val Loss for batch 040/136 @epoch8/10: 0.18083 in 0.09 secs
Val Loss for batch 050/136 @epoch8/10: 0.18662 in 0.09 secs
Val Loss for batch 060/136 @epoch8/10: 0.16436 in 0.09 secs
Val Loss for batch 070/136 @epoch8/10: 0.25556 in 0.09 secs
Val Loss for batch 080/136 @epoch8/10: 0.20294 in 0.08 secs
Val Loss for batch 090/136 @epoch8/10: 0.16143 in 0.09 secs
Val Loss for batch 100/136 @epoch8/10: 0.20838 in 0.09 secs
Val Loss for batch 110/136 @epoch8/10: 0.23583 in 0.09 secs
Val Loss for batch 120/136 @epoch8/10: 0.19784 in 0.09 secs
Val Loss for batch 130/136 @epoch8/10: 0.20136 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7401650768493977, 'Cardiomegaly': 0.8501693718698003, 'Consolidation': 0.7354561464775701, 'Edema': 0.8600953707118589, 'Effusion': 0.8539822619057651, 'Emphysema': 0.8594863709200593, 'Fibrosis': 0.6863781495943035, 'Hernia': 0.8809554983785759, 'Infiltration': 0.6315640444810543, 'Mass': 0.8030147049513474, 'Nodule': 0.6858408924357415, 'Pleural_Thickening': 0.7334721213758914, 'Pneumonia': 0.641537426665572, 'Pneumothorax': 0.7882994462517724, 'none': 0.72752567404414}
AVG Loss in validation set: 0.2155988300722945
0.7678869202049079
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch9/10: 0.03685 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch9/10: 0.0612 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch9/10: 0.04561 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch9/10: 0.05357 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch9/10: 0.05889 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch9/10: 0.0561 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch9/10: 0.04913 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch9/10: 0.05317 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch9/10: 0.0472 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch9/10: 0.04455 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch9/10: 0.06356 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch9/10: 0.0659 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch9/10: 0.0548 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch9/10: 0.04546 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch9/10: 0.06576 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch9/10: 0.05772 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch9/10: 0.05032 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch9/10: 0.04414 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch9/10: 0.05334 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch9/10: 0.04206 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch9/10: 0.04384 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch9/10: 0.05168 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch9/10: 0.05812 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch9/10: 0.05892 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch9/10: 0.04901 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch9/10: 0.04351 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch9/10: 0.02613 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch9/10: 0.04968 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch9/10: 0.0416 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch9/10: 0.04261 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch9/10: 0.0406 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch9/10: 0.05759 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch9/10: 0.04843 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch9/10: 0.04343 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch9/10: 0.04056 in 0 mins 0.24 secs
Train Loss for batch 360/541 @epoch9/10: 0.05138 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch9/10: 0.04609 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch9/10: 0.03883 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch9/10: 0.05929 in 0 mins 0.24 secs
Train Loss for batch 400/541 @epoch9/10: 0.04122 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch9/10: 0.04819 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch9/10: 0.03726 in 0 mins 0.24 secs
Train Loss for batch 430/541 @epoch9/10: 0.05941 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch9/10: 0.0363 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch9/10: 0.04115 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch9/10: 0.05209 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch9/10: 0.04973 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch9/10: 0.04194 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch9/10: 0.0389 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch9/10: 0.06454 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch9/10: 0.04298 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch9/10: 0.03725 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch9/10: 0.05099 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch9/10: 0.05744 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch9/10: 0.18305 in 0.09 secs
Val Loss for batch 020/136 @epoch9/10: 0.21098 in 0.09 secs
Val Loss for batch 030/136 @epoch9/10: 0.19125 in 0.09 secs
Val Loss for batch 040/136 @epoch9/10: 0.18194 in 0.09 secs
Val Loss for batch 050/136 @epoch9/10: 0.19414 in 0.09 secs
Val Loss for batch 060/136 @epoch9/10: 0.16556 in 0.09 secs
Val Loss for batch 070/136 @epoch9/10: 0.24617 in 0.08 secs
Val Loss for batch 080/136 @epoch9/10: 0.1906 in 0.09 secs
Val Loss for batch 090/136 @epoch9/10: 0.16939 in 0.09 secs
Val Loss for batch 100/136 @epoch9/10: 0.20317 in 0.09 secs
Val Loss for batch 110/136 @epoch9/10: 0.23866 in 0.09 secs
Val Loss for batch 120/136 @epoch9/10: 0.20003 in 0.09 secs
Val Loss for batch 130/136 @epoch9/10: 0.20002 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7463031823426894, 'Cardiomegaly': 0.8525203374586748, 'Consolidation': 0.7486284426783629, 'Edema': 0.8652569378588252, 'Effusion': 0.8505721255455062, 'Emphysema': 0.8589055795013001, 'Fibrosis': 0.6984931107527557, 'Hernia': 0.8877243731254663, 'Infiltration': 0.640185189199431, 'Mass': 0.7973289407876828, 'Nodule': 0.6866906330169054, 'Pleural_Thickening': 0.7373026449230599, 'Pneumonia': 0.6406432975969786, 'Pneumothorax': 0.7847027065771526, 'none': 0.7320351791410298}
AVG Loss in validation set: 0.21379884557348128
0.7710898215260564
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch10/10: 0.04263 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch10/10: 0.06065 in 0 mins 0.24 secs
Train Loss for batch 030/541 @epoch10/10: 0.04017 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch10/10: 0.05062 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch10/10: 0.04473 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch10/10: 0.05679 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch10/10: 0.03515 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch10/10: 0.04228 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch10/10: 0.05606 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch10/10: 0.04311 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch10/10: 0.0461 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch10/10: 0.03792 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch10/10: 0.03982 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch10/10: 0.03759 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch10/10: 0.04499 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch10/10: 0.05381 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch10/10: 0.0624 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch10/10: 0.04508 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch10/10: 0.05908 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch10/10: 0.05664 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch10/10: 0.04196 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch10/10: 0.04572 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch10/10: 0.04156 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch10/10: 0.03848 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch10/10: 0.04134 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch10/10: 0.04591 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch10/10: 0.02827 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch10/10: 0.04226 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch10/10: 0.04281 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch10/10: 0.04713 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch10/10: 0.04736 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch10/10: 0.03558 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch10/10: 0.04775 in 0 mins 0.24 secs
Train Loss for batch 340/541 @epoch10/10: 0.04157 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch10/10: 0.05014 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch10/10: 0.03736 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch10/10: 0.06154 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch10/10: 0.03437 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch10/10: 0.03621 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch10/10: 0.04931 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch10/10: 0.05046 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch10/10: 0.03288 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch10/10: 0.04189 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch10/10: 0.04076 in 0 mins 0.24 secs
Train Loss for batch 450/541 @epoch10/10: 0.03252 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch10/10: 0.05748 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch10/10: 0.04406 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch10/10: 0.06201 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch10/10: 0.03986 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch10/10: 0.04366 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch10/10: 0.0426 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch10/10: 0.04349 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch10/10: 0.02852 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch10/10: 0.04086 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch10/10: 0.18681 in 0.09 secs
Val Loss for batch 020/136 @epoch10/10: 0.21309 in 0.09 secs
Val Loss for batch 030/136 @epoch10/10: 0.20596 in 0.09 secs
Val Loss for batch 040/136 @epoch10/10: 0.18823 in 0.09 secs
Val Loss for batch 050/136 @epoch10/10: 0.18137 in 0.09 secs
Val Loss for batch 060/136 @epoch10/10: 0.16579 in 0.09 secs
Val Loss for batch 070/136 @epoch10/10: 0.2502 in 0.09 secs
Val Loss for batch 080/136 @epoch10/10: 0.19692 in 0.09 secs
Val Loss for batch 090/136 @epoch10/10: 0.16495 in 0.09 secs
Val Loss for batch 100/136 @epoch10/10: 0.22233 in 0.09 secs
Val Loss for batch 110/136 @epoch10/10: 0.23549 in 0.09 secs
Val Loss for batch 120/136 @epoch10/10: 0.19962 in 0.08 secs
Val Loss for batch 130/136 @epoch10/10: 0.2102 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7405452234316596, 'Cardiomegaly': 0.845124021016859, 'Consolidation': 0.7426702152172705, 'Edema': 0.854158403654417, 'Effusion': 0.8548081526597567, 'Emphysema': 0.8455257638121244, 'Fibrosis': 0.6967578381161054, 'Hernia': 0.9104212657765328, 'Infiltration': 0.6368154055110776, 'Mass': 0.7899280342118424, 'Nodule': 0.6798094237695078, 'Pleural_Thickening': 0.7306957879304615, 'Pneumonia': 0.6466807393867636, 'Pneumothorax': 0.787444336886034, 'none': 0.7232842221056068}
AVG Loss in validation set: 0.21881787679397116
0.7686703293843151
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_2/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/10: 0.53426 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch1/10: 0.42721 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch1/10: 0.35957 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch1/10: 0.31756 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch1/10: 0.28688 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch1/10: 0.27356 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch1/10: 0.26981 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch1/10: 0.27187 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch1/10: 0.26416 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch1/10: 0.26441 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch1/10: 0.2483 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch1/10: 0.25847 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch1/10: 0.24264 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch1/10: 0.23998 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch1/10: 0.23282 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch1/10: 0.24164 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch1/10: 0.22475 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch1/10: 0.2388 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch1/10: 0.23743 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch1/10: 0.23172 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch1/10: 0.22565 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch1/10: 0.22093 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch1/10: 0.22375 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch1/10: 0.2247 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch1/10: 0.22658 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch1/10: 0.21217 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch1/10: 0.21268 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch1/10: 0.2147 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch1/10: 0.21831 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch1/10: 0.20668 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch1/10: 0.20999 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch1/10: 0.20007 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch1/10: 0.20867 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch1/10: 0.20303 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch1/10: 0.21334 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch1/10: 0.20526 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch1/10: 0.20382 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch1/10: 0.211 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch1/10: 0.202 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch1/10: 0.21198 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch1/10: 0.18712 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch1/10: 0.20333 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch1/10: 0.20589 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch1/10: 0.19886 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch1/10: 0.21105 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch1/10: 0.19637 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch1/10: 0.18867 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch1/10: 0.19301 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch1/10: 0.18773 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch1/10: 0.17815 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch1/10: 0.19479 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch1/10: 0.19428 in 0 mins 0.24 secs
Train Loss for batch 530/541 @epoch1/10: 0.18023 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch1/10: 0.19671 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/10: 0.20149 in 0.08 secs
Val Loss for batch 020/136 @epoch1/10: 0.22692 in 0.09 secs
Val Loss for batch 030/136 @epoch1/10: 0.21325 in 0.09 secs
Val Loss for batch 040/136 @epoch1/10: 0.19869 in 0.09 secs
Val Loss for batch 050/136 @epoch1/10: 0.20971 in 0.09 secs
Val Loss for batch 060/136 @epoch1/10: 0.18527 in 0.09 secs
Val Loss for batch 070/136 @epoch1/10: 0.22551 in 0.09 secs
Val Loss for batch 080/136 @epoch1/10: 0.20286 in 0.09 secs
Val Loss for batch 090/136 @epoch1/10: 0.19862 in 0.09 secs
Val Loss for batch 100/136 @epoch1/10: 0.22149 in 0.09 secs
Val Loss for batch 110/136 @epoch1/10: 0.23245 in 0.09 secs
Val Loss for batch 120/136 @epoch1/10: 0.22194 in 0.09 secs
Val Loss for batch 130/136 @epoch1/10: 0.21757 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.754775579508782, 'Cardiomegaly': 0.8724885443665358, 'Consolidation': 0.7707334009959312, 'Edema': 0.8687643185301108, 'Effusion': 0.8713258719863587, 'Emphysema': 0.8414100473106978, 'Fibrosis': 0.7269284798907107, 'Hernia': 0.7175707565123397, 'Infiltration': 0.616538484272988, 'Mass': 0.7233884854738949, 'Nodule': 0.6700489056924139, 'Pleural_Thickening': 0.7488678820200332, 'Pneumonia': 0.6423458518604942, 'Pneumothorax': 0.7907087643473288, 'none': 0.7233024936105111}
AVG Loss in validation set: 0.21913826283733986
0.7582782409120443
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/10: 0.19356 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch2/10: 0.19395 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch2/10: 0.18327 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch2/10: 0.19945 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch2/10: 0.18875 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch2/10: 0.17586 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch2/10: 0.19044 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch2/10: 0.18423 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch2/10: 0.16993 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch2/10: 0.16461 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch2/10: 0.16006 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch2/10: 0.17656 in 0 mins 0.24 secs
Train Loss for batch 130/541 @epoch2/10: 0.16166 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch2/10: 0.16729 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch2/10: 0.16148 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch2/10: 0.18531 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch2/10: 0.16918 in 0 mins 0.24 secs
Train Loss for batch 180/541 @epoch2/10: 0.185 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch2/10: 0.1516 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch2/10: 0.18227 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch2/10: 0.16704 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch2/10: 0.15378 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch2/10: 0.14779 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch2/10: 0.18774 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch2/10: 0.15008 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch2/10: 0.15176 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch2/10: 0.16585 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch2/10: 0.14118 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch2/10: 0.16069 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch2/10: 0.15542 in 0 mins 0.24 secs
Train Loss for batch 310/541 @epoch2/10: 0.15551 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch2/10: 0.13797 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch2/10: 0.14558 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch2/10: 0.14233 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch2/10: 0.15975 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch2/10: 0.15504 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch2/10: 0.15313 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch2/10: 0.15824 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch2/10: 0.14624 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch2/10: 0.15235 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch2/10: 0.15486 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch2/10: 0.13283 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch2/10: 0.15201 in 0 mins 0.24 secs
Train Loss for batch 440/541 @epoch2/10: 0.1485 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch2/10: 0.15848 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch2/10: 0.13123 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch2/10: 0.14711 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch2/10: 0.1584 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch2/10: 0.13745 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch2/10: 0.13633 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch2/10: 0.14693 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch2/10: 0.14717 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch2/10: 0.13056 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch2/10: 0.12686 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/10: 0.19852 in 0.09 secs
Val Loss for batch 020/136 @epoch2/10: 0.23324 in 0.09 secs
Val Loss for batch 030/136 @epoch2/10: 0.22116 in 0.09 secs
Val Loss for batch 040/136 @epoch2/10: 0.20012 in 0.09 secs
Val Loss for batch 050/136 @epoch2/10: 0.20721 in 0.09 secs
Val Loss for batch 060/136 @epoch2/10: 0.18316 in 0.09 secs
Val Loss for batch 070/136 @epoch2/10: 0.22043 in 0.09 secs
Val Loss for batch 080/136 @epoch2/10: 0.20408 in 0.09 secs
Val Loss for batch 090/136 @epoch2/10: 0.18918 in 0.09 secs
Val Loss for batch 100/136 @epoch2/10: 0.21682 in 0.09 secs
Val Loss for batch 110/136 @epoch2/10: 0.23651 in 0.09 secs
Val Loss for batch 120/136 @epoch2/10: 0.23041 in 0.09 secs
Val Loss for batch 130/136 @epoch2/10: 0.22888 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7416007534667902, 'Cardiomegaly': 0.8684481926773214, 'Consolidation': 0.7512829070649435, 'Edema': 0.8441569038524974, 'Effusion': 0.8664470725939704, 'Emphysema': 0.8195659107809169, 'Fibrosis': 0.6972628555472788, 'Hernia': 0.8351902318712604, 'Infiltration': 0.6082866627086203, 'Mass': 0.7484229093993935, 'Nodule': 0.6486929746213553, 'Pleural_Thickening': 0.7269346363817151, 'Pneumonia': 0.6183291417657303, 'Pneumothorax': 0.7807385251643588, 'none': 0.7192212337891474}
AVG Loss in validation set: 0.21847221612158715
0.753954262706868
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/10: 0.14077 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch3/10: 0.13812 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch3/10: 0.14835 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch3/10: 0.16387 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch3/10: 0.11951 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch3/10: 0.13249 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch3/10: 0.12964 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch3/10: 0.12993 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch3/10: 0.13684 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch3/10: 0.14318 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch3/10: 0.14858 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch3/10: 0.14428 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch3/10: 0.13599 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch3/10: 0.14427 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch3/10: 0.14248 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch3/10: 0.12819 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch3/10: 0.12224 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch3/10: 0.12739 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch3/10: 0.12896 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch3/10: 0.13604 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch3/10: 0.12966 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch3/10: 0.14955 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch3/10: 0.13375 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch3/10: 0.1577 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch3/10: 0.13999 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch3/10: 0.1383 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch3/10: 0.12548 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch3/10: 0.14087 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch3/10: 0.13976 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch3/10: 0.12188 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch3/10: 0.14439 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch3/10: 0.12671 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch3/10: 0.13799 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch3/10: 0.11323 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch3/10: 0.12557 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch3/10: 0.12462 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch3/10: 0.11013 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch3/10: 0.13351 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch3/10: 0.11902 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch3/10: 0.11302 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch3/10: 0.13762 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch3/10: 0.11359 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch3/10: 0.13012 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch3/10: 0.12289 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch3/10: 0.12305 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch3/10: 0.11029 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch3/10: 0.13051 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch3/10: 0.11776 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch3/10: 0.12008 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch3/10: 0.11747 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch3/10: 0.11506 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch3/10: 0.12393 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch3/10: 0.13707 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch3/10: 0.10915 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/10: 0.17557 in 0.09 secs
Val Loss for batch 020/136 @epoch3/10: 0.22531 in 0.09 secs
Val Loss for batch 030/136 @epoch3/10: 0.22216 in 0.09 secs
Val Loss for batch 040/136 @epoch3/10: 0.18716 in 0.09 secs
Val Loss for batch 050/136 @epoch3/10: 0.19839 in 0.09 secs
Val Loss for batch 060/136 @epoch3/10: 0.17671 in 0.09 secs
Val Loss for batch 070/136 @epoch3/10: 0.22097 in 0.09 secs
Val Loss for batch 080/136 @epoch3/10: 0.18951 in 0.09 secs
Val Loss for batch 090/136 @epoch3/10: 0.17645 in 0.09 secs
Val Loss for batch 100/136 @epoch3/10: 0.21324 in 0.09 secs
Val Loss for batch 110/136 @epoch3/10: 0.21951 in 0.09 secs
Val Loss for batch 120/136 @epoch3/10: 0.20078 in 0.09 secs
Val Loss for batch 130/136 @epoch3/10: 0.20727 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7289596101605771, 'Cardiomegaly': 0.8490882661320187, 'Consolidation': 0.7026393008218136, 'Edema': 0.8405012815540822, 'Effusion': 0.8730765474296386, 'Emphysema': 0.8319477173469069, 'Fibrosis': 0.7080654762716844, 'Hernia': 0.8430583255941416, 'Infiltration': 0.6011201677513159, 'Mass': 0.7695987278183304, 'Nodule': 0.6639848362290123, 'Pleural_Thickening': 0.7140555597031937, 'Pneumonia': 0.6264434620908, 'Pneumothorax': 0.7628549786664506, 'none': 0.7261004966616048}
AVG Loss in validation set: 0.20684339358913528
0.7510995898264261
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/10: 0.12593 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch4/10: 0.12755 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch4/10: 0.11355 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch4/10: 0.10476 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch4/10: 0.10701 in 0 mins 0.24 secs
Train Loss for batch 060/541 @epoch4/10: 0.12181 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch4/10: 0.1128 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch4/10: 0.11998 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch4/10: 0.13389 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch4/10: 0.11768 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch4/10: 0.11961 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch4/10: 0.11752 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch4/10: 0.12514 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch4/10: 0.10285 in 0 mins 0.24 secs
Train Loss for batch 150/541 @epoch4/10: 0.09501 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch4/10: 0.11943 in 0 mins 0.24 secs
Train Loss for batch 170/541 @epoch4/10: 0.10746 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch4/10: 0.09809 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch4/10: 0.1035 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch4/10: 0.09999 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch4/10: 0.09733 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch4/10: 0.09841 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch4/10: 0.10489 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch4/10: 0.11984 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch4/10: 0.0985 in 0 mins 0.24 secs
Train Loss for batch 260/541 @epoch4/10: 0.10083 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch4/10: 0.12554 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch4/10: 0.1167 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch4/10: 0.09681 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch4/10: 0.09959 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch4/10: 0.11582 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch4/10: 0.09261 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch4/10: 0.0955 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch4/10: 0.10454 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch4/10: 0.11537 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch4/10: 0.1044 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch4/10: 0.09317 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch4/10: 0.12975 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch4/10: 0.10653 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch4/10: 0.10291 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch4/10: 0.07668 in 0 mins 0.24 secs
Train Loss for batch 420/541 @epoch4/10: 0.09134 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch4/10: 0.11968 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch4/10: 0.09545 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch4/10: 0.1167 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch4/10: 0.12249 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch4/10: 0.10377 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch4/10: 0.09392 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch4/10: 0.10633 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch4/10: 0.09235 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch4/10: 0.09709 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch4/10: 0.11466 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch4/10: 0.11306 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch4/10: 0.08383 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/10: 0.17482 in 0.09 secs
Val Loss for batch 020/136 @epoch4/10: 0.21297 in 0.09 secs
Val Loss for batch 030/136 @epoch4/10: 0.20652 in 0.09 secs
Val Loss for batch 040/136 @epoch4/10: 0.16567 in 0.09 secs
Val Loss for batch 050/136 @epoch4/10: 0.19449 in 0.09 secs
Val Loss for batch 060/136 @epoch4/10: 0.16782 in 0.09 secs
Val Loss for batch 070/136 @epoch4/10: 0.21484 in 0.09 secs
Val Loss for batch 080/136 @epoch4/10: 0.19055 in 0.09 secs
Val Loss for batch 090/136 @epoch4/10: 0.17256 in 0.09 secs
Val Loss for batch 100/136 @epoch4/10: 0.21761 in 0.09 secs
Val Loss for batch 110/136 @epoch4/10: 0.23167 in 0.08 secs
Val Loss for batch 120/136 @epoch4/10: 0.20166 in 0.09 secs
Val Loss for batch 130/136 @epoch4/10: 0.20811 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7529496580093376, 'Cardiomegaly': 0.8491373144074567, 'Consolidation': 0.7086036923336245, 'Edema': 0.841273088430593, 'Effusion': 0.8680215429445574, 'Emphysema': 0.8060845994110203, 'Fibrosis': 0.7008730139240196, 'Hernia': 0.7819222629904237, 'Infiltration': 0.6118381662845105, 'Mass': 0.7402481371512499, 'Nodule': 0.6560474575104013, 'Pleural_Thickening': 0.6996543292421472, 'Pneumonia': 0.6479702585952343, 'Pneumothorax': 0.7748611483710756, 'none': 0.7275358141790154}
AVG Loss in validation set: 0.20584123164511808
0.7456774764004037
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/10: 0.09955 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch5/10: 0.09692 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch5/10: 0.1002 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch5/10: 0.11987 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch5/10: 0.09651 in 0 mins 0.24 secs
Train Loss for batch 060/541 @epoch5/10: 0.0859 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch5/10: 0.08227 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch5/10: 0.08724 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch5/10: 0.08457 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch5/10: 0.0851 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch5/10: 0.09737 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch5/10: 0.07125 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch5/10: 0.09675 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch5/10: 0.08728 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch5/10: 0.09446 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch5/10: 0.09565 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch5/10: 0.09169 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch5/10: 0.06803 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch5/10: 0.10371 in 0 mins 0.24 secs
Train Loss for batch 200/541 @epoch5/10: 0.10532 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch5/10: 0.09295 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch5/10: 0.10193 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch5/10: 0.10115 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch5/10: 0.07783 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch5/10: 0.09636 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch5/10: 0.09412 in 0 mins 0.24 secs
Train Loss for batch 270/541 @epoch5/10: 0.09439 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch5/10: 0.08221 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch5/10: 0.08284 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch5/10: 0.12091 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch5/10: 0.0779 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch5/10: 0.08787 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch5/10: 0.09037 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch5/10: 0.09237 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch5/10: 0.08452 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch5/10: 0.08065 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch5/10: 0.09559 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch5/10: 0.08465 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch5/10: 0.07946 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch5/10: 0.09647 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch5/10: 0.0931 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch5/10: 0.08948 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch5/10: 0.11567 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch5/10: 0.09963 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch5/10: 0.11772 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch5/10: 0.08359 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch5/10: 0.0792 in 0 mins 0.24 secs
Train Loss for batch 480/541 @epoch5/10: 0.08554 in 0 mins 0.24 secs
Train Loss for batch 490/541 @epoch5/10: 0.08772 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch5/10: 0.08128 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch5/10: 0.08935 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch5/10: 0.08102 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch5/10: 0.07292 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch5/10: 0.0753 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/10: 0.16748 in 0.09 secs
Val Loss for batch 020/136 @epoch5/10: 0.21865 in 0.09 secs
Val Loss for batch 030/136 @epoch5/10: 0.19993 in 0.09 secs
Val Loss for batch 040/136 @epoch5/10: 0.17248 in 0.09 secs
Val Loss for batch 050/136 @epoch5/10: 0.19869 in 0.09 secs
Val Loss for batch 060/136 @epoch5/10: 0.16088 in 0.08 secs
Val Loss for batch 070/136 @epoch5/10: 0.23259 in 0.09 secs
Val Loss for batch 080/136 @epoch5/10: 0.19172 in 0.08 secs
Val Loss for batch 090/136 @epoch5/10: 0.16812 in 0.09 secs
Val Loss for batch 100/136 @epoch5/10: 0.2028 in 0.09 secs
Val Loss for batch 110/136 @epoch5/10: 0.23023 in 0.09 secs
Val Loss for batch 120/136 @epoch5/10: 0.20859 in 0.09 secs
Val Loss for batch 130/136 @epoch5/10: 0.20475 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7256743602603001, 'Cardiomegaly': 0.8454998125538407, 'Consolidation': 0.671351756149257, 'Edema': 0.8395748583127622, 'Effusion': 0.855936642769214, 'Emphysema': 0.8184369855592402, 'Fibrosis': 0.6760202898313455, 'Hernia': 0.8184492182147588, 'Infiltration': 0.6221136569457691, 'Mass': 0.7594332634830999, 'Nodule': 0.6553122854449999, 'Pleural_Thickening': 0.7061271331063659, 'Pneumonia': 0.639443443365584, 'Pneumothorax': 0.7573914647691776, 'none': 0.7254513285289641}
AVG Loss in validation set: 0.20678929996281048
0.742197512197551
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_5.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch6/10: 0.08726 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch6/10: 0.08641 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch6/10: 0.06865 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch6/10: 0.08099 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch6/10: 0.08595 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch6/10: 0.09968 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch6/10: 0.09525 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch6/10: 0.0902 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch6/10: 0.09712 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch6/10: 0.09075 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch6/10: 0.09598 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch6/10: 0.0642 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch6/10: 0.08042 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch6/10: 0.08251 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch6/10: 0.08356 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch6/10: 0.09063 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch6/10: 0.08644 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch6/10: 0.0665 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch6/10: 0.07408 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch6/10: 0.0807 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch6/10: 0.08723 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch6/10: 0.06595 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch6/10: 0.06701 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch6/10: 0.07946 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch6/10: 0.09329 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch6/10: 0.06953 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch6/10: 0.07604 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch6/10: 0.06542 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch6/10: 0.07104 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch6/10: 0.08562 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch6/10: 0.07622 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch6/10: 0.07705 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch6/10: 0.08412 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch6/10: 0.07844 in 0 mins 0.24 secs
Train Loss for batch 350/541 @epoch6/10: 0.0799 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch6/10: 0.0799 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch6/10: 0.07965 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch6/10: 0.06019 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch6/10: 0.07619 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch6/10: 0.09847 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch6/10: 0.07092 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch6/10: 0.08048 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch6/10: 0.07318 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch6/10: 0.05857 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch6/10: 0.07479 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch6/10: 0.07711 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch6/10: 0.08382 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch6/10: 0.08587 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch6/10: 0.07268 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch6/10: 0.07677 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch6/10: 0.08505 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch6/10: 0.09505 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch6/10: 0.10705 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch6/10: 0.06778 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch6/10: 0.1827 in 0.09 secs
Val Loss for batch 020/136 @epoch6/10: 0.21774 in 0.09 secs
Val Loss for batch 030/136 @epoch6/10: 0.21192 in 0.09 secs
Val Loss for batch 040/136 @epoch6/10: 0.17563 in 0.09 secs
Val Loss for batch 050/136 @epoch6/10: 0.19243 in 0.09 secs
Val Loss for batch 060/136 @epoch6/10: 0.16887 in 0.09 secs
Val Loss for batch 070/136 @epoch6/10: 0.22963 in 0.09 secs
Val Loss for batch 080/136 @epoch6/10: 0.18765 in 0.09 secs
Val Loss for batch 090/136 @epoch6/10: 0.17045 in 0.09 secs
Val Loss for batch 100/136 @epoch6/10: 0.2276 in 0.09 secs
Val Loss for batch 110/136 @epoch6/10: 0.23469 in 0.08 secs
Val Loss for batch 120/136 @epoch6/10: 0.21368 in 0.09 secs
Val Loss for batch 130/136 @epoch6/10: 0.20925 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7256046648112773, 'Cardiomegaly': 0.8483981568966045, 'Consolidation': 0.6743752230265624, 'Edema': 0.8446723303699689, 'Effusion': 0.8552715216873403, 'Emphysema': 0.8227188464911153, 'Fibrosis': 0.708251816562025, 'Hernia': 0.8382747438454393, 'Infiltration': 0.626335100504671, 'Mass': 0.7549674515849251, 'Nodule': 0.6491838494815735, 'Pleural_Thickening': 0.7333721596295932, 'Pneumonia': 0.6307688069588665, 'Pneumothorax': 0.7705922019655296, 'none': 0.7231209962031729}
AVG Loss in validation set: 0.20940466962282822
0.7487704909868208
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_6.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch7/10: 0.09061 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch7/10: 0.06323 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch7/10: 0.07925 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch7/10: 0.05994 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch7/10: 0.05791 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch7/10: 0.06976 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch7/10: 0.0725 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch7/10: 0.06921 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch7/10: 0.06844 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch7/10: 0.07011 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch7/10: 0.06467 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch7/10: 0.07503 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch7/10: 0.07591 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch7/10: 0.07138 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch7/10: 0.09039 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch7/10: 0.0671 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch7/10: 0.06916 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch7/10: 0.05637 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch7/10: 0.06736 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch7/10: 0.10274 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch7/10: 0.07008 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch7/10: 0.06997 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch7/10: 0.06654 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch7/10: 0.07198 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch7/10: 0.06908 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch7/10: 0.07012 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch7/10: 0.07701 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch7/10: 0.06556 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch7/10: 0.07508 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch7/10: 0.07545 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch7/10: 0.08636 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch7/10: 0.0698 in 0 mins 0.24 secs
Train Loss for batch 330/541 @epoch7/10: 0.06475 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch7/10: 0.07069 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch7/10: 0.06925 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch7/10: 0.0716 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch7/10: 0.07133 in 0 mins 0.24 secs
Train Loss for batch 380/541 @epoch7/10: 0.07988 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch7/10: 0.07129 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch7/10: 0.07588 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch7/10: 0.07092 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch7/10: 0.07777 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch7/10: 0.04742 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch7/10: 0.06045 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch7/10: 0.08151 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch7/10: 0.05598 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch7/10: 0.07269 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch7/10: 0.05014 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch7/10: 0.07666 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch7/10: 0.07275 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch7/10: 0.06239 in 0 mins 0.24 secs
Train Loss for batch 520/541 @epoch7/10: 0.07992 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch7/10: 0.06773 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch7/10: 0.07818 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch7/10: 0.17432 in 0.09 secs
Val Loss for batch 020/136 @epoch7/10: 0.21362 in 0.09 secs
Val Loss for batch 030/136 @epoch7/10: 0.19292 in 0.09 secs
Val Loss for batch 040/136 @epoch7/10: 0.17053 in 0.09 secs
Val Loss for batch 050/136 @epoch7/10: 0.19603 in 0.09 secs
Val Loss for batch 060/136 @epoch7/10: 0.16062 in 0.09 secs
Val Loss for batch 070/136 @epoch7/10: 0.22063 in 0.09 secs
Val Loss for batch 080/136 @epoch7/10: 0.18364 in 0.09 secs
Val Loss for batch 090/136 @epoch7/10: 0.16724 in 0.09 secs
Val Loss for batch 100/136 @epoch7/10: 0.216 in 0.08 secs
Val Loss for batch 110/136 @epoch7/10: 0.23072 in 0.08 secs
Val Loss for batch 120/136 @epoch7/10: 0.20523 in 0.09 secs
Val Loss for batch 130/136 @epoch7/10: 0.20015 in 0.08 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7262948807385068, 'Cardiomegaly': 0.8462784539264208, 'Consolidation': 0.6927551894582628, 'Edema': 0.8533808015618338, 'Effusion': 0.8619055735273727, 'Emphysema': 0.8138470195402989, 'Fibrosis': 0.7087048769994916, 'Hernia': 0.761189348842166, 'Infiltration': 0.6251938880699828, 'Mass': 0.7520138392094051, 'Nodule': 0.6329052275876104, 'Pleural_Thickening': 0.7166905724775516, 'Pneumonia': 0.6614895045163781, 'Pneumothorax': 0.7705875653046411, 'none': 0.7283964460877302}
AVG Loss in validation set: 0.20658724038924986
0.7445169101257088
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_7.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch8/10: 0.06424 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch8/10: 0.05844 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch8/10: 0.05746 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch8/10: 0.0659 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch8/10: 0.06383 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch8/10: 0.0783 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch8/10: 0.05901 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch8/10: 0.07127 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch8/10: 0.05641 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch8/10: 0.08257 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch8/10: 0.06441 in 0 mins 0.24 secs
Train Loss for batch 120/541 @epoch8/10: 0.06142 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch8/10: 0.08229 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch8/10: 0.08623 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch8/10: 0.06096 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch8/10: 0.06399 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch8/10: 0.0615 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch8/10: 0.06231 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch8/10: 0.06811 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch8/10: 0.0707 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch8/10: 0.06248 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch8/10: 0.05341 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch8/10: 0.06573 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch8/10: 0.06596 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch8/10: 0.0675 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch8/10: 0.07254 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch8/10: 0.06885 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch8/10: 0.07407 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch8/10: 0.06541 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch8/10: 0.07053 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch8/10: 0.06058 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch8/10: 0.05564 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch8/10: 0.08904 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch8/10: 0.0569 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch8/10: 0.0607 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch8/10: 0.05813 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch8/10: 0.06564 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch8/10: 0.07145 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch8/10: 0.0642 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch8/10: 0.05487 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch8/10: 0.05499 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch8/10: 0.07195 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch8/10: 0.06145 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch8/10: 0.05611 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch8/10: 0.05657 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch8/10: 0.04966 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch8/10: 0.06041 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch8/10: 0.07385 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch8/10: 0.04775 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch8/10: 0.05806 in 0 mins 0.24 secs
Train Loss for batch 510/541 @epoch8/10: 0.0659 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch8/10: 0.06327 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch8/10: 0.07155 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch8/10: 0.06766 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch8/10: 0.17203 in 0.09 secs
Val Loss for batch 020/136 @epoch8/10: 0.23253 in 0.09 secs
Val Loss for batch 030/136 @epoch8/10: 0.208 in 0.08 secs
Val Loss for batch 040/136 @epoch8/10: 0.19129 in 0.09 secs
Val Loss for batch 050/136 @epoch8/10: 0.19583 in 0.09 secs
Val Loss for batch 060/136 @epoch8/10: 0.15374 in 0.09 secs
Val Loss for batch 070/136 @epoch8/10: 0.23357 in 0.09 secs
Val Loss for batch 080/136 @epoch8/10: 0.18804 in 0.09 secs
Val Loss for batch 090/136 @epoch8/10: 0.18402 in 0.09 secs
Val Loss for batch 100/136 @epoch8/10: 0.2239 in 0.09 secs
Val Loss for batch 110/136 @epoch8/10: 0.24631 in 0.09 secs
Val Loss for batch 120/136 @epoch8/10: 0.21445 in 0.09 secs
Val Loss for batch 130/136 @epoch8/10: 0.21886 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7293001462096367, 'Cardiomegaly': 0.8559470134750328, 'Consolidation': 0.687197625293857, 'Edema': 0.8448527933984608, 'Effusion': 0.8425074630066973, 'Emphysema': 0.825627088111771, 'Fibrosis': 0.6938159580960593, 'Hernia': 0.7942785804546076, 'Infiltration': 0.625902038654778, 'Mass': 0.7569092379571656, 'Nodule': 0.6429486178032856, 'Pleural_Thickening': 0.7142552849900797, 'Pneumonia': 0.6486216800551962, 'Pneumothorax': 0.7708101795762399, 'none': 0.7266180631794794}
AVG Loss in validation set: 0.21463070475030044
0.7452124076487763
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_8.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch9/10: 0.05107 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch9/10: 0.07172 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch9/10: 0.06289 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch9/10: 0.06884 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch9/10: 0.06751 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch9/10: 0.07113 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch9/10: 0.04935 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch9/10: 0.05851 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch9/10: 0.05694 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch9/10: 0.05606 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch9/10: 0.06508 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch9/10: 0.07836 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch9/10: 0.06664 in 0 mins 0.24 secs
Train Loss for batch 140/541 @epoch9/10: 0.05572 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch9/10: 0.05617 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch9/10: 0.06433 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch9/10: 0.06958 in 0 mins 0.23 secs
Train Loss for batch 180/541 @epoch9/10: 0.06625 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch9/10: 0.06438 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch9/10: 0.05341 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch9/10: 0.05523 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch9/10: 0.06583 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch9/10: 0.06904 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch9/10: 0.07207 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch9/10: 0.06152 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch9/10: 0.06155 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch9/10: 0.04266 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch9/10: 0.06848 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch9/10: 0.05593 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch9/10: 0.05476 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch9/10: 0.04633 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch9/10: 0.059 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch9/10: 0.05981 in 0 mins 0.23 secs
Train Loss for batch 340/541 @epoch9/10: 0.0579 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch9/10: 0.05128 in 0 mins 0.24 secs
Train Loss for batch 360/541 @epoch9/10: 0.06769 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch9/10: 0.05401 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch9/10: 0.05399 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch9/10: 0.06715 in 0 mins 0.24 secs
Train Loss for batch 400/541 @epoch9/10: 0.05325 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch9/10: 0.07244 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch9/10: 0.04708 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch9/10: 0.06796 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch9/10: 0.04748 in 0 mins 0.23 secs
Train Loss for batch 450/541 @epoch9/10: 0.0445 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch9/10: 0.0633 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch9/10: 0.05143 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch9/10: 0.05465 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch9/10: 0.05014 in 0 mins 0.23 secs
Train Loss for batch 500/541 @epoch9/10: 0.07635 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch9/10: 0.05106 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch9/10: 0.05146 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch9/10: 0.0627 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch9/10: 0.06437 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch9/10: 0.16929 in 0.09 secs
Val Loss for batch 020/136 @epoch9/10: 0.22001 in 0.09 secs
Val Loss for batch 030/136 @epoch9/10: 0.20033 in 0.09 secs
Val Loss for batch 040/136 @epoch9/10: 0.18124 in 0.09 secs
Val Loss for batch 050/136 @epoch9/10: 0.19585 in 0.09 secs
Val Loss for batch 060/136 @epoch9/10: 0.15608 in 0.09 secs
Val Loss for batch 070/136 @epoch9/10: 0.23696 in 0.09 secs
Val Loss for batch 080/136 @epoch9/10: 0.19484 in 0.09 secs
Val Loss for batch 090/136 @epoch9/10: 0.18493 in 0.09 secs
Val Loss for batch 100/136 @epoch9/10: 0.23177 in 0.09 secs
Val Loss for batch 110/136 @epoch9/10: 0.22826 in 0.09 secs
Val Loss for batch 120/136 @epoch9/10: 0.21175 in 0.09 secs
Val Loss for batch 130/136 @epoch9/10: 0.20739 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7419358872118035, 'Cardiomegaly': 0.8536108441159154, 'Consolidation': 0.707964088016368, 'Edema': 0.8344322994745129, 'Effusion': 0.8456859723051019, 'Emphysema': 0.8257229663017203, 'Fibrosis': 0.7077506646402303, 'Hernia': 0.7943607935082138, 'Infiltration': 0.6336360977838151, 'Mass': 0.7647985685977828, 'Nodule': 0.6498222469638542, 'Pleural_Thickening': 0.7124972003443494, 'Pneumonia': 0.6438552123079405, 'Pneumothorax': 0.7687186091239231, 'none': 0.7197491468218471}
AVG Loss in validation set: 0.21752846996044595
0.7489136750496808
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_9.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch10/10: 0.05269 in 0 mins 0.23 secs
Train Loss for batch 020/541 @epoch10/10: 0.06859 in 0 mins 0.23 secs
Train Loss for batch 030/541 @epoch10/10: 0.04577 in 0 mins 0.23 secs
Train Loss for batch 040/541 @epoch10/10: 0.0622 in 0 mins 0.23 secs
Train Loss for batch 050/541 @epoch10/10: 0.05731 in 0 mins 0.23 secs
Train Loss for batch 060/541 @epoch10/10: 0.06701 in 0 mins 0.23 secs
Train Loss for batch 070/541 @epoch10/10: 0.03857 in 0 mins 0.23 secs
Train Loss for batch 080/541 @epoch10/10: 0.04909 in 0 mins 0.23 secs
Train Loss for batch 090/541 @epoch10/10: 0.07469 in 0 mins 0.23 secs
Train Loss for batch 100/541 @epoch10/10: 0.0555 in 0 mins 0.23 secs
Train Loss for batch 110/541 @epoch10/10: 0.05922 in 0 mins 0.23 secs
Train Loss for batch 120/541 @epoch10/10: 0.05405 in 0 mins 0.23 secs
Train Loss for batch 130/541 @epoch10/10: 0.05662 in 0 mins 0.23 secs
Train Loss for batch 140/541 @epoch10/10: 0.04896 in 0 mins 0.23 secs
Train Loss for batch 150/541 @epoch10/10: 0.05772 in 0 mins 0.23 secs
Train Loss for batch 160/541 @epoch10/10: 0.05608 in 0 mins 0.23 secs
Train Loss for batch 170/541 @epoch10/10: 0.07377 in 0 mins 0.24 secs
Train Loss for batch 180/541 @epoch10/10: 0.05182 in 0 mins 0.23 secs
Train Loss for batch 190/541 @epoch10/10: 0.06584 in 0 mins 0.23 secs
Train Loss for batch 200/541 @epoch10/10: 0.06519 in 0 mins 0.23 secs
Train Loss for batch 210/541 @epoch10/10: 0.05894 in 0 mins 0.23 secs
Train Loss for batch 220/541 @epoch10/10: 0.06048 in 0 mins 0.23 secs
Train Loss for batch 230/541 @epoch10/10: 0.05572 in 0 mins 0.23 secs
Train Loss for batch 240/541 @epoch10/10: 0.04899 in 0 mins 0.23 secs
Train Loss for batch 250/541 @epoch10/10: 0.05251 in 0 mins 0.23 secs
Train Loss for batch 260/541 @epoch10/10: 0.05749 in 0 mins 0.23 secs
Train Loss for batch 270/541 @epoch10/10: 0.04442 in 0 mins 0.23 secs
Train Loss for batch 280/541 @epoch10/10: 0.04631 in 0 mins 0.23 secs
Train Loss for batch 290/541 @epoch10/10: 0.05466 in 0 mins 0.23 secs
Train Loss for batch 300/541 @epoch10/10: 0.05513 in 0 mins 0.23 secs
Train Loss for batch 310/541 @epoch10/10: 0.05815 in 0 mins 0.23 secs
Train Loss for batch 320/541 @epoch10/10: 0.04887 in 0 mins 0.23 secs
Train Loss for batch 330/541 @epoch10/10: 0.05505 in 0 mins 0.24 secs
Train Loss for batch 340/541 @epoch10/10: 0.045 in 0 mins 0.23 secs
Train Loss for batch 350/541 @epoch10/10: 0.05535 in 0 mins 0.23 secs
Train Loss for batch 360/541 @epoch10/10: 0.04625 in 0 mins 0.23 secs
Train Loss for batch 370/541 @epoch10/10: 0.07603 in 0 mins 0.23 secs
Train Loss for batch 380/541 @epoch10/10: 0.03741 in 0 mins 0.23 secs
Train Loss for batch 390/541 @epoch10/10: 0.04651 in 0 mins 0.23 secs
Train Loss for batch 400/541 @epoch10/10: 0.05541 in 0 mins 0.23 secs
Train Loss for batch 410/541 @epoch10/10: 0.06219 in 0 mins 0.23 secs
Train Loss for batch 420/541 @epoch10/10: 0.04349 in 0 mins 0.23 secs
Train Loss for batch 430/541 @epoch10/10: 0.05367 in 0 mins 0.23 secs
Train Loss for batch 440/541 @epoch10/10: 0.05219 in 0 mins 0.24 secs
Train Loss for batch 450/541 @epoch10/10: 0.04843 in 0 mins 0.23 secs
Train Loss for batch 460/541 @epoch10/10: 0.06015 in 0 mins 0.23 secs
Train Loss for batch 470/541 @epoch10/10: 0.0499 in 0 mins 0.23 secs
Train Loss for batch 480/541 @epoch10/10: 0.07173 in 0 mins 0.23 secs
Train Loss for batch 490/541 @epoch10/10: 0.04742 in 0 mins 0.24 secs
Train Loss for batch 500/541 @epoch10/10: 0.06244 in 0 mins 0.23 secs
Train Loss for batch 510/541 @epoch10/10: 0.05454 in 0 mins 0.23 secs
Train Loss for batch 520/541 @epoch10/10: 0.05433 in 0 mins 0.23 secs
Train Loss for batch 530/541 @epoch10/10: 0.03744 in 0 mins 0.23 secs
Train Loss for batch 540/541 @epoch10/10: 0.04901 in 0 mins 0.23 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch10/10: 0.18504 in 0.09 secs
Val Loss for batch 020/136 @epoch10/10: 0.21827 in 0.09 secs
Val Loss for batch 030/136 @epoch10/10: 0.21227 in 0.09 secs
Val Loss for batch 040/136 @epoch10/10: 0.18158 in 0.09 secs
Val Loss for batch 050/136 @epoch10/10: 0.20859 in 0.09 secs
Val Loss for batch 060/136 @epoch10/10: 0.17423 in 0.09 secs
Val Loss for batch 070/136 @epoch10/10: 0.24276 in 0.09 secs
Val Loss for batch 080/136 @epoch10/10: 0.20099 in 0.09 secs
Val Loss for batch 090/136 @epoch10/10: 0.19274 in 0.09 secs
Val Loss for batch 100/136 @epoch10/10: 0.24383 in 0.09 secs
Val Loss for batch 110/136 @epoch10/10: 0.24166 in 0.09 secs
Val Loss for batch 120/136 @epoch10/10: 0.21739 in 0.08 secs
Val Loss for batch 130/136 @epoch10/10: 0.2204 in 0.09 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7269562907406266, 'Cardiomegaly': 0.8348812696571182, 'Consolidation': 0.7042828048537753, 'Edema': 0.8385813264693249, 'Effusion': 0.8436388640143277, 'Emphysema': 0.8032928017092407, 'Fibrosis': 0.6923343310895188, 'Hernia': 0.8397637135940806, 'Infiltration': 0.630682152322161, 'Mass': 0.752082291383098, 'Nodule': 0.6436561353993653, 'Pleural_Thickening': 0.7028211940044093, 'Pneumonia': 0.6323775550917463, 'Pneumothorax': 0.7713912350089935, 'none': 0.7152610226877744}
AVG Loss in validation set: 0.2228471110305795
0.7440529975241276
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_epoch_10.pth
Model saved to /scratch/group4/out/1/ft_googlenet_adam_steplr_1/models/model_weights_final_0.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch1/5: 0.28408 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch1/5: 0.26506 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch1/5: 0.24515 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch1/5: 0.26574 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch1/5: 0.24645 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch1/5: 0.24792 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch1/5: 0.25325 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch1/5: 0.22392 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch1/5: 0.23685 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch1/5: 0.22899 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch1/5: 0.22407 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch1/5: 0.22135 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch1/5: 0.23554 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch1/5: 0.22309 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch1/5: 0.21162 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch1/5: 0.22949 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch1/5: 0.25588 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch1/5: 0.22522 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch1/5: 0.23314 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch1/5: 0.23597 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch1/5: 0.20393 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch1/5: 0.22489 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch1/5: 0.20564 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch1/5: 0.22252 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch1/5: 0.22126 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch1/5: 0.21416 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch1/5: 0.22608 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch1/5: 0.23164 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch1/5: 0.24172 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch1/5: 0.2222 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch1/5: 0.21371 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch1/5: 0.21457 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch1/5: 0.20587 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch1/5: 0.21095 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch1/5: 0.20249 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch1/5: 0.21298 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch1/5: 0.21134 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch1/5: 0.21781 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch1/5: 0.20498 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch1/5: 0.20992 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch1/5: 0.20312 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch1/5: 0.2355 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch1/5: 0.20862 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch1/5: 0.18401 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch1/5: 0.20469 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch1/5: 0.20636 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch1/5: 0.19606 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch1/5: 0.18831 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch1/5: 0.19748 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch1/5: 0.18391 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch1/5: 0.20758 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch1/5: 0.1914 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch1/5: 0.19252 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch1/5: 0.20574 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch1/5: 0.21424 in 0.1 secs
Val Loss for batch 020/136 @epoch1/5: 0.23503 in 0.11 secs
Val Loss for batch 030/136 @epoch1/5: 0.22992 in 0.11 secs
Val Loss for batch 040/136 @epoch1/5: 0.2044 in 0.1 secs
Val Loss for batch 050/136 @epoch1/5: 0.21829 in 0.11 secs
Val Loss for batch 060/136 @epoch1/5: 0.20189 in 0.1 secs
Val Loss for batch 070/136 @epoch1/5: 0.24016 in 0.1 secs
Val Loss for batch 080/136 @epoch1/5: 0.21965 in 0.11 secs
Val Loss for batch 090/136 @epoch1/5: 0.20726 in 0.11 secs
Val Loss for batch 100/136 @epoch1/5: 0.23246 in 0.1 secs
Val Loss for batch 110/136 @epoch1/5: 0.24632 in 0.11 secs
Val Loss for batch 120/136 @epoch1/5: 0.22074 in 0.11 secs
Val Loss for batch 130/136 @epoch1/5: 0.2187 in 0.11 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7099515938285911, 'Cardiomegaly': 0.8587420294508736, 'Consolidation': 0.7552778843722711, 'Edema': 0.8558025064541321, 'Effusion': 0.8592504130794317, 'Emphysema': 0.70469393720407, 'Fibrosis': 0.681822419408677, 'Hernia': 0.7542925871229998, 'Infiltration': 0.5952228644011869, 'Mass': 0.6969819317915635, 'Nodule': 0.5721297615792892, 'Pleural_Thickening': 0.6970738230379783, 'Pneumonia': 0.5324724055132797, 'Pneumothorax': 0.7743421150963242, 'none': 0.7199818539741053}
AVG Loss in validation set: 0.2276368237346397
0.7177183051671906
Model saved to /scratch/group4/out/1/ft_resnet_34_adam_steplr/models/model_weights_epoch_1.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch2/5: 0.19693 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch2/5: 0.19032 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch2/5: 0.18198 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch2/5: 0.18717 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch2/5: 0.18781 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch2/5: 0.19267 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch2/5: 0.20974 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch2/5: 0.21154 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch2/5: 0.19858 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch2/5: 0.17473 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch2/5: 0.20057 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch2/5: 0.17788 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch2/5: 0.20224 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch2/5: 0.20695 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch2/5: 0.18593 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch2/5: 0.16651 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch2/5: 0.19436 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch2/5: 0.18787 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch2/5: 0.18212 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch2/5: 0.19321 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch2/5: 0.17005 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch2/5: 0.18864 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch2/5: 0.19711 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch2/5: 0.16935 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch2/5: 0.19408 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch2/5: 0.17558 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch2/5: 0.2054 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch2/5: 0.16734 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch2/5: 0.16647 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch2/5: 0.1799 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch2/5: 0.18766 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch2/5: 0.16439 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch2/5: 0.19127 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch2/5: 0.20054 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch2/5: 0.16802 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch2/5: 0.15899 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch2/5: 0.16723 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch2/5: 0.14352 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch2/5: 0.16866 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch2/5: 0.18413 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch2/5: 0.19066 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch2/5: 0.2084 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch2/5: 0.19352 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch2/5: 0.17929 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch2/5: 0.17002 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch2/5: 0.17169 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch2/5: 0.16855 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch2/5: 0.1677 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch2/5: 0.1639 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch2/5: 0.16843 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch2/5: 0.1805 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch2/5: 0.16218 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch2/5: 0.1838 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch2/5: 0.16653 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch2/5: 0.1918 in 0.11 secs
Val Loss for batch 020/136 @epoch2/5: 0.24188 in 0.11 secs
Val Loss for batch 030/136 @epoch2/5: 0.2231 in 0.1 secs
Val Loss for batch 040/136 @epoch2/5: 0.17868 in 0.1 secs
Val Loss for batch 050/136 @epoch2/5: 0.21087 in 0.11 secs
Val Loss for batch 060/136 @epoch2/5: 0.18907 in 0.11 secs
Val Loss for batch 070/136 @epoch2/5: 0.22442 in 0.1 secs
Val Loss for batch 080/136 @epoch2/5: 0.20479 in 0.1 secs
Val Loss for batch 090/136 @epoch2/5: 0.1851 in 0.11 secs
Val Loss for batch 100/136 @epoch2/5: 0.2058 in 0.1 secs
Val Loss for batch 110/136 @epoch2/5: 0.23783 in 0.11 secs
Val Loss for batch 120/136 @epoch2/5: 0.21436 in 0.11 secs
Val Loss for batch 130/136 @epoch2/5: 0.22352 in 0.1 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7128645428955922, 'Cardiomegaly': 0.8629475103340629, 'Consolidation': 0.7474066157523549, 'Edema': 0.8610613173267921, 'Effusion': 0.867912480016301, 'Emphysema': 0.8129998257625745, 'Fibrosis': 0.6690927285675696, 'Hernia': 0.6919781374175967, 'Infiltration': 0.5769205506501472, 'Mass': 0.7761907512804117, 'Nodule': 0.5929484379368186, 'Pleural_Thickening': 0.7184454858319256, 'Pneumonia': 0.6407187386118277, 'Pneumothorax': 0.6937901146171661, 'none': 0.7221180584396198}
AVG Loss in validation set: 0.21724223941771234
0.7303769455000815
Model saved to /scratch/group4/out/1/ft_resnet_34_adam_steplr/models/model_weights_epoch_2.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch3/5: 0.143 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch3/5: 0.14748 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch3/5: 0.1608 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch3/5: 0.14455 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch3/5: 0.1287 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch3/5: 0.15549 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch3/5: 0.14565 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch3/5: 0.1306 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch3/5: 0.14085 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch3/5: 0.14464 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch3/5: 0.1593 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch3/5: 0.14215 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch3/5: 0.14781 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch3/5: 0.14706 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch3/5: 0.13297 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch3/5: 0.13293 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch3/5: 0.13861 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch3/5: 0.14431 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch3/5: 0.14165 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch3/5: 0.17423 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch3/5: 0.13989 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch3/5: 0.13266 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch3/5: 0.13824 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch3/5: 0.14793 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch3/5: 0.14552 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch3/5: 0.13913 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch3/5: 0.12455 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch3/5: 0.1363 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch3/5: 0.13326 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch3/5: 0.12211 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch3/5: 0.11624 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch3/5: 0.12677 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch3/5: 0.14568 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch3/5: 0.13561 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch3/5: 0.1433 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch3/5: 0.13191 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch3/5: 0.13736 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch3/5: 0.12954 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch3/5: 0.13263 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch3/5: 0.13287 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch3/5: 0.17009 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch3/5: 0.12975 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch3/5: 0.1386 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch3/5: 0.13468 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch3/5: 0.1479 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch3/5: 0.14577 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch3/5: 0.15777 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch3/5: 0.11622 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch3/5: 0.12359 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch3/5: 0.15051 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch3/5: 0.12712 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch3/5: 0.13149 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch3/5: 0.1095 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch3/5: 0.14337 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch3/5: 0.1874 in 0.1 secs
Val Loss for batch 020/136 @epoch3/5: 0.22238 in 0.1 secs
Val Loss for batch 030/136 @epoch3/5: 0.21096 in 0.1 secs
Val Loss for batch 040/136 @epoch3/5: 0.17333 in 0.11 secs
Val Loss for batch 050/136 @epoch3/5: 0.20004 in 0.11 secs
Val Loss for batch 060/136 @epoch3/5: 0.16946 in 0.1 secs
Val Loss for batch 070/136 @epoch3/5: 0.21419 in 0.1 secs
Val Loss for batch 080/136 @epoch3/5: 0.19176 in 0.11 secs
Val Loss for batch 090/136 @epoch3/5: 0.17837 in 0.11 secs
Val Loss for batch 100/136 @epoch3/5: 0.19741 in 0.11 secs
Val Loss for batch 110/136 @epoch3/5: 0.23142 in 0.11 secs
Val Loss for batch 120/136 @epoch3/5: 0.20925 in 0.1 secs
Val Loss for batch 130/136 @epoch3/5: 0.1947 in 0.11 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7360244875943246, 'Cardiomegaly': 0.8739271302851357, 'Consolidation': 0.7332431962328908, 'Edema': 0.8751754501665894, 'Effusion': 0.8685227727990354, 'Emphysema': 0.8507317495817827, 'Fibrosis': 0.7018533753173128, 'Hernia': 0.844355464884369, 'Infiltration': 0.5876584071553128, 'Mass': 0.7862373937210761, 'Nodule': 0.6573468000213785, 'Pleural_Thickening': 0.7210192530419621, 'Pneumonia': 0.6482115258026276, 'Pneumothorax': 0.768893820356556, 'none': 0.7349017140941779}
AVG Loss in validation set: 0.2056274632654199
0.7609429162114538
Model saved to /scratch/group4/out/1/ft_resnet_34_adam_steplr/models/model_weights_epoch_3.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch4/5: 0.1306 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch4/5: 0.13044 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch4/5: 0.12156 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch4/5: 0.13554 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch4/5: 0.12611 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch4/5: 0.13335 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch4/5: 0.13514 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch4/5: 0.12694 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch4/5: 0.12696 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch4/5: 0.11592 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch4/5: 0.12904 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch4/5: 0.11307 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch4/5: 0.12652 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch4/5: 0.14167 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch4/5: 0.14621 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch4/5: 0.11538 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch4/5: 0.13559 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch4/5: 0.12761 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch4/5: 0.12607 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch4/5: 0.10323 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch4/5: 0.11888 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch4/5: 0.12083 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch4/5: 0.11274 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch4/5: 0.12672 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch4/5: 0.1156 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch4/5: 0.1145 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch4/5: 0.1253 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch4/5: 0.08494 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch4/5: 0.1134 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch4/5: 0.10355 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch4/5: 0.12975 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch4/5: 0.11928 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch4/5: 0.10853 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch4/5: 0.11356 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch4/5: 0.11784 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch4/5: 0.10995 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch4/5: 0.13169 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch4/5: 0.1282 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch4/5: 0.11435 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch4/5: 0.12401 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch4/5: 0.10272 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch4/5: 0.0955 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch4/5: 0.10628 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch4/5: 0.11945 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch4/5: 0.12173 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch4/5: 0.12589 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch4/5: 0.11418 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch4/5: 0.11357 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch4/5: 0.11064 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch4/5: 0.10617 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch4/5: 0.10701 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch4/5: 0.11412 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch4/5: 0.10666 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch4/5: 0.11932 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch4/5: 0.1878 in 0.11 secs
Val Loss for batch 020/136 @epoch4/5: 0.22054 in 0.11 secs
Val Loss for batch 030/136 @epoch4/5: 0.20213 in 0.1 secs
Val Loss for batch 040/136 @epoch4/5: 0.17121 in 0.11 secs
Val Loss for batch 050/136 @epoch4/5: 0.19785 in 0.11 secs
Val Loss for batch 060/136 @epoch4/5: 0.16134 in 0.11 secs
Val Loss for batch 070/136 @epoch4/5: 0.22946 in 0.11 secs
Val Loss for batch 080/136 @epoch4/5: 0.18768 in 0.11 secs
Val Loss for batch 090/136 @epoch4/5: 0.18235 in 0.11 secs
Val Loss for batch 100/136 @epoch4/5: 0.20227 in 0.11 secs
Val Loss for batch 110/136 @epoch4/5: 0.22711 in 0.1 secs
Val Loss for batch 120/136 @epoch4/5: 0.20678 in 0.11 secs
Val Loss for batch 130/136 @epoch4/5: 0.18576 in 0.1 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7308672343501933, 'Cardiomegaly': 0.8721649892428956, 'Consolidation': 0.6957329302866037, 'Edema': 0.8670069772083424, 'Effusion': 0.8650883917210994, 'Emphysema': 0.8520250102114556, 'Fibrosis': 0.7036627747808711, 'Hernia': 0.8500251206552685, 'Infiltration': 0.5935133602127229, 'Mass': 0.7670073184474255, 'Nodule': 0.662600571050338, 'Pleural_Thickening': 0.7424686785427124, 'Pneumonia': 0.644153735464551, 'Pneumothorax': 0.7560112671950568, 'none': 0.7324202084550315}
AVG Loss in validation set: 0.20742216609828296
0.7573091685263954
Model saved to /scratch/group4/out/1/ft_resnet_34_adam_steplr/models/model_weights_epoch_4.pth
-------------------------------------------------------
TRAIN
-------------------------------------------------------
Train Loss for batch 010/541 @epoch5/5: 0.10464 in 0 mins 0.26 secs
Train Loss for batch 020/541 @epoch5/5: 0.11648 in 0 mins 0.26 secs
Train Loss for batch 030/541 @epoch5/5: 0.11851 in 0 mins 0.26 secs
Train Loss for batch 040/541 @epoch5/5: 0.11502 in 0 mins 0.26 secs
Train Loss for batch 050/541 @epoch5/5: 0.13842 in 0 mins 0.26 secs
Train Loss for batch 060/541 @epoch5/5: 0.13108 in 0 mins 0.26 secs
Train Loss for batch 070/541 @epoch5/5: 0.10897 in 0 mins 0.26 secs
Train Loss for batch 080/541 @epoch5/5: 0.10314 in 0 mins 0.26 secs
Train Loss for batch 090/541 @epoch5/5: 0.11948 in 0 mins 0.26 secs
Train Loss for batch 100/541 @epoch5/5: 0.11244 in 0 mins 0.26 secs
Train Loss for batch 110/541 @epoch5/5: 0.10638 in 0 mins 0.26 secs
Train Loss for batch 120/541 @epoch5/5: 0.10832 in 0 mins 0.26 secs
Train Loss for batch 130/541 @epoch5/5: 0.12814 in 0 mins 0.26 secs
Train Loss for batch 140/541 @epoch5/5: 0.11703 in 0 mins 0.26 secs
Train Loss for batch 150/541 @epoch5/5: 0.09222 in 0 mins 0.26 secs
Train Loss for batch 160/541 @epoch5/5: 0.08895 in 0 mins 0.26 secs
Train Loss for batch 170/541 @epoch5/5: 0.11752 in 0 mins 0.26 secs
Train Loss for batch 180/541 @epoch5/5: 0.123 in 0 mins 0.26 secs
Train Loss for batch 190/541 @epoch5/5: 0.12031 in 0 mins 0.26 secs
Train Loss for batch 200/541 @epoch5/5: 0.09765 in 0 mins 0.26 secs
Train Loss for batch 210/541 @epoch5/5: 0.10326 in 0 mins 0.26 secs
Train Loss for batch 220/541 @epoch5/5: 0.11191 in 0 mins 0.26 secs
Train Loss for batch 230/541 @epoch5/5: 0.09839 in 0 mins 0.26 secs
Train Loss for batch 240/541 @epoch5/5: 0.11048 in 0 mins 0.26 secs
Train Loss for batch 250/541 @epoch5/5: 0.11151 in 0 mins 0.26 secs
Train Loss for batch 260/541 @epoch5/5: 0.12166 in 0 mins 0.26 secs
Train Loss for batch 270/541 @epoch5/5: 0.13679 in 0 mins 0.26 secs
Train Loss for batch 280/541 @epoch5/5: 0.10038 in 0 mins 0.26 secs
Train Loss for batch 290/541 @epoch5/5: 0.09809 in 0 mins 0.26 secs
Train Loss for batch 300/541 @epoch5/5: 0.14191 in 0 mins 0.26 secs
Train Loss for batch 310/541 @epoch5/5: 0.10403 in 0 mins 0.26 secs
Train Loss for batch 320/541 @epoch5/5: 0.10651 in 0 mins 0.26 secs
Train Loss for batch 330/541 @epoch5/5: 0.12016 in 0 mins 0.26 secs
Train Loss for batch 340/541 @epoch5/5: 0.1061 in 0 mins 0.26 secs
Train Loss for batch 350/541 @epoch5/5: 0.10033 in 0 mins 0.26 secs
Train Loss for batch 360/541 @epoch5/5: 0.13559 in 0 mins 0.26 secs
Train Loss for batch 370/541 @epoch5/5: 0.11807 in 0 mins 0.26 secs
Train Loss for batch 380/541 @epoch5/5: 0.11685 in 0 mins 0.26 secs
Train Loss for batch 390/541 @epoch5/5: 0.12249 in 0 mins 0.26 secs
Train Loss for batch 400/541 @epoch5/5: 0.10926 in 0 mins 0.26 secs
Train Loss for batch 410/541 @epoch5/5: 0.10413 in 0 mins 0.26 secs
Train Loss for batch 420/541 @epoch5/5: 0.11591 in 0 mins 0.26 secs
Train Loss for batch 430/541 @epoch5/5: 0.09343 in 0 mins 0.26 secs
Train Loss for batch 440/541 @epoch5/5: 0.09084 in 0 mins 0.26 secs
Train Loss for batch 450/541 @epoch5/5: 0.11197 in 0 mins 0.26 secs
Train Loss for batch 460/541 @epoch5/5: 0.12102 in 0 mins 0.26 secs
Train Loss for batch 470/541 @epoch5/5: 0.12075 in 0 mins 0.26 secs
Train Loss for batch 480/541 @epoch5/5: 0.10113 in 0 mins 0.26 secs
Train Loss for batch 490/541 @epoch5/5: 0.0924 in 0 mins 0.26 secs
Train Loss for batch 500/541 @epoch5/5: 0.12535 in 0 mins 0.26 secs
Train Loss for batch 510/541 @epoch5/5: 0.1252 in 0 mins 0.26 secs
Train Loss for batch 520/541 @epoch5/5: 0.11162 in 0 mins 0.26 secs
Train Loss for batch 530/541 @epoch5/5: 0.10573 in 0 mins 0.26 secs
Train Loss for batch 540/541 @epoch5/5: 0.11 in 0 mins 0.26 secs
-------------------------------------------------------
VAL
-------------------------------------------------------
Val Loss for batch 010/136 @epoch5/5: 0.18218 in 0.11 secs
Val Loss for batch 020/136 @epoch5/5: 0.2203 in 0.11 secs
Val Loss for batch 030/136 @epoch5/5: 0.21035 in 0.11 secs
Val Loss for batch 040/136 @epoch5/5: 0.18072 in 0.1 secs
Val Loss for batch 050/136 @epoch5/5: 0.20511 in 0.11 secs
Val Loss for batch 060/136 @epoch5/5: 0.16444 in 0.1 secs
Val Loss for batch 070/136 @epoch5/5: 0.21515 in 0.1 secs
Val Loss for batch 080/136 @epoch5/5: 0.19082 in 0.1 secs
Val Loss for batch 090/136 @epoch5/5: 0.1851 in 0.1 secs
Val Loss for batch 100/136 @epoch5/5: 0.20263 in 0.1 secs
Val Loss for batch 110/136 @epoch5/5: 0.22178 in 0.11 secs
Val Loss for batch 120/136 @epoch5/5: 0.21259 in 0.11 secs
Val Loss for batch 130/136 @epoch5/5: 0.191 in 0.1 secs
ROC_AUC_SCORE: {'Atelectasis': 0.7410086189465943, 'Cardiomegaly': 0.8699892077444611, 'Consolidation': 0.7039664209414546, 'Edema': 0.8624512419495756, 'Effusion': 0.8708642839688411, 'Emphysema': 0.8469353731489653, 'Fibrosis': 0.7182758782209925, 'Hernia': 0.831734238691899, 'Infiltration': 0.6129657804617025, 'Mass': 0.7646040536348502, 'Nodule': 0.6513767107870545, 'Pleural_Thickening': 0.7521236750774158, 'Pneumonia': 0.6661391197131874, 'Pneumothorax': 0.7617725092703217, 'none': 0.7321951923955757}
AVG Loss in validation set: 0.20585517047237478
0.761014793754094
Model saved to /scratch/group4/out/1/ft_resnet_34_adam_steplr/models/model_weights_epoch_5.pth
Model saved to /scratch/group4/out/1/ft_resnet_34_adam_steplr/models/model_weights_final_0.pth
